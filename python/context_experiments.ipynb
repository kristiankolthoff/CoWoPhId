{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context-Aware Complex Word Identification\n",
    "Here we devise and implement all the relevant methods for evaluating the influence of context words for the complexity of a given target word. Thus, we implement various context definition methods that extract context words for a target based on different ideas (e.g. local context, grammatical context and semantic context). Afterwards we compute features for the context and use these features to represent the context in the classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.wsd import lesk\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from collections import defaultdict\n",
    "\n",
    "Model = namedtuple('Model', 'type, name, dimension, corpus, model')\n",
    "Dataset = namedtuple('Dataset', 'name, train, test')\n",
    "FeatureDataset = namedtuple('FeatureDataset', 'name, fc, agg, train, test')\n",
    "FeatureCategory = namedtuple('FeatureCategory', 'name, func')\n",
    "Aggregation = namedtuple('Aggregation', 'name, agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "MAIN_PATH_DATASET = \"../cwishareddataset/traindevset/english/\"\n",
    "genres = ['Wikipedia', 'WikiNews', 'News']\n",
    "datasets = ['Train', 'Dev']\n",
    "\n",
    "datasets = [Dataset('Wikipedia', 'Train_Feat', 'Dev_Feat'),\n",
    "            Dataset('WikiNews', 'Train_Feat', 'Dev_Feat'),\n",
    "            Dataset('News', 'Train_Feat', 'Dev_Feat')]\n",
    "\n",
    "feature_categories = []\n",
    "\n",
    "def load_df(path):\n",
    "    df = pd.read_csv(path, header=0, sep = \"\\t\")\n",
    "    df = df.drop(['Unnamed: 0'], axis = 1)\n",
    "    return df\n",
    "\n",
    "datasets = [Dataset(d.name, load_df(MAIN_PATH_DATASET + d.name + '_' + d.train + '.tsv'),\n",
    "                            load_df(MAIN_PATH_DATASET + d.name + '_' + d.test + '.tsv'))\n",
    "                            for d in datasets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import *\n",
    "from nltk import word_tokenize\n",
    "from functools import lru_cache\n",
    "from utils import penn_to_wn\n",
    "import re\n",
    "import unicodedata\n",
    "import sys\n",
    "\n",
    "wordNetLemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def overlaps(start1, end1, start2, end2):\n",
    "    return bool(range(max(start1, start2), min(end1, end2)+1))\n",
    "\n",
    "tbl = dict.fromkeys(i for i in range(sys.maxunicode)\n",
    "                      if unicodedata.category(chr(i)).startswith('P'))\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(tbl)\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def targets_with_index(start, end, context):\n",
    "    curr_pos = 0\n",
    "    targets = []\n",
    "    j = 0\n",
    "    w = 0\n",
    "    curr_split = ''\n",
    "    ctx_split = context.split()\n",
    "    whitespaces = re.findall('\\s+', context)\n",
    "    num_whitespaces = [len(token) for token in whitespaces]\n",
    "    num_whitespaces.append(1)\n",
    "    tokens = word_tokenize(context)\n",
    "    tokens = ['\"' if token not in context else token for token in tokens]\n",
    "    for index, token in enumerate(tokens, 1):\n",
    "        targets.append((token, index, curr_pos, (curr_pos + len(token))))\n",
    "        curr_pos += len(token)\n",
    "        curr_split += token\n",
    "        if ctx_split[j] == curr_split:\n",
    "            curr_pos += num_whitespaces[w]\n",
    "            j += 1\n",
    "            w += 1\n",
    "            curr_split = ''\n",
    "    vals = [(target[0], target[1]) for target in targets \\\n",
    "            if overlaps(start, end, target[2], target[3])]\n",
    "    return [val for val in vals if val[0] != '\"']\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def wordnet_pos_tagging(sentence):\n",
    "    tokens = word_tokenize(sentence)\n",
    "    return nltk.pos_tag(tokens)\n",
    "\n",
    "def pos_tags(start, end, sentence):\n",
    "    wordPOSPairs = wordnet_pos_tagging(sentence)\n",
    "    targets_index = targets_with_index(start, end, sentence)\n",
    "    results = [wordPOSPairs[tpl[1]-1][1] for tpl in targets_index]\n",
    "    filtered_results = [result for result in results \n",
    "                        if remove_punctuation(result).strip() and result != 'POS']\n",
    "    return filtered_results if len(filtered_results) > 0 else None\n",
    "\n",
    "def wordnet_lemma(target, pos):\n",
    "    tokens = nltk.word_tokenize(target)\n",
    "    if pos:\n",
    "        pos = [penn_to_wn(poss) if penn_to_wn(poss) else 'n' for poss in pos]\n",
    "        lemmas = [wordNetLemmatizer.lemmatize(token, poss)\n",
    "                     for token, poss in zip(tokens, pos)]\n",
    "        return ' '.join(lemmas)\n",
    "    return target\n",
    "\n",
    "def preprocessing(dataframe):\n",
    "    df = dataframe.copy()\n",
    "    df['p_sentence'] = df.sentence.apply(lambda sent : sent.strip().lower())\n",
    "    df['sentence'] = df.sentence.apply(lambda sent : sent.replace(\"''\", \"``\"))\n",
    "    df['p_target'] = df.target.apply(lambda target : target.strip().lower())\n",
    "    df['pos_tags'] = df[['start', 'end', 'sentence']].apply(lambda vals : pos_tags(*vals), axis = 1)\n",
    "    df['pos_tags_pt'] = df.pos_tags.apply(lambda pos : [penn_to_wn(poss) if penn_to_wn(poss) else 'n' for poss in pos])\n",
    "    df['lemma'] = df[['target', 'pos_tags']].apply(lambda vals : wordnet_lemma(*vals), axis = 1)\n",
    "    df['p_lemma'] = df.lemma.apply(lambda lemma : lemma.strip().lower())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_datasets = [Dataset(ds.name, preprocessing(ds.train), \n",
    "                               preprocessing(ds.test)) for ds in datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = preprocessed_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Context-Token Aggregation\n",
    "First we define how feature values of multiple context-tokens should be aggreagated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq_wiki = {}\n",
    "sum_counts = 0\n",
    "with open(\"resources/word-freq-dumps/enwiki-20150602-words-frequency.txt\", encoding=\"utf8\") as file:\n",
    "    for line in file:\n",
    "        word, freq = line.partition(\" \")[::2]\n",
    "        sum_counts+=int(freq)\n",
    "        word_freq_wiki[word.strip()] = int(freq)\n",
    "        \n",
    "def get_unigram_probability(word):\n",
    "    return word_freq_wiki.get(word,1) / (sum_counts + len(word_freq_wiki))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def agg_ctx_feat_num_average(tokens, func_feature, *args, **kwargs):\n",
    "    if all(isinstance(tpl, tuple) for tpl in tokens):\n",
    "        return np.mean([func_feature(token, *args) for token, dist in tokens])\n",
    "    return np.mean([func_feature(token, *args) for token in tokens])\n",
    "\n",
    "def agg_ctx_feat_num_weighted_average(tokens, func_feature, alpha, *args):\n",
    "    if all(isinstance(tpl, tuple) for tpl in tokens):\n",
    "        if len(tokens)==1:\n",
    "            return np.mean([func_feature(token, *args) for token, dist in tokens])\n",
    "        prob_sum = np.sum([(alpha/(alpha+get_unigram_probability(token))) for token, dist in tokens])\n",
    "        return np.mean([((alpha/(alpha+get_unigram_probability(token)))/prob_sum) * \n",
    "                func_feature(token, *args) for token, dist in tokens])\n",
    "    prob_sum = np.sum([(alpha/(alpha+get_unigram_probability(token))) for token in tokens])\n",
    "    return np.mean([((alpha/(alpha+get_unigram_probability(token)))/prob_sum) * \n",
    "                func_feature(token, *args) for token in tokens])\n",
    "\n",
    "agg_feat_num_weighted_average_medium = lambda target, func_feature, *args: \\\n",
    "                        agg_ctx_feat_num_weighted_average(target, func_feature, 0.0001, *args)\n",
    "\n",
    "def agg_ctx_feat_num_distance(tokens, func_feature, *args):\n",
    "    if all(isinstance(tpl, tuple) for tpl in tokens):\n",
    "        if len(tokens)==1:\n",
    "            return np.mean([func_feature(token, *args) for token, dist in tokens])\n",
    "        dist_sum = np.sum(dist for token, dist in tokens)\n",
    "        return np.sum([(func_feature(token, *args) * ((dist_sum-dist)/dist_sum)) \n",
    "                    for token, dist in tokens])\n",
    "    return np.mean([func_feature(token, *args) for token in tokens])\n",
    "\n",
    "def agg_ctx_feat_num_median(tokens, func_feature, *args):\n",
    "    if all(isinstance(tpl, tuple) for tpl in tokens):\n",
    "        return np.median([func_feature(token, *args) for token, dist in tokens])\n",
    "    return np.median([func_feature(token, *args) for token in tokens])\n",
    "\n",
    "def agg_ctx_feat_num_max(tokens, func_feature, *args):\n",
    "    if all(isinstance(tpl, tuple) for tpl in tokens):\n",
    "        return np.max([func_feature(token, *args) for token, dist in tokens])\n",
    "    return np.max([func_feature(token, *args) for token in tokens])\n",
    "\n",
    "def agg_ctx_feat_num_min(tokens, func_feature, *args):\n",
    "    if all(isinstance(tpl, tuple) for tpl in tokens):\n",
    "        return np.min([func_feature(token, *args) for token, dist in tokens])\n",
    "    return np.min([func_feature(token, *args) for token in tokens])\n",
    "\n",
    "def agg_ctx_feat_num_sum(tokens, func_feature, *args):\n",
    "    if all(isinstance(tpl, tuple) for tpl in tokens):\n",
    "        return np.sum([func_feature(token, *args) for token, dist in tokens])\n",
    "    return np.sum([func_feature(token, *args) for token in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_default = [Aggregation('mean', agg_ctx_feat_num_average)]\n",
    "agg_distance = [Aggregation('dist', agg_ctx_feat_num_distance)]\n",
    "agg_weighted = [Aggregation('weighted', agg_feat_num_weighted_average_medium)]\n",
    "aggs_small = [Aggregation('mean', agg_ctx_feat_num_average), Aggregation('max', agg_ctx_feat_num_max)]\n",
    "aggs_all = [Aggregation('mean', agg_ctx_feat_num_average), Aggregation('median', agg_ctx_feat_num_median),\n",
    "            Aggregation('max', agg_ctx_feat_num_max), Aggregation('min', agg_ctx_feat_num_min)]\n",
    "           #Aggregation('weighted_mean', agg_ctx_feat_num_weighted_average_medium)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggs = agg_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_feature_datasets(*args):\n",
    "    zipped = zip(*args)\n",
    "    concat_features = []\n",
    "    for dataset in zipped:\n",
    "        df_train = None\n",
    "        df_test = None\n",
    "        ctxs = []\n",
    "        fcs = []\n",
    "        aggs = []\n",
    "        for tpl in dataset:\n",
    "            if not fcs:\n",
    "                df_train = tpl.train.copy()\n",
    "                df_test = tpl.test.copy()\n",
    "            else:\n",
    "                df_train = pd.concat([df_train, tpl.train.copy()], axis = 1)\n",
    "                df_test = pd.concat([df_test, tpl.test.copy()], axis = 1)\n",
    "            ctxs.append(tpl.context)\n",
    "            fcs.append(tpl.fc)\n",
    "            aggs.append(tpl.agg)\n",
    "        concat_features.append(ContextFeatureDataset(tpl.name, ctxs, fcs, aggs,\n",
    "                    df_train.loc[:,~df_train.columns.duplicated()], \n",
    "                    df_test.loc[:,~df_test.columns.duplicated()]))\n",
    "    return concat_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Context Definition and Extraction\n",
    "Here we compute different kinds of context definitions. For example, as a baseline we extract all tokens from the sentence except the target. A second approach is to use a n preceeding or n succeding tokens, or a combined window apporach were we extract n tokens preceeding and succeding of the target. A more sophisticated apporach involves dependency parsing of the sentence and applying different extraction heuristics. Finally we also implement a context extraction approach exploting FrameNet semantic parsing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Context Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.parse.corenlp import *\n",
    "import os\n",
    "from functools import lru_cache\n",
    "\n",
    "# First make sure that the StanfordCoreNLP Server is running under port 9011\n",
    "# cd to stanfordCoreNLP directory\n",
    "# java -mx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9011 -timeout 15000\n",
    "parser = CoreNLPDependencyParser(url='http://localhost:9011/')\n",
    "\n",
    "with open(\"resources/dictionaries/stopwords_en.txt\", encoding=\"utf8\") as file:\n",
    "    content = [line.strip().lower() for line in file.readlines()]\n",
    "    stop_words = set(content)\n",
    "    \n",
    "def overlaps(start1, end1, start2, end2):\n",
    "    return bool(range(max(start1, start2), min(end1, end2)+1))\n",
    "\n",
    "def post_process_ctx(context, filtering=True):\n",
    "    return [token for token in context if \n",
    "            (token.isalnum() and (not filtering\n",
    "        or preprocess_target(token).lower() not in stop_words))]\n",
    "\n",
    "def preprocess_target(target):\n",
    "    return target.strip()\n",
    "\n",
    "def target_index_char_based(start, end, ctx_tokens):\n",
    "    size = np.sum([len(token) for token in ctx_tokens]) + len(ctx_tokens)\n",
    "    target_pos = (start + end) / 2\n",
    "    target_pos_rel = target_pos / size\n",
    "    return int(target_pos_rel * len(post_process_ctx(ctx_tokens)))\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def targets_with_index(start, end, context):\n",
    "    curr_pos = 0\n",
    "    targets = []\n",
    "    j = 0\n",
    "    w = 0\n",
    "    curr_split = ''\n",
    "    ctx_split = context.split()\n",
    "    whitespaces = re.findall('\\s+', context)\n",
    "    num_whitespaces = [len(token) for token in whitespaces]\n",
    "    num_whitespaces.append(1)\n",
    "    tokens = word_tokenize(context)\n",
    "    tokens = ['\"' if token not in context else token for token in tokens]\n",
    "    for index, token in enumerate(tokens, 1):\n",
    "        targets.append((token, index, curr_pos, (curr_pos + len(token))))\n",
    "        curr_pos += len(token)\n",
    "        curr_split += token\n",
    "        if ctx_split[j] == curr_split:\n",
    "            curr_pos += num_whitespaces[w]\n",
    "            j += 1\n",
    "            w += 1\n",
    "            curr_split = ''\n",
    "    vals = [(target[0], target[1]) for target in targets \\\n",
    "            if overlaps(start, end, target[2], target[3])]\n",
    "    return [val for val in vals if val[0] != '\"']\n",
    "\n",
    "from joblib import Memory\n",
    "memory = Memory(location='resources/dependency-cache-corenlp', verbose=0)\n",
    "@memory.cache\n",
    "def dependency_parse_with_root(sentence):\n",
    "    try:\n",
    "        dependency_parser = parser.raw_parse(sentence)\n",
    "        dependencies = []\n",
    "        parsetree = list(dependency_parser)[0]\n",
    "        for index, node in parsetree.nodes.items():\n",
    "            for relation, dependant in parsetree.nodes[index]['deps'].items():\n",
    "                for dep in dependant:\n",
    "                    triple = ((node['word'], index), relation, \\\n",
    "                              (parsetree.nodes[dep]['word'], dep))\n",
    "                    dependencies.append(triple)\n",
    "        return dependencies\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def dependency_parse(sentence):\n",
    "    dependencies = dependency_parse_with_root(sentence)\n",
    "    filtered_dependencies = [triple for triple in dependencies if triple[1] != 'ROOT']\n",
    "    return filtered_dependencies\n",
    "\n",
    "def ctx_extraction_sentence(context, target):\n",
    "    ctx_tokens = word_tokenize(context)\n",
    "    if target in ctx_tokens:\n",
    "        ctx_tokens.remove(target)\n",
    "    return ctx_tokens\n",
    "\n",
    "def ctx_extraction_sentence_filtered(context, target, start, end, filtering = True):\n",
    "    context = context[:start] + context[end:]\n",
    "    ctx_tokens = word_tokenize(context)\n",
    "    post_ctx_tokens = post_process_ctx(ctx_tokens, filtering)\n",
    "    return ctx_tokens\n",
    "\n",
    "def ctx_extraction_hit(context, filtering = True):\n",
    "    hit_tokens = [token for sentence in context for token in word_tokenize(sentence)]\n",
    "    post_ctx_tokens = post_process_ctx(hit_tokens, filtering)\n",
    "    return post_ctx_tokens\n",
    "\n",
    "def ctx_extraction_window_pre_n(context, target, start, end, \n",
    "                            filtering = True, n = 3, dist = True):\n",
    "    target = preprocess_target(target)\n",
    "    ctx_tokens = word_tokenize(context[:start])\n",
    "    post_ctx_tokens = post_process_ctx(ctx_tokens, filtering)\n",
    "    return [(elem, index) for index, elem in zip(range(n, 0, -1), post_ctx_tokens[-n:])] \\\n",
    "                if dist else post_ctx_tokens[-n:]\n",
    "\n",
    "def ctx_extraction_window_suc_n(context, target, start, end, \n",
    "                            filtering = True, n = 3, dist = True):\n",
    "    target = preprocess_target(target)\n",
    "    ctx_tokens = word_tokenize(context[end:])\n",
    "    post_ctx_tokens = post_process_ctx(ctx_tokens, filtering)\n",
    "    return [(elem, index) for index, elem in zip(range(1, (n+1)), post_ctx_tokens[:n])] \\\n",
    "                if dist else post_ctx_tokens[:n]\n",
    "\n",
    "def ctx_extraction_window_pre_suc_n(context, target, start, end, \n",
    "                                filtering = True, n = 3, dist = True):\n",
    "    ctx_tokens_pre = ctx_extraction_window_pre_n(context, target, start, end, filtering, n, dist)\n",
    "    ctx_tokens_suc = ctx_extraction_window_suc_n(context, target, start, end, filtering, n, dist)\n",
    "    ctx_tokens_pre.extend(ctx_tokens_suc)\n",
    "    return ctx_tokens_pre\n",
    "\n",
    "def ctx_extraction_dep_in(context, target, start, end, dist = True):\n",
    "    target = preprocess_target(target)\n",
    "    targets = targets_with_index(start, end, context)\n",
    "    triples = dependency_parse(context)\n",
    "    selec_tuples = list(set([triple for triple in triples \\\n",
    "                if triple[2] in targets and triple[0] not in targets]))\n",
    "    return [(triple[0][0], np.abs(triple[0][1]-triple[2][1])) for triple in selec_tuples] if dist \\\n",
    "                else [triple[0][0] for triple in selec_tuples]\n",
    "\n",
    "def ctx_extraction_dep_out(context, target, start, end, dist = True):\n",
    "    target = preprocess_target(target)\n",
    "    targets = targets_with_index(start, end, context)\n",
    "    triples = dependency_parse(context)\n",
    "    selec_tuples = list(set([triple for triple in triples \\\n",
    "                if triple[0] in targets and triple[2] not in targets]))\n",
    "    return [(triple[2][0], np.abs(triple[0][1]-triple[2][1])) for triple in selec_tuples] if dist \\\n",
    "                else [triple[2][0] for triple in selec_tuples]\n",
    "\n",
    "def ctx_extraction_dep_in_out(context, target, start, end, dist = True):\n",
    "    ctx_tokens_in = ctx_extraction_dep_in(context, target, start, end, dist)\n",
    "    ctx_tokens_out = ctx_extraction_dep_out(context, target, start, end, dist)\n",
    "    ctx_tokens_in.extend(ctx_tokens_out)\n",
    "    return list(set(ctx_tokens_in))\n",
    "\n",
    "def ctx_extraction_dep_recu_in_n_steps(context, target, start, \n",
    "                            end, n = 2, dist = True):\n",
    "    target = preprocess_target(target)\n",
    "    targets = targets_with_index(start, end, context)\n",
    "    triples = dependency_parse(context)\n",
    "    result_tokens = []\n",
    "    curr_target = targets\n",
    "    for step in range(0, n):\n",
    "        step_result = [triple[0] for triple in triples \n",
    "                       if triple[2] in curr_target]\n",
    "        curr_target = list(set(step_result))\n",
    "        result_tokens.extend(step_result)\n",
    "    mean_target_index = np.mean([tgt[1] for tgt in targets])\n",
    "    unique = list(set([result for result in result_tokens if result not in targets]))\n",
    "    return [(token[0], np.abs(token[1]-mean_target_index))\n",
    "                    for token in unique] if dist \\\n",
    "                else [token[0] for token in unique]\n",
    "\n",
    "def ctx_extraction_dep_recu_out_n_steps(context, target, start, \n",
    "                        end, n = 2, dist = True):\n",
    "    target = preprocess_target(target)\n",
    "    targets = targets_with_index(start, end, context)\n",
    "    triples = dependency_parse(context)\n",
    "    result_tokens = []\n",
    "    curr_target = targets\n",
    "    for step in range(0, n):\n",
    "        step_result = [triple[2] for triple in triples \n",
    "                       if triple[0] in curr_target]\n",
    "        curr_target = list(set(step_result))\n",
    "        result_tokens.extend(step_result)\n",
    "    mean_target_index = np.mean([tgt[1] for tgt in targets])\n",
    "    unique = list(set([result for result in result_tokens if result not in targets]))\n",
    "    return [(token[0], np.abs(token[1]-mean_target_index))\n",
    "                    for token in unique] if dist \\\n",
    "                else [token[0] for token in unique]\n",
    "\n",
    "def ctx_extraction_dep_recu_in_out_n_steps(context, target, start, \n",
    "                            end, n = 2, dist = True):\n",
    "    target = preprocess_target(target)\n",
    "    targets = targets_with_index(start, end, context)\n",
    "    triples = dependency_parse(context)\n",
    "    result_tokens = []\n",
    "    curr_target = targets\n",
    "    for step in range(0, n):\n",
    "        step_result = [triple[2] for triple in triples \n",
    "                       if triple[0] in curr_target]\n",
    "        step_result_out = [triple[0] for triple in triples \n",
    "                       if triple[2] in curr_target]\n",
    "        step_result.extend(step_result_out)\n",
    "        curr_target = list(set(step_result))\n",
    "        result_tokens.extend(step_result)\n",
    "    mean_target_index = np.mean([tgt[1] for tgt in targets])\n",
    "    unique = list(set([result for result in result_tokens if result not in targets]))\n",
    "    return [(token[0], np.abs(token[1]-mean_target_index))\n",
    "                    for token in unique] if dist \\\n",
    "                else [token[0] for token in unique]\n",
    "\n",
    "def ctx_extraction_dep_recu_in_cover(context, target, start, \n",
    "                        end, cover = 0.1, dist = True):\n",
    "    target = preprocess_target(target)\n",
    "    targets = targets_with_index(start, end, context)\n",
    "    triples = dependency_parse(context)\n",
    "    ctx_tokens = word_tokenize(context)\n",
    "    ctx_tokens_post = post_process_ctx(ctx_tokens)\n",
    "    result_tokens = []\n",
    "    curr_target = targets\n",
    "    curr_cover = 0\n",
    "    while curr_cover < cover:\n",
    "        step_result = [triple[0] for triple in triples \n",
    "                       if triple[2] in curr_target]\n",
    "        if set(step_result) == set(curr_target):\n",
    "                break\n",
    "        curr_target = list(set(step_result))\n",
    "        result_tokens.extend(step_result)\n",
    "        curr_cover = len(result_tokens) / len(ctx_tokens_post)\n",
    "    mean_target_index = np.mean([tgt[1] for tgt in targets])\n",
    "    unique = list(set([result for result in result_tokens if result not in targets]))\n",
    "    return [(token[0], np.abs(token[1]-mean_target_index))\n",
    "                    for token in unique] if dist \\\n",
    "                else [token[0] for token in unique]\n",
    "\n",
    "def ctx_extraction_dep_recu_out_cover(context, target, start, \n",
    "                        end, cover = 0.1, dist = True):\n",
    "    target = preprocess_target(target)\n",
    "    targets = targets_with_index(start, end, context)\n",
    "    triples = dependency_parse(context)\n",
    "    ctx_tokens = word_tokenize(context)\n",
    "    ctx_tokens_post = post_process_ctx(ctx_tokens)\n",
    "    result_tokens = []\n",
    "    curr_target = targets\n",
    "    curr_cover = 0\n",
    "    while curr_cover < cover:\n",
    "        step_result = [triple[2] for triple in triples \n",
    "                       if triple[0] in curr_target]\n",
    "        if set(step_result) == set(curr_target):\n",
    "                break\n",
    "        curr_target = list(set(step_result))\n",
    "        result_tokens.extend(step_result)\n",
    "        curr_cover = len(result_tokens) / len(ctx_tokens_post)\n",
    "    mean_target_index = np.mean([tgt[1] for tgt in targets])\n",
    "    unique = list(set([result for result in result_tokens if result not in targets]))\n",
    "    return [(token[0], np.abs(token[1]-mean_target_index))\n",
    "                    for token in unique] if dist \\\n",
    "                else [token[0] for token in unique]\n",
    "\n",
    "def ctx_extraction_dep_recu_in_out_cover(context, target, start,\n",
    "                        end, cover = 0.1, dist = True):\n",
    "    target = preprocess_target(target)\n",
    "    targets = targets_with_index(start, end, context)\n",
    "    triples = dependency_parse(context)\n",
    "    ctx_tokens = word_tokenize(context)\n",
    "    ctx_tokens_post = post_process_ctx(ctx_tokens)\n",
    "    result_tokens = []\n",
    "    curr_target = targets\n",
    "    curr_cover = 0\n",
    "    while curr_cover < cover:\n",
    "        step_result = [triple[2] for triple in triples \n",
    "                       if triple[0] in curr_target]\n",
    "        step_result_out = [triple[0] for triple in triples \n",
    "                       if triple[2] in curr_target]\n",
    "        step_result.extend(step_result_out)\n",
    "        if set(step_result) == set(curr_target):\n",
    "                break\n",
    "        curr_target = list(set(step_result))\n",
    "        result_tokens.extend(step_result)\n",
    "        curr_cover = len(result_tokens) / len(ctx_tokens_post)\n",
    "    mean_target_index = np.mean([tgt[1] for tgt in targets])\n",
    "    unique = list(set([result for result in result_tokens if result not in targets]))\n",
    "    return [(token[0], np.abs(token[1]-mean_target_index))\n",
    "                    for token in unique] if dist \\\n",
    "                else [token[0] for token in unique]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Normally, the land will be passed down by future generations in a way \" + \\\n",
    "             \"that recognizes the community's traditional connection to that country .\"\n",
    "target = 'passed'\n",
    "\n",
    "print('ctx_etraction_all:')\n",
    "print(ctx_extraction_sentence_filtered(sentence, target, 28, 34,))\n",
    "\n",
    "print('ctx_extraction_window_pre_n:')\n",
    "print(ctx_extraction_window_pre_n(sentence, \"Normally\", 0, 8, filtering=False))\n",
    "print(ctx_extraction_window_pre_n(sentence, \"the\", 11, 14, filtering=False))\n",
    "print(ctx_extraction_window_pre_n(sentence, \"land\", 15, 19, filtering=False))\n",
    "print(ctx_extraction_window_pre_n(sentence, \"to\", 126, 128, filtering=False))\n",
    "print(ctx_extraction_window_pre_n(sentence, target, 28, 34, n = 5, filtering=False))\n",
    "\n",
    "print('ctx_extraction_window_suc_n:')\n",
    "print(ctx_extraction_window_suc_n(sentence, \"country\", 135, 142, filtering=False))\n",
    "print(ctx_extraction_window_suc_n(sentence, \"to\", 126, 128, filtering=False))\n",
    "print(ctx_extraction_window_suc_n(sentence, \"connection\", 115, 125, filtering=False))\n",
    "print(ctx_extraction_window_suc_n(sentence, \"community\", 91, 100, n = 5, filtering=False))\n",
    "\n",
    "print('ctx_extraction_window_pre_suc_n:')\n",
    "print(ctx_extraction_window_pre_suc_n(sentence, \"passed\", 28, 34, filtering=False))\n",
    "print(ctx_extraction_window_pre_suc_n(sentence, \"the\", 11, 14, filtering=False))\n",
    "print(ctx_extraction_window_pre_suc_n(sentence, \"to\", 127, 129, filtering=False))\n",
    "\n",
    "print('ctx_extraction_dep_in:')\n",
    "print(ctx_extraction_dep_in(sentence, \"land\", 15, 19))\n",
    "\n",
    "print('ctx_extraction_dep_out:')\n",
    "print(ctx_extraction_dep_out(sentence, target, 28, 34))\n",
    "print(ctx_extraction_dep_out(sentence, \"land\", 15, 19))\n",
    "\n",
    "print('ctx_extraction_dep_in_out:')\n",
    "print(ctx_extraction_dep_in_out(sentence, \"land\", 15, 19))\n",
    "\n",
    "print('ctx_extraction_dep_recu_in_n_steps:')\n",
    "print(ctx_extraction_dep_recu_in_n_steps(sentence, \"the\", 11, 14, n = 3))\n",
    "\n",
    "print('ctx_extraction_dep_recu_out_n_steps:')\n",
    "print(ctx_extraction_dep_recu_out_n_steps(sentence, \"the\", 11, 14))\n",
    "\n",
    "print('ctx_extraction_dep_recu_in_out_n_steps:')\n",
    "print(ctx_extraction_dep_recu_in_out_n_steps(sentence, \"the\", 11, 14))\n",
    "\n",
    "print('ctx_extraction_dep_recu_in_cover:')\n",
    "print(ctx_extraction_dep_recu_in_cover(sentence, \"the\", 11, 14, cover=0.1))\n",
    "\n",
    "print('ctx_extraction_dep_recu_out_cover:')\n",
    "print(ctx_extraction_dep_recu_out_cover(sentence, \"the\", 11, 14, cover=0.1))\n",
    "\n",
    "print('ctx_extraction_dep_recu_in_out_cover:')\n",
    "print(ctx_extraction_dep_recu_in_out_cover(sentence, \"the\", 11, 14, cover=0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Context Extraction\n",
    "\n",
    "After we defined all the context extraction approaches, we can apply them on the actual dataset. To do so, we first extract all the distinct sentences from the actual training set and create a new dataframe containing only the sentence ids, the sentence, the target and all the computed contexts. This also makes it easier to integrate context extraction functions implemented in other languages. Afterwards we can compute the context features and join them back with the target features dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Context = namedtuple('Context', 'name, params, func')\n",
    "ContextFeatureCategory = namedtuple('ContextFeatureCategory', 'name, func')\n",
    "ContextDataset = namedtuple('ContextDataset', 'name, context, train, test')\n",
    "ContextFeatureDataset = namedtuple('ContextFeatureDataset', 'name, context, fc, agg, train, test')\n",
    "ctx_fcs = []\n",
    "ctx_feature_datasets = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3.2.1) Extraction functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctx_window(dataframe, n, filtering, window_func):\n",
    "    df = dataframe.copy()\n",
    "    df['context'] = df.apply(lambda columns : \n",
    "                window_func(columns['sentence'], columns['target'], \\\n",
    "                columns['start'], columns['end'],  n = n, filtering = filtering), axis = 1)\n",
    "    return df\n",
    "\n",
    "ctx_window_pre_2_nf = Context('ctx_window_pre_n', {'n':2, 'filtering':False}, \\\n",
    "                              lambda dataframe : ctx_window(dataframe, 2, False, ctx_extraction_window_pre_n))\n",
    "ctx_window_pre_2_f = Context('ctx_window_pre_n', {'n':2, 'filtering':True}, \\\n",
    "                             lambda dataframe : ctx_window(dataframe, 2, True, ctx_extraction_window_pre_n))\n",
    "ctx_window_suc_n_2_nf = Context('ctx_window_suc_n',  {'n':2, 'filtering':False}, \\\n",
    "                            lambda dataframe : ctx_window(dataframe, 2, False, ctx_extraction_window_suc_n))\n",
    "ctx_window_pre_suc_n_2_nf = Context('ctx_window_pre_suc_n',  {'n':2, 'filtering':False}, \\\n",
    "                            lambda dataframe : ctx_window(dataframe, 2, False, ctx_extraction_window_pre_suc_n))\n",
    "ctx_window_pre_suc_n_2_f = Context('ctx_window_pre_suc_n',  {'n':2, 'filtering':True}, \\\n",
    "                            lambda dataframe : ctx_window(dataframe, 2, True, ctx_extraction_window_pre_suc_n))\n",
    "ctx_window_pre_suc_n_3_f = Context('ctx_window_pre_suc_n',  {'n':3, 'filtering':True}, \\\n",
    "                            lambda dataframe : ctx_window(dataframe, 3, True, ctx_extraction_window_pre_suc_n))\n",
    "ctx_window_pre_suc_n_4_f = Context('ctx_window_pre_suc_n',  {'n':4, 'filtering':True}, \\\n",
    "                            lambda dataframe : ctx_window(dataframe, 4, True, ctx_extraction_window_pre_suc_n))\n",
    "ctx_window_pre_suc_n_5_f = Context('ctx_window_pre_suc_n',  {'n':5, 'filtering':True}, \\\n",
    "                            lambda dataframe : ctx_window(dataframe, 5, True, ctx_extraction_window_pre_suc_n))\n",
    "\n",
    "\n",
    "\n",
    "def ctx_dependency(dataframe, filtering, dep_func):\n",
    "    df = dataframe.copy()\n",
    "    df['context'] = df.apply(lambda columns : \n",
    "            dep_func(columns['sentence'], columns['target'], \\\n",
    "            columns['start'], columns['end']), axis = 1)\n",
    "    return df\n",
    "\n",
    "ctx_dep_in_2_nf = Context('ctx_dep_in', {'n':2, 'filtering':False}, \\\n",
    "                              lambda dataframe : ctx_dependency(dataframe, False, ctx_extraction_dep_in))\n",
    "ctx_dep_out_2_nf = Context('ctx_dep_out', {'n':2, 'filtering':False}, \\\n",
    "                              lambda dataframe : ctx_dependency(dataframe, False, ctx_extraction_dep_out))\n",
    "ctx_dep_in_out_2_nf = Context('ctx_dep_in_out', {'n':2, 'filtering':False}, \\\n",
    "                              lambda dataframe : ctx_dependency(dataframe, False, ctx_extraction_dep_in_out))\n",
    "\n",
    "ctx_dep_in_2_f = Context('ctx_dep_in', {'filtering':True}, \\\n",
    "                              lambda dataframe : ctx_dependency(dataframe, True, ctx_extraction_dep_in))\n",
    "ctx_dep_out_2_f = Context('ctx_dep_out', {'filtering':True}, \\\n",
    "                              lambda dataframe : ctx_dependency(dataframe, True, ctx_extraction_dep_out))\n",
    "ctx_dep_in_out_2_f = Context('ctx_dep_in_out', {'filtering':True}, \\\n",
    "                              lambda dataframe : ctx_dependency(dataframe, True, ctx_extraction_dep_in_out))\n",
    "\n",
    "\n",
    "\n",
    "def ctx_dependency_recu_steps(dataframe, n, filtering, dep_func):\n",
    "    df = dataframe.copy()\n",
    "    df['context']  = df.apply(lambda columns : \n",
    "                dep_func(columns['sentence'], columns['target'], \\\n",
    "                columns['start'], columns['end'], n=n), axis = 1)\n",
    "    return df\n",
    "\n",
    "ctx_dep_rec_in_2_nf = Context('ctx_dep_rec_in_n', {'n':2, 'filtering':False}, \\\n",
    "                lambda dataframe : ctx_dependency_recu_steps(dataframe, 2, False, ctx_extraction_dep_recu_in_n_steps))\n",
    "ctx_dep_rec_out_2_nf = Context('ctx_dep_rec_out_n', {'n':2, 'filtering':False}, \\\n",
    "                lambda dataframe : ctx_dependency_recu_steps(dataframe, 2, False, ctx_extraction_dep_recu_out_n_steps))\n",
    "ctx_dep_rec_in_out_2_nf = Context('ctx_dep_rec_in_out_n', {'n':2, 'filtering':False}, \\\n",
    "                lambda dataframe : ctx_dependency_recu_steps(dataframe, 2, False, ctx_extraction_dep_recu_in_out_n_steps))\n",
    "\n",
    "\n",
    "\n",
    "def ctx_dependency_recu_cover(dataframe, cover, filtering, dep_func):\n",
    "    df = dataframe.copy()\n",
    "    df['context']  = df.apply(lambda columns : \n",
    "                dep_func(columns['sentence'], columns['target'], \\\n",
    "                columns['start'], columns['end'], cover=cover), axis = 1)\n",
    "    return df\n",
    "\n",
    "ctx_dep_rec_in_02_nf = Context('ctx_dep_rec_in_02', {'cover': 0.2, 'filtering':False}, \\\n",
    "                lambda dataframe : ctx_dependency_recu_cover(dataframe, 0.2, False, ctx_extraction_dep_recu_in_cover))\n",
    "ctx_dep_rec_out_02_nf = Context('ctx_dep_rec_out_02', {'cover': 0.2, 'filtering':False}, \\\n",
    "                lambda dataframe : ctx_dependency_recu_cover(dataframe, 0.2, False, ctx_extraction_dep_recu_out_cover))\n",
    "ctx_dep_rec_in_out_02_nf = Context('ctx_dep_rec_in_out_02', {'cover': 0.2, 'filtering':False}, \\\n",
    "                lambda dataframe : ctx_dependency_recu_cover(dataframe, 0.2, False, ctx_extraction_dep_recu_in_out_cover))\n",
    "\n",
    "\n",
    "\n",
    "def ctx_sentence(dataframe, filtering):\n",
    "    df = dataframe.copy()\n",
    "    df['context']  = df.apply(lambda columns : \n",
    "                ctx_extraction_sentence_filtered(columns['sentence'], columns['target'], \\\n",
    "                columns['start'], columns['end'], filtering=filtering), axis = 1)\n",
    "    return df\n",
    "\n",
    "ctx_sentence_nf = Context('ctx_sentence', {'filtering':False}, lambda dataframe : ctx_sentence(dataframe, False))\n",
    "\n",
    "\n",
    "\n",
    "def ctx_hit(dataframe, filtering):\n",
    "    df = dataframe.copy()\n",
    "    df = df.join(df.groupby('id')['sentence'].apply(lambda sentences : \\\n",
    "                    tuple(ctx_extraction_hit(list(set(sentences))))), on='id', rsuffix='_hits')\n",
    "    df['sentence_hits'] = df.sentence_hits.apply(lambda hits : list(hits))\n",
    "    df.rename(columns={'sentence_hits':'context'}, inplace=True)\n",
    "    return df\n",
    "\n",
    "ctx_hit_nf = Context('ctx_sentence', {'filtering':False}, lambda dataframe : ctx_hit(dataframe, False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3.2.2) Context Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "import sys\n",
    "\n",
    "tbl = dict.fromkeys(i for i in range(sys.maxunicode)\n",
    "                      if unicodedata.category(chr(i)).startswith('P'))\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(tbl)\n",
    "\n",
    "def preprocess_ctx(context):\n",
    "    if all(isinstance(tpl, tuple) for tpl in context):\n",
    "        stripped = [(token.strip().lower(), dist) for token, dist in context]\n",
    "        return [(token, dist) for token, dist in stripped if remove_punctuation(token)]\n",
    "    stripped = [token.strip().lower() for token in context]\n",
    "    return [token for token in stripped if remove_punctuation(token)]\n",
    "\n",
    "def preprocess_ctx_df(dataframe):\n",
    "    df = dataframe.copy()\n",
    "    df['p_context_dist'] = df.context.apply(lambda context : preprocess_ctx(context))\n",
    "    df['p_context'] = df.context.apply(lambda context : [token for token, dist in preprocess_ctx(context)] \\\n",
    "                                      if all(isinstance(tpl, tuple) for tpl in context) else preprocess_ctx(context))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts = [ctx_window_pre_suc_n_2_f,ctx_window_pre_suc_n_3_f,ctx_window_pre_suc_n_4_f,ctx_window_pre_suc_n_5_f, \\\n",
    "           ctx_dep_in_2_f, ctx_dep_out_2_f, ctx_dep_in_out_2_f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx_datasets = [ContextDataset(ds.name, ctx, preprocess_ctx_df(ctx.func(ds.train)), \n",
    "                preprocess_ctx_df(ctx.func(ds.test)))\n",
    "                for ctx in contexts\n",
    "                for ds in datasets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Context Features\n",
    "After defining all the context definitions and extracting the different kinds of contexts from the sentence, we compute features on the context words. Therefore we first define which of the precomputed contexts to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4.1) Context (Aggregated Word-Level) Complexity Features\n",
    "Here we compute features that measure the complexity of the extracted context itself. These features are divded into two categories. First, we compute the most important target features as found in the other notebook on feature importance on the context. The target features are already adapted to MWE, which makes it straightforward to apply them to context of any length and apply proper aggregation. Second, we compute features that are computed on the context alone as, for example, several traditional readability metrics and the number of characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordmodel import Word\n",
    "\n",
    "words_mrc_database = {}\n",
    "with open(\"resources/mrc-database/mrc2.dct\", encoding=\"utf8\") as file:\n",
    "    for index, line in enumerate(file):\n",
    "        line = line.strip()\n",
    "        word, phon, dphon, stress = line[51:].split('|')\n",
    "        w = Word(\n",
    "                wid = index,\n",
    "                nlet = int(line[0:2]),\n",
    "                nphon = int(line[2:4]),\n",
    "                nsyl = int(line[4]),\n",
    "                kf_freq = int(line[5:10]),\n",
    "                kf_ncats = int(line[10:12]),\n",
    "                kf_nsamp = int(line[12:15]),\n",
    "                tl_freq = int(line[15:21]),\n",
    "                brown_freq = int(line[21:25]),\n",
    "                fam = int(line[25:28]),\n",
    "                conc = int(line[28:31]),\n",
    "                imag = int(line[31:34]),\n",
    "                meanc = int(line[34:37]),\n",
    "                meanp = int(line[37:40]),\n",
    "                aoa = int(line[40:43]),\n",
    "                tq2 = line[43],\n",
    "                wtype = line[44],\n",
    "                pdwtype = line[45],\n",
    "                alphasyl = line[46],\n",
    "                status = line[47],\n",
    "                var = line[48],\n",
    "                cap = line[49],\n",
    "                irreg = line[50],\n",
    "                word=word,\n",
    "                phon=phon,\n",
    "                dphon=dphon,\n",
    "                stress=stress)\n",
    "        words_mrc_database[w.word.strip().lower()] = w\n",
    "\n",
    "def mrc_database(target, func, missing_val):\n",
    "    word = words_mrc_database.get(target.strip().lower())\n",
    "    val = func(word) if word else missing_val\n",
    "    return val if val != 0 else missing_val\n",
    "\n",
    "word_concreteness = {}\n",
    "with open(\"resources/word-freq-dumps/concreteness_brysbaert_et_al.txt\", encoding=\"utf8\") as file:\n",
    "    for line in file:\n",
    "        word, bigram, conc_m, conc_sd, \\\n",
    "        unknown, total, percent_known, \\\n",
    "        subtlex, dom_pos = line.split('\\t')\n",
    "        word_concreteness[word.strip()] = float(conc_m)\n",
    "\n",
    "word_freq_wiki = {}\n",
    "freq_sum_wiki = 0\n",
    "with open(\"resources/word-freq-dumps/enwiki-20150602-words-frequency.txt\", encoding=\"utf8\") as file:\n",
    "    for line in file:\n",
    "        word, freq = line.partition(\" \")[::2]\n",
    "        word_freq_wiki[word.strip()] = int(freq)\n",
    "        freq_sum_wiki+=int(freq)\n",
    "        \n",
    "def get_dict_count(target, freqs):\n",
    "    return freqs.get(target.strip().lower(), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctx_features_context_complexity_from_target(dataframe, agg):\n",
    "    df = dataframe.copy()\n",
    "    df['ctx_length'] = df.p_context.apply(lambda context : agg(context, len))\n",
    "    df['ctx_freq_wiki'] = df.p_context.apply(lambda context : agg(context, get_dict_count, word_freq_wiki))\n",
    "    df['ctx_mrc_fam'] = df.p_context.apply(lambda target : agg(target, mrc_database, lambda word : word.fam, 400))\n",
    "    df['ctx_mrc_conc'] = df.p_context.apply(lambda target : agg(target, mrc_database, lambda word : word.conc, 400))\n",
    "    df['ctx_mrc_imag'] = df.p_context.apply(lambda target : agg(target, mrc_database, lambda word : word.imag, 400))\n",
    "    df['ctx_mrc_meanc'] = df.p_context.apply(lambda target : agg(target, mrc_database, lambda word : word.meanc, 400))\n",
    "    df['ctx_concreteness'] = df.p_context.apply(lambda target : agg(target, \\\n",
    "                                                lambda target : word_concreteness.get(target, 2.5)))\n",
    "    df = df.fillna(0)\n",
    "    return df\n",
    "\n",
    "ctx_fc_context_complexity_from_target = ContextFeatureCategory('context_complexity_from_target', \\\n",
    "                                ctx_features_context_complexity_from_target)\n",
    "feature_categories.append(ctx_fc_context_complexity_from_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx_datasets_fc_context_complexity_from_target = [ContextFeatureDataset(ctx_ds.name, ctx_ds.context, \n",
    "        ctx_fc_context_complexity_from_target, agg, ctx_fc_context_complexity_from_target.func(ctx_ds.train, agg.agg),\n",
    "        ctx_fc_context_complexity_from_target.func(ctx_ds.test, agg.agg)) \n",
    "        for ctx_ds in ctx_datasets for agg in agg_distance]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4.2) Context-only Complexity Features\n",
    "Here we compute features that measure the complexity of the extracted context itself. These features are divded into two categories. First, we compute the most important target features as found in the other notebook on feature importance on the context. The target features are already adapted to MWE, which makes it straightforward to apply them to context of any length and apply proper aggregation. Second, we compute features that are computed on the context alone as, for example, several traditional readability metrics and the number of characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Studio\\Anaconda3\\lib\\site-packages\\gensim-3.5.0-py3.6-win-amd64.egg\\gensim\\utils.py:1209: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model : glove.6B.50d.txt\n",
      "load model : glove.6B.300d.txt\n",
      "[Model(type='glove', name='glove.6B.50d.txt', dimension=50, corpus='wikipedia+gigaword5', model=<gensim.models.keyedvectors.Word2VecKeyedVectors object at 0x000000FC09E03978>), Model(type='glove', name='glove.6B.300d.txt', dimension=300, corpus='wikipedia+gigaword5', model=<gensim.models.keyedvectors.Word2VecKeyedVectors object at 0x000000FC5C5AF6D8>)]\n"
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "MAIN_PATH = 'D:/workspace_python/CoWoReId/python/resources/word-embeddings/'\n",
    "\n",
    "glove_defs = [#Model('glove', 'glove.42B.300d.txt', 300, 'cc42B', None),  \n",
    "              #Model('glove', 'glove.840B.300d.txt', 300, 'cc840B', None), \n",
    "              Model('glove', 'glove.6B.50d.txt', 50, 'wikipedia+gigaword5', None),\n",
    "              #Model('glove', 'glove.6B.100d.txt',100, 'wikipedia+gigaword5', None),\n",
    "              #Model('glove', 'glove.6B.200d.txt', 200, 'wikipedia+gigaword5', None), \n",
    "              Model('glove', 'glove.6B.300d.txt', 300, 'wikipedia+gigaword5', None)]\n",
    "              #Model('glove', 'glove.twitter.27B.25d.txt', 25, 'twitter', None)]\n",
    "              #Model('glove', 'glove.twitter.27B.50d.txt', 50, 'twitter', None), \n",
    "              #Model('glove', 'glove.twitter.27B.100d.txt', 100, 'twitter', None), \n",
    "              #Model('glove', 'glove.twitter.27B.200d.txt', 200, 'twitter', None)]\n",
    "\n",
    "glove_models = []\n",
    "for model in glove_defs:\n",
    "    glove_file = datapath(MAIN_PATH + model.name)\n",
    "    tmp_file = get_tmpfile(model.name + '-temp')\n",
    "    glove2word2vec(glove_file, tmp_file)\n",
    "    vecs = KeyedVectors.load_word2vec_format(tmp_file)\n",
    "    glove_models.append(Model(model.type, model.name, model.dimension, model.corpus, vecs))\n",
    "    print('load model : {}'.format(model.name))\n",
    "    \n",
    "print(glove_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = glove_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ngram_representation import ngram_repr_bow_max\n",
    "from ngram_representation import ngram_repr_wiki_weighted_bow\n",
    "from ngram_representation import ngram_repr_bow_min\n",
    "from ngram_representation import missing_strat_random\n",
    "\n",
    "def word_embedding_ngram_repr(target, model, missing_strat, ngram_repr, *args):\n",
    "    tokens = word_tokenize(target)\n",
    "    if len(tokens) > 1:\n",
    "        # First construct multi-word query\n",
    "        query = '_'.join(tokens)\n",
    "        if query in model.vocab:\n",
    "            return model[query]\n",
    "        query = '_'.join([token.strip().lower() for token in tokens])\n",
    "        if query in model.vocab:\n",
    "            return model[query]\n",
    "        all_embeddings = [model[word.strip().lower()] \n",
    "                              if word.strip().lower() in model.vocab \n",
    "                              else missing_strat(word, model.vector_size) \n",
    "                              for word in tokens]\n",
    "        return ngram_repr(all_embeddings, tokens)\n",
    "    else:\n",
    "        if target in model.vocab:\n",
    "            return ngram_repr(model[target], [target])\n",
    "        else:\n",
    "            return ngram_repr(model[target.strip().lower()], [target]) \\\n",
    "                if target.strip().lower() in model.vocab \\\n",
    "                else ngram_repr([missing_strat(target, model.vector_size)], [target])\n",
    "\n",
    "def cosine_similarity(vec_l, vec_r):\n",
    "    return np.dot(vec_l,vec_r) / (np.linalg.norm(vec_l) \\\n",
    "                * np.linalg.norm(vec_r))\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def ctx_target_embed_cos_sims(context, target, model):\n",
    "    ngram_repr = ngram_repr_bow_max\n",
    "    missing_strat = missing_strat_random\n",
    "    embed_target = word_embedding_ngram_repr(target, model, missing_strat, ngram_repr)\n",
    "    embed_contexts = [word_embedding_ngram_repr(ctx, model, \n",
    "                        missing_strat_random, ngram_repr) for ctx in context]\n",
    "    return [cosine_similarity(embed_target, ctx_embed) for ctx_embed in embed_contexts]\n",
    "\n",
    "def ctx_target_embed_cos_max(context, target, model):\n",
    "    cos_sims = ctx_target_embed_cos_sims(tuple(context), target, model)\n",
    "    return np.min(cos_sims) if cos_sims else 0\n",
    "\n",
    "def ctx_target_embed_cos_min(context, target, model):\n",
    "    cos_sims = ctx_target_embed_cos_sims(tuple(context), target, model)\n",
    "    return np.max(cos_sims) if cos_sims else 0\n",
    "\n",
    "def ctx_target_embed_cos_mean(context, target, model):\n",
    "    cos_sims = ctx_target_embed_cos_sims(tuple(context), target, model)\n",
    "    return np.mean(cos_sims) if cos_sims else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26700908"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx_target_embed_cos_mean(['comic'], 'theater', models[1].model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.027261626"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx_target_embed_cos_mean(['rain'], 'theater', models[1].model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33071867"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx_target_embed_cos_mean(['film', 'radio', 'television'], 'theater', models[1].model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33359954"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx_target_embed_cos_mean(['skin'], 'covered', models[1].model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25853682"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx_target_embed_cos_mean(['song'], 'covered', models[1].model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textatistic import Textatistic\n",
    "    \n",
    "def ctx_features_context_complexity_from_context(dataframe, agg):\n",
    "    df = dataframe.copy()\n",
    "    df['ctx_len_chars'] = df.p_context.apply(lambda context : np.sum([len(word) for word in context]))\n",
    "    df['ctx_len_words'] = df.p_context.apply(lambda context : len(context))\n",
    "    df['ctx_norm_chars'] = df.ctx_len_chars / df.ctx_len_words\n",
    "#     df['ctx_rb_dalechall_score'] = df.p_context.apply(lambda context : \\\n",
    "#                             Textatistic(' '.join(context) + '.').dalechall_score if context else 7)\n",
    "#     df['ctx_rb_flesch_score'] = df.p_context.apply(lambda context : \\\n",
    "#                             Textatistic(' '.join(context) + '.').flesch_score if context else 50)\n",
    "#     df['ctx_rb_fleschkincaid_score'] = df.p_context.apply(lambda context : \\\n",
    "#                             Textatistic(' '.join(context) + '.').fleschkincaid_score if context else 50)\n",
    "#     df['ctx_rb_gunningfog_score'] = df.p_context.apply(lambda context : \\\n",
    "#                             Textatistic(' '.join(context) + '.').gunningfog_score if context else 14)\n",
    "#     df['ctx_rb_polysyblword_count'] = df.p_context.apply(lambda context : \\\n",
    "#                             Textatistic(' '.join(context) + '.').polysyblword_count if context else 0)\n",
    "#     df['ctx_rb_sybl_count'] = df.p_context.apply(lambda context : \\\n",
    "#                             Textatistic(' '.join(context) + '.').sybl_count if context else 0)\n",
    "#     df['ctx_rb_sybl_count_ratio'] = df.p_context.apply(lambda context : \\\n",
    "#                             Textatistic(' '.join(context) + '.').sybl_count / len(context) if context else 0)\n",
    "    df['ctx_target_embed_cos_glove_300_min'] = df[['p_context', 'p_target']].apply(lambda vals : \\\n",
    "                                                        ctx_target_embed_cos_min(*vals, models[0].model), axis=1)\n",
    "    df['ctx_target_embed_cos_glove_300_max'] = df[['p_context', 'p_target']].apply(lambda vals : \\\n",
    "                                                        ctx_target_embed_cos_max(*vals, models[0].model), axis=1)\n",
    "    df['ctx_target_embed_cos_glove_300_mean'] = df[['p_context', 'p_target']].apply(lambda vals : \\\n",
    "                                                        ctx_target_embed_cos_mean(*vals, models[0].model), axis=1)\n",
    "    df = df.fillna(0)\n",
    "    return df\n",
    "\n",
    "ctx_fc_context_complexity_from_context = ContextFeatureCategory('context_complexity_from_context', \\\n",
    "                                ctx_features_context_complexity_from_context)\n",
    "feature_categories.append(ctx_fc_context_complexity_from_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx_datasets_fc_context_complexity_from_context = [ContextFeatureDataset(ctx_ds.name, ctx_ds.context, \n",
    "        ctx_fc_context_complexity_from_context, agg, ctx_fc_context_complexity_from_context.func(ctx_ds.train, agg.agg),\n",
    "        ctx_fc_context_complexity_from_context.func(ctx_ds.test, agg.agg)) \n",
    "        for ctx_ds in ctx_datasets for agg in aggs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx_fc_context_complexity = ContextFeatureCategory('context_complexity', \\\n",
    "                        [ctx_fc_context_complexity_from_target, ctx_fc_context_complexity_from_context])\n",
    "ctx_datasets_fc_context_complexity = [ContextFeatureDataset(ds.name, ds.context, ctx_fc_context_complexity, ds.agg,\n",
    "            ds.train, ds.test) for ds in concat_feature_datasets(ctx_datasets_fc_context_complexity_from_target, \n",
    "                            ctx_datasets_fc_context_complexity_from_context)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>target</th>\n",
       "      <th>nat</th>\n",
       "      <th>non_nat</th>\n",
       "      <th>nat_marked</th>\n",
       "      <th>non_nat_marked</th>\n",
       "      <th>binary</th>\n",
       "      <th>prob</th>\n",
       "      <th>p_target</th>\n",
       "      <th>pos_tags</th>\n",
       "      <th>pos_tags_pt</th>\n",
       "      <th>lemma</th>\n",
       "      <th>p_lemma</th>\n",
       "      <th>wn_synset_freq</th>\n",
       "      <th>wn_synset_avg_lemma_freq</th>\n",
       "      <th>wn_synset_avg_lemma_len</th>\n",
       "      <th>wn_synset_diff_len_avg_lemma_len</th>\n",
       "      <th>wn_synset_avg_hypernyms</th>\n",
       "      <th>wn_synset_sum_hypernyms</th>\n",
       "      <th>wn_synset_avg_hyponyms</th>\n",
       "      <th>wn_synset_avg_definition_len</th>\n",
       "      <th>wn_synset_avg_hyptree_depth</th>\n",
       "      <th>wn_synset_num_distinct_pos</th>\n",
       "      <th>wn_synset_avg_num_relations</th>\n",
       "      <th>wn_synset_avg_freq_pos_noun</th>\n",
       "      <th>wn_synset_avg_freq_pos_verb</th>\n",
       "      <th>wn_synset_avg_freq_pos_adj</th>\n",
       "      <th>wn_synset_avg_freq_pos_adv</th>\n",
       "      <th>wn_synset_avg_freq_pos_noun_norm</th>\n",
       "      <th>wn_synset_avg_freq_pos_verb_norm</th>\n",
       "      <th>wn_synset_avg_freq_pos_adj_norm</th>\n",
       "      <th>wn_synset_avg_freq_pos_adv_norm</th>\n",
       "      <th>wn_synset_sense_entropy_uniform</th>\n",
       "      <th>wn_synset_sense_entropy_pos_uniform</th>\n",
       "      <th>wn_synsets_sense_entropy_pos_central</th>\n",
       "      <th>wn_synset_pos_ratio_1</th>\n",
       "      <th>wn_synset_pos_ratio_2</th>\n",
       "      <th>swn_avg_objective_score</th>\n",
       "      <th>wn_synsets_freq_ratio_to_max_agg_min</th>\n",
       "      <th>wn_synsets_freq_ratio_to_max_agg_mean</th>\n",
       "      <th>wn_synsets_freq_ratio_to_max_agg_median</th>\n",
       "      <th>wn_synsets_avg_lemma_freq</th>\n",
       "      <th>wn_synsets_freq_ratio_to_avg</th>\n",
       "      <th>wn_synset_lesk_wsd_ratio_hi_freq</th>\n",
       "      <th>wn_synset_lesk_wsd_ratio_low_freq</th>\n",
       "      <th>wn_synset_lesk_wsd_ratio_hi_nopos_freq</th>\n",
       "      <th>wn_synset_lesk_wsd_ratio_low_nopos_freq</th>\n",
       "      <th>wn_synset_lesk_wsd_ratio_hi_freq_sum</th>\n",
       "      <th>wn_synset_lesk_wsd_ratio_low_freq_sum</th>\n",
       "      <th>wn_synset_lesk_wsd_ratio_to_freq_sum</th>\n",
       "      <th>wn_synset_lesk_wsd__norm_sense_rank</th>\n",
       "      <th>p_sentence</th>\n",
       "      <th>context</th>\n",
       "      <th>p_context_dist</th>\n",
       "      <th>p_context</th>\n",
       "      <th>ctx_length</th>\n",
       "      <th>ctx_freq_wiki</th>\n",
       "      <th>ctx_mrc_fam</th>\n",
       "      <th>ctx_mrc_conc</th>\n",
       "      <th>ctx_mrc_imag</th>\n",
       "      <th>ctx_mrc_meanc</th>\n",
       "      <th>ctx_concreteness</th>\n",
       "      <th>ctx_len_chars</th>\n",
       "      <th>ctx_len_words</th>\n",
       "      <th>ctx_norm_chars</th>\n",
       "      <th>ctx_target_embed_cos_glove_300_min</th>\n",
       "      <th>ctx_target_embed_cos_glove_300_max</th>\n",
       "      <th>ctx_target_embed_cos_glove_300_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>3WJGKMRWVIAGMQCINAUOJA1MQ5XDCL</td>\n",
       "      <td>La India covered the song on her album , Sobre el Fuego as her third single from the album .</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>covered</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>covered</td>\n",
       "      <td>[VBD]</td>\n",
       "      <td>[v]</td>\n",
       "      <td>cover</td>\n",
       "      <td>cover</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.259259</td>\n",
       "      <td>6.377049</td>\n",
       "      <td>-0.622951</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>24.0</td>\n",
       "      <td>4.444444</td>\n",
       "      <td>46.481481</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.754888</td>\n",
       "      <td>0.228538</td>\n",
       "      <td>4.70044</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.957143</td>\n",
       "      <td>0.930556</td>\n",
       "      <td>0.457309</td>\n",
       "      <td>0.14524</td>\n",
       "      <td>0.14524</td>\n",
       "      <td>102539.393443</td>\n",
       "      <td>0.684943</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.973718</td>\n",
       "      <td>0.026282</td>\n",
       "      <td>0.792295</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>la india covered the song on her album , sobre el fuego as her third single from the album .</td>\n",
       "      <td>[(La, 2), (India, 1), (song, 1), (album, 2)]</td>\n",
       "      <td>[(la, 2), (india, 1), (song, 1), (album, 2)]</td>\n",
       "      <td>[la, india, song, album]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>624782.750000</td>\n",
       "      <td>450.750000</td>\n",
       "      <td>428.500000</td>\n",
       "      <td>444.500000</td>\n",
       "      <td>434.750000</td>\n",
       "      <td>3.537500</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.405836</td>\n",
       "      <td>0.231509</td>\n",
       "      <td>0.336759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4434</th>\n",
       "      <td>34D9ZRXCYRVYV0Y20MTM8EXYR5MSAS</td>\n",
       "      <td>The skin is covered in chromatophores , which enable the squid to change color to suit its surroundings , making it practically invisible .</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>covered</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>covered</td>\n",
       "      <td>[VBN]</td>\n",
       "      <td>[v]</td>\n",
       "      <td>cover</td>\n",
       "      <td>cover</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.259259</td>\n",
       "      <td>6.377049</td>\n",
       "      <td>-0.622951</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>24.0</td>\n",
       "      <td>4.444444</td>\n",
       "      <td>46.481481</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.754888</td>\n",
       "      <td>0.228538</td>\n",
       "      <td>4.70044</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.957143</td>\n",
       "      <td>0.930556</td>\n",
       "      <td>0.457309</td>\n",
       "      <td>0.14524</td>\n",
       "      <td>0.14524</td>\n",
       "      <td>102539.393443</td>\n",
       "      <td>0.684943</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.392238</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>the skin is covered in chromatophores , which enable the squid to change color to suit its surroundings , making it practically invisible .</td>\n",
       "      <td>[(skin, 2), (chromatophores, 1), (enable, 2)]</td>\n",
       "      <td>[(skin, 2), (chromatophores, 1), (enable, 2)]</td>\n",
       "      <td>[skin, chromatophores, enable]</td>\n",
       "      <td>8.0</td>\n",
       "      <td>29436.666667</td>\n",
       "      <td>463.666667</td>\n",
       "      <td>471.333333</td>\n",
       "      <td>479.333333</td>\n",
       "      <td>427.333333</td>\n",
       "      <td>3.106667</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.622445</td>\n",
       "      <td>0.007744</td>\n",
       "      <td>0.285621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  id  \\\n",
       "702   3WJGKMRWVIAGMQCINAUOJA1MQ5XDCL   \n",
       "4434  34D9ZRXCYRVYV0Y20MTM8EXYR5MSAS   \n",
       "\n",
       "                                                                                                                                         sentence  \\\n",
       "702                                                  La India covered the song on her album , Sobre el Fuego as her third single from the album .   \n",
       "4434  The skin is covered in chromatophores , which enable the squid to change color to suit its surroundings , making it practically invisible .   \n",
       "\n",
       "      start  end   target  nat  non_nat  nat_marked  non_nat_marked  binary  \\\n",
       "702       9   16  covered   10       10           2               2       1   \n",
       "4434     12   19  covered   10       10           0               0       0   \n",
       "\n",
       "      prob p_target pos_tags pos_tags_pt  lemma p_lemma  wn_synset_freq  \\\n",
       "702    0.2  covered    [VBD]         [v]  cover   cover            27.0   \n",
       "4434   0.0  covered    [VBN]         [v]  cover   cover            27.0   \n",
       "\n",
       "      wn_synset_avg_lemma_freq  wn_synset_avg_lemma_len  \\\n",
       "702                   2.259259                 6.377049   \n",
       "4434                  2.259259                 6.377049   \n",
       "\n",
       "      wn_synset_diff_len_avg_lemma_len  wn_synset_avg_hypernyms  \\\n",
       "702                          -0.622951                 0.888889   \n",
       "4434                         -0.622951                 0.888889   \n",
       "\n",
       "      wn_synset_sum_hypernyms  wn_synset_avg_hyponyms  \\\n",
       "702                      24.0                4.444444   \n",
       "4434                     24.0                4.444444   \n",
       "\n",
       "      wn_synset_avg_definition_len  wn_synset_avg_hyptree_depth  \\\n",
       "702                      46.481481                     2.666667   \n",
       "4434                     46.481481                     2.666667   \n",
       "\n",
       "      wn_synset_num_distinct_pos  wn_synset_avg_num_relations  \\\n",
       "702                          2.0                     5.333333   \n",
       "4434                         2.0                     5.333333   \n",
       "\n",
       "      wn_synset_avg_freq_pos_noun  wn_synset_avg_freq_pos_verb  \\\n",
       "702                           0.0                         26.0   \n",
       "4434                          0.0                         26.0   \n",
       "\n",
       "      wn_synset_avg_freq_pos_adj  wn_synset_avg_freq_pos_adv  \\\n",
       "702                          1.0                         0.0   \n",
       "4434                         1.0                         0.0   \n",
       "\n",
       "      wn_synset_avg_freq_pos_noun_norm  wn_synset_avg_freq_pos_verb_norm  \\\n",
       "702                                0.0                          0.962963   \n",
       "4434                               0.0                          0.962963   \n",
       "\n",
       "      wn_synset_avg_freq_pos_adj_norm  wn_synset_avg_freq_pos_adv_norm  \\\n",
       "702                          0.037037                              0.0   \n",
       "4434                         0.037037                              0.0   \n",
       "\n",
       "      wn_synset_sense_entropy_uniform  wn_synset_sense_entropy_pos_uniform  \\\n",
       "702                          4.754888                             0.228538   \n",
       "4434                         4.754888                             0.228538   \n",
       "\n",
       "      wn_synsets_sense_entropy_pos_central  wn_synset_pos_ratio_1  \\\n",
       "702                                4.70044               0.962963   \n",
       "4434                               4.70044               0.962963   \n",
       "\n",
       "      wn_synset_pos_ratio_2  swn_avg_objective_score  \\\n",
       "702                0.957143                 0.930556   \n",
       "4434               0.957143                 0.930556   \n",
       "\n",
       "      wn_synsets_freq_ratio_to_max_agg_min  \\\n",
       "702                               0.457309   \n",
       "4434                              0.457309   \n",
       "\n",
       "      wn_synsets_freq_ratio_to_max_agg_mean  \\\n",
       "702                                 0.14524   \n",
       "4434                                0.14524   \n",
       "\n",
       "      wn_synsets_freq_ratio_to_max_agg_median  wn_synsets_avg_lemma_freq  \\\n",
       "702                                   0.14524              102539.393443   \n",
       "4434                                  0.14524              102539.393443   \n",
       "\n",
       "      wn_synsets_freq_ratio_to_avg  wn_synset_lesk_wsd_ratio_hi_freq  \\\n",
       "702                       0.684943                               0.5   \n",
       "4434                      0.684943                               1.0   \n",
       "\n",
       "      wn_synset_lesk_wsd_ratio_low_freq  \\\n",
       "702                                 0.5   \n",
       "4434                                0.0   \n",
       "\n",
       "      wn_synset_lesk_wsd_ratio_hi_nopos_freq  \\\n",
       "702                                      0.5   \n",
       "4434                                     1.0   \n",
       "\n",
       "      wn_synset_lesk_wsd_ratio_low_nopos_freq  \\\n",
       "702                                       0.5   \n",
       "4434                                      0.0   \n",
       "\n",
       "      wn_synset_lesk_wsd_ratio_hi_freq_sum  \\\n",
       "702                               0.973718   \n",
       "4434                              1.000000   \n",
       "\n",
       "      wn_synset_lesk_wsd_ratio_low_freq_sum  \\\n",
       "702                                0.026282   \n",
       "4434                               0.000000   \n",
       "\n",
       "      wn_synset_lesk_wsd_ratio_to_freq_sum  \\\n",
       "702                               0.792295   \n",
       "4434                              0.392238   \n",
       "\n",
       "      wn_synset_lesk_wsd__norm_sense_rank  \\\n",
       "702                              0.962963   \n",
       "4434                             0.296296   \n",
       "\n",
       "                                                                                                                                       p_sentence  \\\n",
       "702                                                  la india covered the song on her album , sobre el fuego as her third single from the album .   \n",
       "4434  the skin is covered in chromatophores , which enable the squid to change color to suit its surroundings , making it practically invisible .   \n",
       "\n",
       "                                            context  \\\n",
       "702    [(La, 2), (India, 1), (song, 1), (album, 2)]   \n",
       "4434  [(skin, 2), (chromatophores, 1), (enable, 2)]   \n",
       "\n",
       "                                     p_context_dist  \\\n",
       "702    [(la, 2), (india, 1), (song, 1), (album, 2)]   \n",
       "4434  [(skin, 2), (chromatophores, 1), (enable, 2)]   \n",
       "\n",
       "                           p_context  ctx_length  ctx_freq_wiki  ctx_mrc_fam  \\\n",
       "702         [la, india, song, album]         4.0  624782.750000   450.750000   \n",
       "4434  [skin, chromatophores, enable]         8.0   29436.666667   463.666667   \n",
       "\n",
       "      ctx_mrc_conc  ctx_mrc_imag  ctx_mrc_meanc  ctx_concreteness  \\\n",
       "702     428.500000    444.500000     434.750000          3.537500   \n",
       "4434    471.333333    479.333333     427.333333          3.106667   \n",
       "\n",
       "      ctx_len_chars  ctx_len_words  ctx_norm_chars  \\\n",
       "702            16.0              4             4.0   \n",
       "4434           24.0              3             8.0   \n",
       "\n",
       "      ctx_target_embed_cos_glove_300_min  ctx_target_embed_cos_glove_300_max  \\\n",
       "702                             0.405836                            0.231509   \n",
       "4434                            0.622445                            0.007744   \n",
       "\n",
       "      ctx_target_embed_cos_glove_300_mean  \n",
       "702                              0.336759  \n",
       "4434                             0.285621  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = ctx_datasets_fc_context_complexity[0].train\n",
    "train.loc[train.target=='covered',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>p_context</th>\n",
       "      <th>ctx_target_embed_cos_glove_300_min</th>\n",
       "      <th>ctx_target_embed_cos_glove_300_max</th>\n",
       "      <th>ctx_target_embed_cos_glove_300_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>theater</td>\n",
       "      <td>[tradition, comic, film]</td>\n",
       "      <td>0.702274</td>\n",
       "      <td>0.359093</td>\n",
       "      <td>0.519586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>theater</td>\n",
       "      <td>[carpets, wallpaper, sets, termed]</td>\n",
       "      <td>0.354014</td>\n",
       "      <td>0.120082</td>\n",
       "      <td>0.185138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5549</th>\n",
       "      <td>theater</td>\n",
       "      <td>[film, television, radio, capacity]</td>\n",
       "      <td>0.702274</td>\n",
       "      <td>0.375060</td>\n",
       "      <td>0.546904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       target                            p_context  \\\n",
       "446   theater             [tradition, comic, film]   \n",
       "796   theater   [carpets, wallpaper, sets, termed]   \n",
       "5549  theater  [film, television, radio, capacity]   \n",
       "\n",
       "      ctx_target_embed_cos_glove_300_min  ctx_target_embed_cos_glove_300_max  \\\n",
       "446                             0.702274                            0.359093   \n",
       "796                             0.354014                            0.120082   \n",
       "5549                            0.702274                            0.375060   \n",
       "\n",
       "      ctx_target_embed_cos_glove_300_mean  \n",
       "446                              0.519586  \n",
       "796                              0.185138  \n",
       "5549                             0.546904  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = ctx_datasets_fc_context_complexity[0].train\n",
    "train.loc[train.target=='theater',['target', 'p_context', \\\n",
    "    'ctx_target_embed_cos_glove_300_min', 'ctx_target_embed_cos_glove_300_max', 'ctx_target_embed_cos_glove_300_mean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "#Select wikipedia train set of concatenation\n",
    "data = ctx_datasets_fc_context_complexity[0].train\n",
    "complexity_plot_1 = sns.scatterplot(x=\"ctx_rb_flesch_score\", y=\"ctx_norm_chars\", \n",
    "                                    hue=\"binary\", size='prob',\n",
    "            sizes=(40, 400), alpha=.5, palette=\"muted\",\n",
    "            data=data)\n",
    "plt.show(complexity_plot_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4.3) Sentence/HIT features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pickle\n",
    "\n",
    "with open('resources/dbpedia-cache/dbpedia_annotations_00.json', 'rb') as fp:\n",
    "    dbpedia_00 = pickle.load(fp)\n",
    "    \n",
    "with open('resources/dbpedia-cache/dbpedia_annotations_25.json', 'rb') as fp:\n",
    "    dbpedia_25 = pickle.load(fp)\n",
    "    \n",
    "with open('resources/dbpedia-cache/dbpedia_annotations_50.json', 'rb') as fp:\n",
    "    dbpedia_50 = pickle.load(fp)\n",
    "    \n",
    "with open('resources/dbpedia-cache/dbpedia_annotations_75.json', 'rb') as fp:\n",
    "    dbpedia_75 = pickle.load(fp)\n",
    "    \n",
    "with open('resources/dbpedia-cache/pagerank.json', 'rb') as fp:\n",
    "    page_rank = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def overlaps(start1, end1, start2, end2):\n",
    "    return bool(range(max(start1, start2), min(end1, end2)+1))\n",
    "\n",
    "def dbp_match_entities(sentence, target, start, end, annotations):\n",
    "    an_sents = annotations.get(sentence)\n",
    "    if an_sents:\n",
    "        ans = [(an['offset'], an['offset']+len(an['surfaceForm']), an) for an in an_sents]\n",
    "        return [an for s, e, an in ans if overlaps(start, end, s, e)]\n",
    "    return []\n",
    "\n",
    "def dbp_pagerank(sentence, annotations):\n",
    "    entities = annotations.get(sentence)\n",
    "    if not entities:\n",
    "        return 0\n",
    "    return np.nan_to_num(np.mean([page_rank.get(entity['URI'], 0) for entity in entities]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def ctx_features_sentence(dataframe, agg):\n",
    "    df = dataframe.copy()\n",
    "    df['dbp_pagerank_25'] = df.sentence.apply(lambda sentence : \\\n",
    "                                                dbp_pagerank(sentence, dbpedia_25))\n",
    "    df = df.fillna(0)\n",
    "    return df\n",
    "    \n",
    "ctx_fc_context_sentence = ContextFeatureCategory('context_complexity_sentence', \\\n",
    "                                ctx_features_sentence)\n",
    "feature_categories.append(ctx_fc_context_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "contexts = [ctx_sentence_nf]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ctx_datasets = [ContextDataset(ds.name, ctx, preprocess_ctx_df(ctx.func(ds.train)), \n",
    "                preprocess_ctx_df(ctx.func(ds.test)))\n",
    "                for ctx in contexts\n",
    "                for ds in datasets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ctx_datasets_fc_context_complexity_sentence = [ContextFeatureDataset(ctx_ds.name, ctx_ds.context, \n",
    "        ctx_fc_context_sentence, agg, ctx_fc_context_sentence.func(ctx_ds.train, agg.agg),\n",
    "        ctx_fc_context_sentence.func(ctx_ds.test, agg.agg))\n",
    "        for ctx_ds in ctx_datasets for agg in aggs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train = ctx_datasets_fc_context_complexity_sentence[0].train\n",
    "train.loc[train.dbp_pagerank_25<30,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "concat = concat_feature_datasets(ctx_datasets_fc_context_complexity_sentence, ctx_datasets_fc_context_complexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "#Select wikipedia train set of concatenation\n",
    "data = concat[0].train\n",
    "complexity_plot_1 = sns.scatterplot(x=\"ctx_norm_chars\", y=\"dbp_pagerank_25\", \n",
    "                                    hue=\"binary\", size='prob',\n",
    "            sizes=(40, 400), alpha=.5, palette=\"muted\",\n",
    "            data=data)\n",
    "plt.show(complexity_plot_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 5. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "Result = namedtuple('Result', 'dataset, fc, agg, measure')\n",
    "Dataset = namedtuple('Dataset', 'name, train, test')\n",
    "FeatureDataset = namedtuple('FeatureDataset', 'name, fc, agg, train, test')\n",
    "FeatureCategory = namedtuple('FeatureCategory', 'name, func')\n",
    "Feature = namedtuple('Feature', 'name, fc_name, train, test')\n",
    "Metric = namedtuple('Metric', 'name, func')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_labels_for_binary_df(dataframe):\n",
    "    df = dataframe.copy()\n",
    "    df = df.drop(['id', 'sentence', 'target', 'nat', 'non_nat', \n",
    "                  'nat_marked', 'non_nat_marked', 'prob', 'start', \n",
    "                  'end', 'p_target', 'lemma', 'p_lemma', 'pos_tags', 'pos_tags_pt', \n",
    "                 'p_sentence', 'context', 'p_context_dist', 'p_context'], axis = 1)\n",
    "    return df\n",
    "\n",
    "def remove_label_for_binary_df_and_ctx_features(dataframe):\n",
    "    df = remove_labels_for_binary_df(dataframe)\n",
    "    df = df[df.columns.drop(list(df.filter(regex='ctx')))]\n",
    "    df = df[df.columns.drop(list(df.filter(regex='rb_sybl_count_ratio')))]\n",
    "    return df\n",
    "\n",
    "def remove_labels_for_regr_df(dataframe):\n",
    "    df = dataframe.copy()\n",
    "    df = df.drop(['id', 'sentence', 'target', 'nat', 'non_nat', \n",
    "                  'nat_marked', 'non_nat_marked', 'binary', 'start', \n",
    "                  'end', 'p_target', 'lemma', 'p_lemma', 'pos_tags', 'pos_tags_pt',\n",
    "                 'p_sentence', 'context', 'p_context_dist', 'p_context'], axis = 1)\n",
    "    return df\n",
    "\n",
    "    \n",
    "def transform_feat_to_num(train, test):\n",
    "    train_copy = train.copy()\n",
    "    test_copy = test.copy()\n",
    "    #train_copy = train_copy.replace(np.inf, 0)\n",
    "    #train_copy = train_copy.replace(np.nan, 0)\n",
    "    train_copy = train_copy.replace([np.inf, -np.inf], np.nan)\n",
    "    train_copy = train_copy.fillna(0)\n",
    "    #test_copy = test_copy.replace(np.inf, 0)\n",
    "    #test_copy = test_copy.replace(np.nan, 0)\n",
    "    test_copy = test_copy.replace([np.inf, -np.inf], np.nan)\n",
    "    test_copy = test_copy.fillna(0)\n",
    "    shape_train = train.shape\n",
    "    shape_test = test.shape\n",
    "    df = train_copy.append(test_copy, ignore_index=True)\n",
    "    df = pd.get_dummies(df)\n",
    "    return (df.loc[0:(shape_train[0]-1),], \n",
    "            df.loc[shape_train[0]:df.shape[0],])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn import model_selection\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def get_majority_class_prediction(train, test):\n",
    "    dummy = DummyClassifier(strategy='most_frequent', \n",
    "                            random_state=None, constant=None)\n",
    "    x_train = train.loc[:, train.columns != 'binary']\n",
    "    y_train = train.binary.values\n",
    "    x_test = test\n",
    "    y_test = test.binary.values\n",
    "    dummy.fit(x_train, y_train)\n",
    "    prediction = dummy.predict(x_test)\n",
    "    f1score = f1_score(y_test, prediction)\n",
    "    return f1score\n",
    "\n",
    "def always_complex_prediction(train, test):\n",
    "    y_test = test.binary.values\n",
    "    prediction = [1 for val in y_test]\n",
    "    f1score = precision_recall_fscore_support(y_test, prediction)\n",
    "    return f1score\n",
    "\n",
    "def svm(train, test):\n",
    "    print('average_classification')\n",
    "    x_train = train.loc[:, train.columns != 'binary']\n",
    "    y_train = train.binary.values\n",
    "    x_test = test.loc[:, test.columns != 'binary']\n",
    "    y_test = test.binary.values\n",
    "    seed = 7\n",
    "    #knn = MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto',\n",
    "     #  beta_1=0.9, beta_2=0.999, early_stopping=False,\n",
    "    #   epsilon=1e-08, hidden_layer_sizes=(5, 100), learning_rate='constant',\n",
    "    #   learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
    "    #   nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
    "    #   solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
    "    #   warm_start=False)\n",
    "    knn = svm.SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "        decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
    "        max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "        tol=0.001, verbose=False)\n",
    "    knn.fit(x_train, y_train) \n",
    "    prediction = knn.predict(x_test)\n",
    "    f1score = f1_score(y_test, prediction)\n",
    "    #kfold = model_selection.KFold(n_splits=2, random_state=seed)\n",
    "    #cv_results = model_selection.cross_val_score(knn, x_train, y_train, cv=kfold, scoring=make_scorer(f1_score))\n",
    "    return f1score\n",
    "\n",
    "def xgboost(train, test):\n",
    "    x_train = train.loc[:, train.columns != 'binary']\n",
    "    y_train = train.binary.values\n",
    "    x_test = test.loc[:, test.columns != 'binary']\n",
    "    y_test = test.binary.values\n",
    "    xgtrain = xgb.DMatrix(x_train.values, label=y_train)\n",
    "    xgtest = xgb.DMatrix(x_test.values, label=y_test)\n",
    "    xg_test_x = xgb.DMatrix(x_test.values)\n",
    "    param = {'max_depth': 30, 'eta': 1, 'silent': 1, 'objective': 'binary:logistic',  'n_estimators':5000}\n",
    "    evallist = [(xgtest, 'eval'), (xgtrain, 'train')]\n",
    "    num_round = 70\n",
    "    bst = xgb.train(param, xgtrain, num_round, evallist)\n",
    "    prediction = bst.predict(xg_test_x)\n",
    "    prediction_binary = list(map(lambda val: 1 if val>0.5 else 0, prediction))\n",
    "    f1score = precision_recall_fscore_support(y_test, prediction_binary)\n",
    "    return f1score\n",
    "\n",
    "def random_forest(train, test):\n",
    "    x_train = train.loc[:, train.columns != 'binary']\n",
    "    y_train = train.binary.values\n",
    "    x_test = test.loc[:, test.columns != 'binary']\n",
    "    y_test = test.binary.values\n",
    "    clf = RandomForestClassifier(max_depth=10, random_state=0, n_estimators=1800, \\\n",
    "                            verbose=1, min_samples_split=5, min_samples_leaf=4, bootstrap=False)\n",
    "    clf.fit(x_train, y_train)\n",
    "    prediction = clf.predict(x_test)\n",
    "    prediction_binary = list(map(lambda val: 1 if val>0.5 else 0, prediction))\n",
    "    f1score = precision_recall_fscore_support(y_test, prediction_binary)\n",
    "    return f1score\n",
    "\n",
    "# {'n_estimators': 1800,\n",
    "#  'min_samples_split': 5,\n",
    "#  'min_samples_leaf': 4,\n",
    "#  'max_features': 'auto',\n",
    "#  'max_depth': 10,\n",
    "#  'bootstrap': False}\n",
    "\n",
    "def xgboost_with_bst(train, test):\n",
    "    x_train = train.loc[:, train.columns != 'binary']\n",
    "    y_train = train.binary.values\n",
    "    x_test = test.loc[:, test.columns != 'binary']\n",
    "    y_test = test.binary.values\n",
    "    xgtrain = xgb.DMatrix(x_train.values, label=y_train, feature_names=x_train.columns.values)\n",
    "    xgtest = xgb.DMatrix(x_test.values, label=y_test, feature_names=x_test.columns.values)\n",
    "    xg_test_x = xgb.DMatrix(x_test.values, feature_names=x_test.columns.values)\n",
    "    param = {'max_depth': 30, 'eta': 1, 'silent': 1, 'objective': 'binary:logistic',  'n_estimators':5000}\n",
    "    evallist = [(xgtest, 'eval'), (xgtrain, 'train')]\n",
    "    num_round = 70\n",
    "    bst = xgb.train(param, xgtrain, num_round, evallist)\n",
    "    prediction = bst.predict(xg_test_x)\n",
    "    prediction_binary = list(map(lambda val: 1 if val>0.5 else 0, prediction))\n",
    "    f1score = precision_recall_fscore_support(y_test, prediction_binary)\n",
    "    return f1score, bst\n",
    "\n",
    "def adaboost(train, test):\n",
    "    x_train = train.loc[:, train.columns != 'binary']\n",
    "    y_train = train.binary.values\n",
    "    x_test = test.loc[:, test.columns != 'binary']\n",
    "    y_test = test.binary.values\n",
    "    adab = AdaBoostClassifier(base_estimator=None, n_estimators=5000, \n",
    "                          learning_rate=1.0, algorithm='SAMME.R',\n",
    "                          random_state=None)\n",
    "    adab.fit(x_train, y_train) \n",
    "    prediction = adab.predict(x_test)\n",
    "    f1score = precision_recall_fscore_support(y_test, prediction)\n",
    "    return f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ContextFeatureDataset = namedtuple('ContextFeatureDataset', 'name, context, fc, agg, train, test')\n",
    "Result = namedtuple('Result', 'dataset, fc, agg, context, measure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      binary  wn_synset_freq  wn_synset_avg_lemma_freq  \\\n",
       " 0          1            1.00                  5.000000   \n",
       " 1          1           25.00                  4.360000   \n",
       " 2          0           18.00                  3.000000   \n",
       " 3          1            7.00                  1.857143   \n",
       " 4          1            7.00                  1.785714   \n",
       " 5          1            7.00                  1.714286   \n",
       " 6          1            9.00                  3.555556   \n",
       " 7          0            6.00                  1.666667   \n",
       " 8          1            2.00                  1.000000   \n",
       " 9          0            3.20                  1.413333   \n",
       " 10         1            5.00                  3.400000   \n",
       " 11         0            9.00                  2.666667   \n",
       " 12         1            5.00                  3.600000   \n",
       " 13         0           37.00                  3.972973   \n",
       " 14         1            8.75                  2.108333   \n",
       " 15         1           10.00                  1.611111   \n",
       " 16         0           18.00                  3.000000   \n",
       " 17         1            0.00                  0.000000   \n",
       " 18         0           12.00                  1.833333   \n",
       " 19         1            5.00                  3.200000   \n",
       " 20         0            2.00                  1.500000   \n",
       " 21         1            5.00                  3.600000   \n",
       " 22         0           17.00                  2.176471   \n",
       " 23         0            5.00                  1.800000   \n",
       " 24         1            5.50                  2.716667   \n",
       " 25         0            1.00                  3.000000   \n",
       " 26         0            6.00                  1.833333   \n",
       " 27         0            4.00                  1.500000   \n",
       " 28         0            5.00                  3.600000   \n",
       " 29         1           27.00                  2.592593   \n",
       " ...      ...             ...                       ...   \n",
       " 5521       0           21.00                  2.238095   \n",
       " 5522       0            8.00                  2.625000   \n",
       " 5523       1           11.50                  3.598485   \n",
       " 5524       0           11.00                  5.363636   \n",
       " 5525       1           12.00                  1.833333   \n",
       " 5526       0           38.00                  2.105263   \n",
       " 5527       0           22.00                  2.818182   \n",
       " 5528       0            8.00                  2.625000   \n",
       " 5529       1            1.00                  1.000000   \n",
       " 5530       1            1.00                  1.000000   \n",
       " 5531       0           10.00                  2.700000   \n",
       " 5532       0            1.00                  3.000000   \n",
       " 5533       1            6.00                  3.333333   \n",
       " 5534       1            6.00                  2.500000   \n",
       " 5535       1            6.00                  1.666667   \n",
       " 5536       1            1.00                  3.000000   \n",
       " 5537       0            2.00                  4.000000   \n",
       " 5538       0            1.00                  1.000000   \n",
       " 5539       0            5.00                  1.400000   \n",
       " 5540       1            4.00                  1.500000   \n",
       " 5541       0            3.00                  2.666667   \n",
       " 5542       0           16.00                  2.375000   \n",
       " 5543       1            3.00                  3.333333   \n",
       " 5544       1            8.00                  1.375000   \n",
       " 5545       1            9.00                  1.555556   \n",
       " 5546       0           38.00                  2.447368   \n",
       " 5547       0            7.00                  3.142857   \n",
       " 5548       0            3.00                  5.000000   \n",
       " 5549       0            3.00                  4.666667   \n",
       " 5550       0            5.00                  2.600000   \n",
       " \n",
       "       wn_synset_avg_lemma_len  wn_synset_diff_len_avg_lemma_len  \\\n",
       " 0                    9.000000                          1.000000   \n",
       " 1                    6.284404                          0.284404   \n",
       " 2                    6.500000                          2.500000   \n",
       " 3                    7.461538                          1.461538   \n",
       " 4                    8.855769                          0.355769   \n",
       " 5                   10.250000                         -0.750000   \n",
       " 6                    8.312500                         -1.687500   \n",
       " 7                   12.800000                          3.800000   \n",
       " 8                   11.000000                          0.000000   \n",
       " 9                    5.454902                         -1.345098   \n",
       " 10                   6.941176                         -0.058824   \n",
       " 11                   9.333333                         -0.666667   \n",
       " 12                   9.333333                         -0.666667   \n",
       " 13                   6.632653                         -0.367347   \n",
       " 14                   5.674242                         -1.825758   \n",
       " 15                   4.454545                         -2.212121   \n",
       " 16                   6.500000                          2.500000   \n",
       " 17                   0.000000                        -10.000000   \n",
       " 18                   6.863636                          0.863636   \n",
       " 19                   7.125000                         -0.875000   \n",
       " 20                  14.333333                          5.333333   \n",
       " 21                   9.333333                         -0.666667   \n",
       " 22                   6.675676                          0.675676   \n",
       " 23                   9.444444                          0.444444   \n",
       " 24                   8.439394                         -0.560606   \n",
       " 25                  10.666667                          2.666667   \n",
       " 26                   7.545455                         -0.454545   \n",
       " 27                   6.500000                         -2.500000   \n",
       " 28                   9.333333                         -0.666667   \n",
       " 29                   6.328571                          0.328571   \n",
       " ...                       ...                               ...   \n",
       " 5521                 6.893617                         -1.106383   \n",
       " 5522                 9.095238                          3.095238   \n",
       " 5523                 5.909476                          1.909476   \n",
       " 5524                 5.864407                          1.864407   \n",
       " 5525                 5.954545                          1.954545   \n",
       " 5526                 5.087500                          0.087500   \n",
       " 5527                 7.661290                          2.661290   \n",
       " 5528                 9.095238                          3.095238   \n",
       " 5529                 5.000000                          0.000000   \n",
       " 5530                 6.000000                         -1.000000   \n",
       " 5531                 5.370370                          0.370370   \n",
       " 5532                 7.333333                          5.333333   \n",
       " 5533                10.400000                         -0.600000   \n",
       " 5534                 9.900000                          0.900000   \n",
       " 5535                 9.400000                          2.400000   \n",
       " 5536                10.333333                         -0.666667   \n",
       " 5537                 6.625000                          1.625000   \n",
       " 5538                 7.000000                          0.000000   \n",
       " 5539                 7.142857                          1.142857   \n",
       " 5540                 8.500000                          0.500000   \n",
       " 5541                 6.625000                          0.625000   \n",
       " 5542                 5.315789                          1.315789   \n",
       " 5543                 6.600000                          1.600000   \n",
       " 5544                 8.909091                         -1.090909   \n",
       " 5545                 9.500000                          1.500000   \n",
       " 5546                 6.440860                          1.440860   \n",
       " 5547                 8.136364                          4.136364   \n",
       " 5548                 9.266667                         -0.733333   \n",
       " 5549                10.285714                          3.285714   \n",
       " 5550                 8.307692                          3.307692   \n",
       " \n",
       "       wn_synset_avg_hypernyms  wn_synset_sum_hypernyms  \\\n",
       " 0                    0.000000                 0.000000   \n",
       " 1                    0.840000                21.000000   \n",
       " 2                    0.888889                16.000000   \n",
       " 3                    0.428571                 3.000000   \n",
       " 4                    0.714286                 5.000000   \n",
       " 5                    1.000000                 7.000000   \n",
       " 6                    0.888889                 8.000000   \n",
       " 7                    1.000000                 6.000000   \n",
       " 8                    0.000000                 0.000000   \n",
       " 9                    0.400000                 2.800000   \n",
       " 10                   1.000000                 5.000000   \n",
       " 11                   1.000000                 9.000000   \n",
       " 12                   0.600000                 3.000000   \n",
       " 13                   0.756757                28.000000   \n",
       " 14                   0.622222                 7.750000   \n",
       " 15                   0.629630                 9.333333   \n",
       " 16                   0.888889                16.000000   \n",
       " 17                   0.000000                 0.000000   \n",
       " 18                   1.000000                12.000000   \n",
       " 19                   0.600000                 3.000000   \n",
       " 20                   0.000000                 0.000000   \n",
       " 21                   0.600000                 3.000000   \n",
       " 22                   1.000000                17.000000   \n",
       " 23                   0.000000                 0.000000   \n",
       " 24                   0.800000                 4.500000   \n",
       " 25                   1.000000                 1.000000   \n",
       " 26                   1.000000                 6.000000   \n",
       " 27                   0.750000                 3.000000   \n",
       " 28                   0.600000                 3.000000   \n",
       " 29                   0.925926                25.000000   \n",
       " ...                       ...                      ...   \n",
       " 5521                 1.000000                21.000000   \n",
       " 5522                 0.250000                 2.000000   \n",
       " 5523                 1.045455                12.000000   \n",
       " 5524                 1.090909                12.000000   \n",
       " 5525                 1.000000                12.000000   \n",
       " 5526                 1.026316                39.000000   \n",
       " 5527                 0.318182                 7.000000   \n",
       " 5528                 0.250000                 2.000000   \n",
       " 5529                 1.000000                 1.000000   \n",
       " 5530                 1.000000                 1.000000   \n",
       " 5531                 1.000000                10.000000   \n",
       " 5532                 1.000000                 1.000000   \n",
       " 5533                 0.333333                 2.000000   \n",
       " 5534                 0.666667                 4.000000   \n",
       " 5535                 1.000000                 6.000000   \n",
       " 5536                 1.000000                 1.000000   \n",
       " 5537                 1.000000                 2.000000   \n",
       " 5538                 1.000000                 1.000000   \n",
       " 5539                 0.400000                 2.000000   \n",
       " 5540                 0.000000                 0.000000   \n",
       " 5541                 1.333333                 4.000000   \n",
       " 5542                 0.687500                11.000000   \n",
       " 5543                 0.333333                 1.000000   \n",
       " 5544                 1.000000                 8.000000   \n",
       " 5545                 1.000000                 9.000000   \n",
       " 5546                 0.921053                35.000000   \n",
       " 5547                 1.428571                10.000000   \n",
       " 5548                 1.000000                 3.000000   \n",
       " 5549                 1.000000                 3.000000   \n",
       " 5550                 0.800000                 4.000000   \n",
       " \n",
       "       wn_synset_avg_hyponyms  wn_synset_avg_definition_len  \\\n",
       " 0                   0.000000                     23.000000   \n",
       " 1                   4.400000                     33.560000   \n",
       " 2                   5.555556                     47.333333   \n",
       " 3                   1.142857                     52.285714   \n",
       " 4                   1.000000                     52.928571   \n",
       " 5                   0.857143                     53.571429   \n",
       " 6                   1.777778                     36.888889   \n",
       " 7                   3.000000                     50.666667   \n",
       " 8                   0.000000                     42.000000   \n",
       " 9                   3.502222                     33.182222   \n",
       " 10                 13.400000                     64.800000   \n",
       " 11                  4.111111                     59.111111   \n",
       " 12                  1.000000                     71.600000   \n",
       " 13                  3.054054                     37.675676   \n",
       " 14                  2.201389                     46.816667   \n",
       " 15                  2.601852                     38.555556   \n",
       " 16                  5.555556                     47.333333   \n",
       " 17                  0.000000                      0.000000   \n",
       " 18                  2.250000                     68.333333   \n",
       " 19                  0.600000                     28.800000   \n",
       " 20                  0.000000                    141.000000   \n",
       " 21                  1.000000                     71.600000   \n",
       " 22                  4.000000                     44.705882   \n",
       " 23                  0.000000                     42.800000   \n",
       " 24                  1.250000                     60.216667   \n",
       " 25                  3.000000                     36.000000   \n",
       " 26                  1.500000                     48.833333   \n",
       " 27                  3.000000                     63.000000   \n",
       " 28                  1.000000                     71.600000   \n",
       " 29                  2.481481                     49.851852   \n",
       " ...                      ...                           ...   \n",
       " 5521                2.428571                     50.190476   \n",
       " 5522                1.000000                     46.750000   \n",
       " 5523                0.924242                     62.882576   \n",
       " 5524                1.181818                     53.181818   \n",
       " 5525                0.666667                     72.583333   \n",
       " 5526                4.315789                     43.131579   \n",
       " 5527                0.409091                     54.909091   \n",
       " 5528                1.000000                     46.750000   \n",
       " 5529               17.000000                    163.000000   \n",
       " 5530                0.000000                     19.000000   \n",
       " 5531                5.800000                     51.100000   \n",
       " 5532                0.000000                     58.000000   \n",
       " 5533                0.166667                     49.833333   \n",
       " 5534                2.333333                     43.833333   \n",
       " 5535                4.500000                     37.833333   \n",
       " 5536                2.000000                     64.000000   \n",
       " 5537               12.500000                     30.000000   \n",
       " 5538                3.000000                     14.000000   \n",
       " 5539                2.000000                     67.200000   \n",
       " 5540                0.000000                     59.750000   \n",
       " 5541              135.000000                     79.666667   \n",
       " 5542               10.375000                     53.437500   \n",
       " 5543                1.666667                     47.000000   \n",
       " 5544                4.500000                     64.250000   \n",
       " 5545                0.666667                     51.222222   \n",
       " 5546                5.473684                     43.578947   \n",
       " 5547                5.714286                     66.571429   \n",
       " 5548                2.000000                     82.000000   \n",
       " 5549                2.666667                     59.666667   \n",
       " 5550                1.000000                     49.000000   \n",
       " \n",
       "       wn_synset_avg_hyptree_depth  wn_synset_num_distinct_pos  \\\n",
       " 0                        0.000000                    1.000000   \n",
       " 1                        1.520000                    1.000000   \n",
       " 2                        4.166667                    2.000000   \n",
       " 3                        2.428571                    3.000000   \n",
       " 4                        4.285714                    2.000000   \n",
       " 5                        6.142857                    1.000000   \n",
       " 6                        3.111111                    1.000000   \n",
       " 7                        5.333333                    1.000000   \n",
       " 8                        0.000000                    2.000000   \n",
       " 9                        2.493333                    0.800000   \n",
       " 10                       5.800000                    1.000000   \n",
       " 11                       6.666667                    1.000000   \n",
       " 12                       3.200000                    3.000000   \n",
       " 13                       2.567568                    5.000000   \n",
       " 14                       3.279167                    1.750000   \n",
       " 15                       3.305556                    1.333333   \n",
       " 16                       4.166667                    2.000000   \n",
       " 17                       0.000000                    0.000000   \n",
       " 18                       5.750000                    2.000000   \n",
       " 19                       1.000000                    1.000000   \n",
       " 20                       7.000000                    1.000000   \n",
       " 21                       3.200000                    3.000000   \n",
       " 22                       4.764706                    2.000000   \n",
       " 23                       0.000000                    2.000000   \n",
       " 24                       4.266667                    2.500000   \n",
       " 25                       9.000000                    1.000000   \n",
       " 26                       5.333333                    2.000000   \n",
       " 27                       3.000000                    1.000000   \n",
       " 28                       3.200000                    3.000000   \n",
       " 29                       3.481481                    2.000000   \n",
       " ...                           ...                         ...   \n",
       " 5521                     2.000000                    1.000000   \n",
       " 5522                     1.125000                    3.000000   \n",
       " 5523                     6.632576                    2.000000   \n",
       " 5524                     6.181818                    2.000000   \n",
       " 5525                     7.083333                    2.000000   \n",
       " 5526                     4.000000                    2.000000   \n",
       " 5527                     2.727273                    4.000000   \n",
       " 5528                     1.125000                    3.000000   \n",
       " 5529                     7.000000                    1.000000   \n",
       " 5530                     2.000000                    1.000000   \n",
       " 5531                     2.100000                    1.000000   \n",
       " 5532                     7.000000                    1.000000   \n",
       " 5533                     3.000000                    3.000000   \n",
       " 5534                     5.000000                    2.500000   \n",
       " 5535                     7.000000                    2.000000   \n",
       " 5536                     6.000000                    1.000000   \n",
       " 5537                     8.000000                    1.000000   \n",
       " 5538                    10.000000                    1.000000   \n",
       " 5539                     2.800000                    3.000000   \n",
       " 5540                     0.000000                    2.000000   \n",
       " 5541                     6.333333                    1.000000   \n",
       " 5542                     2.937500                    2.000000   \n",
       " 5543                     3.000000                    3.000000   \n",
       " 5544                     7.000000                    1.000000   \n",
       " 5545                     6.555556                    1.000000   \n",
       " 5546                     3.131579                    2.000000   \n",
       " 5547                     5.857143                    2.000000   \n",
       " 5548                     9.333333                    1.000000   \n",
       " 5549                     6.000000                    1.000000   \n",
       " 5550                     6.000000                    3.000000   \n",
       " \n",
       "       wn_synset_avg_num_relations  wn_synset_avg_freq_pos_noun  \\\n",
       " 0                        0.000000                     0.000000   \n",
       " 1                        5.240000                     0.000000   \n",
       " 2                        9.777778                    11.000000   \n",
       " 3                        1.571429                     3.000000   \n",
       " 4                        1.714286                     5.000000   \n",
       " 5                        1.857143                     7.000000   \n",
       " 6                        2.666667                     0.000000   \n",
       " 7                        5.666667                     6.000000   \n",
       " 8                        0.000000                     0.000000   \n",
       " 9                        6.182222                     2.800000   \n",
       " 10                      25.800000                     5.000000   \n",
       " 11                       5.111111                     9.000000   \n",
       " 12                       1.600000                     2.000000   \n",
       " 13                       3.810811                     7.000000   \n",
       " 14                       3.677778                     5.250000   \n",
       " 15                       4.370370                     6.333333   \n",
       " 16                       9.777778                    11.000000   \n",
       " 17                       0.000000                     0.000000   \n",
       " 18                       3.333333                     8.000000   \n",
       " 19                       1.200000                     0.000000   \n",
       " 20                      25.500000                     2.000000   \n",
       " 21                       1.600000                     2.000000   \n",
       " 22                       5.058824                    11.000000   \n",
       " 23                       0.000000                     0.000000   \n",
       " 24                       2.050000                     2.500000   \n",
       " 25                       4.000000                     1.000000   \n",
       " 26                       2.500000                     3.000000   \n",
       " 27                       3.750000                     0.000000   \n",
       " 28                       1.600000                     2.000000   \n",
       " 29                       3.407407                     6.000000   \n",
       " ...                           ...                          ...   \n",
       " 5521                     3.428571                     0.000000   \n",
       " 5522                     1.250000                     1.000000   \n",
       " 5523                     2.803030                     9.500000   \n",
       " 5524                     3.272727                     8.000000   \n",
       " 5525                     2.333333                    11.000000   \n",
       " 5526                     5.368421                    12.000000   \n",
       " 5527                     0.863636                     7.000000   \n",
       " 5528                     1.250000                     1.000000   \n",
       " 5529                    18.000000                     1.000000   \n",
       " 5530                     1.000000                     0.000000   \n",
       " 5531                     6.800000                     0.000000   \n",
       " 5532                     3.000000                     1.000000   \n",
       " 5533                     0.500000                     2.000000   \n",
       " 5534                     3.166667                     3.500000   \n",
       " 5535                     5.833333                     5.000000   \n",
       " 5536                     3.000000                     1.000000   \n",
       " 5537                    49.500000                     2.000000   \n",
       " 5538                    53.000000                     1.000000   \n",
       " 5539                     2.600000                     2.000000   \n",
       " 5540                     0.000000                     0.000000   \n",
       " 5541                   137.333333                     3.000000   \n",
       " 5542                    11.437500                     6.000000   \n",
       " 5543                     8.000000                     1.000000   \n",
       " 5544                     5.625000                     8.000000   \n",
       " 5545                     1.666667                     9.000000   \n",
       " 5546                     6.421053                    11.000000   \n",
       " 5547                     7.857143                     5.000000   \n",
       " 5548                     6.333333                     3.000000   \n",
       " 5549                     8.666667                     3.000000   \n",
       " 5550                     3.200000                     3.000000   \n",
       " \n",
       "       wn_synset_avg_freq_pos_verb  wn_synset_avg_freq_pos_adj  \\\n",
       " 0                        0.000000                        0.00   \n",
       " 1                       25.000000                        0.00   \n",
       " 2                        7.000000                        0.00   \n",
       " 3                        0.000000                        4.00   \n",
       " 4                        0.000000                        2.00   \n",
       " 5                        0.000000                        0.00   \n",
       " 6                        9.000000                        0.00   \n",
       " 7                        0.000000                        0.00   \n",
       " 8                        0.000000                        2.00   \n",
       " 9                        0.000000                        0.40   \n",
       " 10                       0.000000                        0.00   \n",
       " 11                       0.000000                        0.00   \n",
       " 12                       0.000000                        3.00   \n",
       " 13                      25.000000                        4.00   \n",
       " 14                       2.750000                        0.75   \n",
       " 15                       3.666667                        0.00   \n",
       " 16                       7.000000                        0.00   \n",
       " 17                       0.000000                        0.00   \n",
       " 18                       4.000000                        0.00   \n",
       " 19                       5.000000                        0.00   \n",
       " 20                       0.000000                        0.00   \n",
       " 21                       0.000000                        3.00   \n",
       " 22                       6.000000                        0.00   \n",
       " 23                       0.000000                        5.00   \n",
       " 24                       1.500000                        1.50   \n",
       " 25                       0.000000                        0.00   \n",
       " 26                       3.000000                        0.00   \n",
       " 27                       4.000000                        0.00   \n",
       " 28                       0.000000                        3.00   \n",
       " 29                      21.000000                        0.00   \n",
       " ...                           ...                         ...   \n",
       " 5521                    21.000000                        0.00   \n",
       " 5522                     1.000000                        6.00   \n",
       " 5523                     2.000000                        0.00   \n",
       " 5524                     3.000000                        0.00   \n",
       " 5525                     1.000000                        0.00   \n",
       " 5526                    26.000000                        0.00   \n",
       " 5527                     1.000000                       14.00   \n",
       " 5528                     1.000000                        6.00   \n",
       " 5529                     0.000000                        0.00   \n",
       " 5530                     1.000000                        0.00   \n",
       " 5531                    10.000000                        0.00   \n",
       " 5532                     0.000000                        0.00   \n",
       " 5533                     0.000000                        2.00   \n",
       " 5534                     0.500000                        1.00   \n",
       " 5535                     1.000000                        0.00   \n",
       " 5536                     0.000000                        0.00   \n",
       " 5537                     0.000000                        0.00   \n",
       " 5538                     0.000000                        0.00   \n",
       " 5539                     0.000000                        3.00   \n",
       " 5540                     0.000000                        4.00   \n",
       " 5541                     0.000000                        0.00   \n",
       " 5542                    10.000000                        0.00   \n",
       " 5543                     0.000000                        2.00   \n",
       " 5544                     0.000000                        0.00   \n",
       " 5545                     0.000000                        0.00   \n",
       " 5546                    27.000000                        0.00   \n",
       " 5547                     2.000000                        0.00   \n",
       " 5548                     0.000000                        0.00   \n",
       " 5549                     0.000000                        0.00   \n",
       " 5550                     1.000000                        1.00   \n",
       " \n",
       "       wn_synset_avg_freq_pos_adv  wn_synset_avg_freq_pos_noun_norm  \\\n",
       " 0                            1.0                          0.000000   \n",
       " 1                            0.0                          0.000000   \n",
       " 2                            0.0                          0.611111   \n",
       " 3                            0.0                          0.428571   \n",
       " 4                            0.0                          0.714286   \n",
       " 5                            0.0                          1.000000   \n",
       " 6                            0.0                          0.000000   \n",
       " 7                            0.0                          1.000000   \n",
       " 8                            0.0                          0.000000   \n",
       " 9                            0.0                          0.875000   \n",
       " 10                           0.0                          1.000000   \n",
       " 11                           0.0                          1.000000   \n",
       " 12                           0.0                          0.400000   \n",
       " 13                           1.0                          0.189189   \n",
       " 14                           0.0                          0.600000   \n",
       " 15                           0.0                          0.633333   \n",
       " 16                           0.0                          0.611111   \n",
       " 17                           0.0                          0.000000   \n",
       " 18                           0.0                          0.666667   \n",
       " 19                           0.0                          0.000000   \n",
       " 20                           0.0                          1.000000   \n",
       " 21                           0.0                          0.400000   \n",
       " 22                           0.0                          0.647059   \n",
       " 23                           0.0                          0.000000   \n",
       " 24                           0.0                          0.454545   \n",
       " 25                           0.0                          1.000000   \n",
       " 26                           0.0                          0.500000   \n",
       " 27                           0.0                          0.000000   \n",
       " 28                           0.0                          0.400000   \n",
       " 29                           0.0                          0.222222   \n",
       " ...                          ...                               ...   \n",
       " 5521                         0.0                          0.000000   \n",
       " 5522                         0.0                          0.125000   \n",
       " 5523                         0.0                          0.826087   \n",
       " 5524                         0.0                          0.727273   \n",
       " 5525                         0.0                          0.916667   \n",
       " 5526                         0.0                          0.315789   \n",
       " 5527                         0.0                          0.318182   \n",
       " 5528                         0.0                          0.125000   \n",
       " 5529                         0.0                          1.000000   \n",
       " 5530                         0.0                          0.000000   \n",
       " 5531                         0.0                          0.000000   \n",
       " 5532                         0.0                          1.000000   \n",
       " 5533                         2.0                          0.333333   \n",
       " 5534                         1.0                          0.583333   \n",
       " 5535                         0.0                          0.833333   \n",
       " 5536                         0.0                          1.000000   \n",
       " 5537                         0.0                          1.000000   \n",
       " 5538                         0.0                          1.000000   \n",
       " 5539                         0.0                          0.400000   \n",
       " 5540                         0.0                          0.000000   \n",
       " 5541                         0.0                          1.000000   \n",
       " 5542                         0.0                          0.375000   \n",
       " 5543                         0.0                          0.333333   \n",
       " 5544                         0.0                          1.000000   \n",
       " 5545                         0.0                          1.000000   \n",
       " 5546                         0.0                          0.289474   \n",
       " 5547                         0.0                          0.714286   \n",
       " 5548                         0.0                          1.000000   \n",
       " 5549                         0.0                          1.000000   \n",
       " 5550                         0.0                          0.600000   \n",
       " \n",
       "       wn_synset_avg_freq_pos_verb_norm  wn_synset_avg_freq_pos_adj_norm  \\\n",
       " 0                             0.000000                         0.000000   \n",
       " 1                             1.000000                         0.000000   \n",
       " 2                             0.388889                         0.000000   \n",
       " 3                             0.000000                         0.571429   \n",
       " 4                             0.000000                         0.285714   \n",
       " 5                             0.000000                         0.000000   \n",
       " 6                             1.000000                         0.000000   \n",
       " 7                             0.000000                         0.000000   \n",
       " 8                             0.000000                         1.000000   \n",
       " 9                             0.000000                         0.125000   \n",
       " 10                            0.000000                         0.000000   \n",
       " 11                            0.000000                         0.000000   \n",
       " 12                            0.000000                         0.600000   \n",
       " 13                            0.675676                         0.108108   \n",
       " 14                            0.314286                         0.085714   \n",
       " 15                            0.366667                         0.000000   \n",
       " 16                            0.388889                         0.000000   \n",
       " 17                            0.000000                         0.000000   \n",
       " 18                            0.333333                         0.000000   \n",
       " 19                            1.000000                         0.000000   \n",
       " 20                            0.000000                         0.000000   \n",
       " 21                            0.000000                         0.600000   \n",
       " 22                            0.352941                         0.000000   \n",
       " 23                            0.000000                         1.000000   \n",
       " 24                            0.272727                         0.272727   \n",
       " 25                            0.000000                         0.000000   \n",
       " 26                            0.500000                         0.000000   \n",
       " 27                            1.000000                         0.000000   \n",
       " 28                            0.000000                         0.600000   \n",
       " 29                            0.777778                         0.000000   \n",
       " ...                                ...                              ...   \n",
       " 5521                          1.000000                         0.000000   \n",
       " 5522                          0.125000                         0.750000   \n",
       " 5523                          0.173913                         0.000000   \n",
       " 5524                          0.272727                         0.000000   \n",
       " 5525                          0.083333                         0.000000   \n",
       " 5526                          0.684211                         0.000000   \n",
       " 5527                          0.045455                         0.636364   \n",
       " 5528                          0.125000                         0.750000   \n",
       " 5529                          0.000000                         0.000000   \n",
       " 5530                          1.000000                         0.000000   \n",
       " 5531                          1.000000                         0.000000   \n",
       " 5532                          0.000000                         0.000000   \n",
       " 5533                          0.000000                         0.333333   \n",
       " 5534                          0.083333                         0.166667   \n",
       " 5535                          0.166667                         0.000000   \n",
       " 5536                          0.000000                         0.000000   \n",
       " 5537                          0.000000                         0.000000   \n",
       " 5538                          0.000000                         0.000000   \n",
       " 5539                          0.000000                         0.600000   \n",
       " 5540                          0.000000                         1.000000   \n",
       " 5541                          0.000000                         0.000000   \n",
       " 5542                          0.625000                         0.000000   \n",
       " 5543                          0.000000                         0.666667   \n",
       " 5544                          0.000000                         0.000000   \n",
       " 5545                          0.000000                         0.000000   \n",
       " 5546                          0.710526                         0.000000   \n",
       " 5547                          0.285714                         0.000000   \n",
       " 5548                          0.000000                         0.000000   \n",
       " 5549                          0.000000                         0.000000   \n",
       " 5550                          0.200000                         0.200000   \n",
       " \n",
       "       wn_synset_avg_freq_pos_adv_norm  wn_synset_sense_entropy_uniform  \\\n",
       " 0                            1.000000                         0.000000   \n",
       " 1                            0.000000                         4.643856   \n",
       " 2                            0.000000                         4.169925   \n",
       " 3                            0.000000                         2.807355   \n",
       " 4                            0.000000                         2.807355   \n",
       " 5                            0.000000                         2.807355   \n",
       " 6                            0.000000                         3.169925   \n",
       " 7                            0.000000                         2.584963   \n",
       " 8                            0.000000                         1.000000   \n",
       " 9                            0.000000                         1.298371   \n",
       " 10                           0.000000                         2.321928   \n",
       " 11                           0.000000                         3.169925   \n",
       " 12                           0.000000                         2.321928   \n",
       " 13                           0.027027                         5.209453   \n",
       " 14                           0.000000                         2.519204   \n",
       " 15                           0.000000                         2.584963   \n",
       " 16                           0.000000                         4.169925   \n",
       " 17                           0.000000                         0.000000   \n",
       " 18                           0.000000                         3.584963   \n",
       " 19                           0.000000                         2.321928   \n",
       " 20                           0.000000                         1.000000   \n",
       " 21                           0.000000                         2.321928   \n",
       " 22                           0.000000                         4.087463   \n",
       " 23                           0.000000                         2.321928   \n",
       " 24                           0.000000                         2.453445   \n",
       " 25                           0.000000                         0.000000   \n",
       " 26                           0.000000                         2.584963   \n",
       " 27                           0.000000                         2.000000   \n",
       " 28                           0.000000                         2.321928   \n",
       " 29                           0.000000                         4.754888   \n",
       " ...                               ...                              ...   \n",
       " 5521                         0.000000                         4.392317   \n",
       " 5522                         0.000000                         3.000000   \n",
       " 5523                         0.000000                         3.522197   \n",
       " 5524                         0.000000                         3.459432   \n",
       " 5525                         0.000000                         3.584963   \n",
       " 5526                         0.000000                         5.247928   \n",
       " 5527                         0.000000                         4.459432   \n",
       " 5528                         0.000000                         3.000000   \n",
       " 5529                         0.000000                         0.000000   \n",
       " 5530                         0.000000                         0.000000   \n",
       " 5531                         0.000000                         3.321928   \n",
       " 5532                         0.000000                         0.000000   \n",
       " 5533                         0.333333                         2.584963   \n",
       " 5534                         0.166667                         2.584963   \n",
       " 5535                         0.000000                         2.584963   \n",
       " 5536                         0.000000                         0.000000   \n",
       " 5537                         0.000000                         1.000000   \n",
       " 5538                         0.000000                         0.000000   \n",
       " 5539                         0.000000                         2.321928   \n",
       " 5540                         0.000000                         2.000000   \n",
       " 5541                         0.000000                         1.584963   \n",
       " 5542                         0.000000                         4.000000   \n",
       " 5543                         0.000000                         1.584963   \n",
       " 5544                         0.000000                         3.000000   \n",
       " 5545                         0.000000                         3.169925   \n",
       " 5546                         0.000000                         5.247928   \n",
       " 5547                         0.000000                         2.807355   \n",
       " 5548                         0.000000                         1.584963   \n",
       " 5549                         0.000000                         1.584963   \n",
       " 5550                         0.000000                         2.321928   \n",
       " \n",
       "       wn_synset_sense_entropy_pos_uniform  \\\n",
       " 0                                0.000000   \n",
       " 1                                0.000000   \n",
       " 2                                0.964079   \n",
       " 3                                0.985228   \n",
       " 4                                0.492614   \n",
       " 5                                0.000000   \n",
       " 6                                0.000000   \n",
       " 7                                0.000000   \n",
       " 8                                0.000000   \n",
       " 9                                0.000000   \n",
       " 10                               0.000000   \n",
       " 11                               0.000000   \n",
       " 12                               0.970951   \n",
       " 13                               1.324375   \n",
       " 14                               0.713331   \n",
       " 15                               0.627458   \n",
       " 16                               0.964079   \n",
       " 17                               0.000000   \n",
       " 18                               0.918296   \n",
       " 19                               0.000000   \n",
       " 20                               0.000000   \n",
       " 21                               0.970951   \n",
       " 22                               0.936667   \n",
       " 23                               0.000000   \n",
       " 24                               0.985475   \n",
       " 25                               0.000000   \n",
       " 26                               1.000000   \n",
       " 27                               0.000000   \n",
       " 28                               0.970951   \n",
       " 29                               0.764205   \n",
       " ...                                   ...   \n",
       " 5521                             0.000000   \n",
       " 5522                             1.061278   \n",
       " 5523                             0.629584   \n",
       " 5524                             0.845351   \n",
       " 5525                             0.413817   \n",
       " 5526                             0.899744   \n",
       " 5527                             1.143320   \n",
       " 5528                             1.061278   \n",
       " 5529                             0.000000   \n",
       " 5530                             0.000000   \n",
       " 5531                             0.000000   \n",
       " 5532                             0.000000   \n",
       " 5533                             1.584963   \n",
       " 5534                             1.117492   \n",
       " 5535                             0.650022   \n",
       " 5536                             0.000000   \n",
       " 5537                             0.000000   \n",
       " 5538                             0.000000   \n",
       " 5539                             0.970951   \n",
       " 5540                             0.000000   \n",
       " 5541                             0.000000   \n",
       " 5542                             0.954434   \n",
       " 5543                             0.918296   \n",
       " 5544                             0.000000   \n",
       " 5545                             0.000000   \n",
       " 5546                             0.868040   \n",
       " 5547                             0.863121   \n",
       " 5548                             0.000000   \n",
       " 5549                             0.000000   \n",
       " 5550                             1.370951   \n",
       " \n",
       "       wn_synsets_sense_entropy_pos_central  wn_synset_pos_ratio_1  \\\n",
       " 0                                -0.000000               1.000000   \n",
       " 1                                 4.643856               1.000000   \n",
       " 2                                 3.459432               0.611111   \n",
       " 3                                 2.000000               0.571429   \n",
       " 4                                -0.000000               0.785714   \n",
       " 5                                 2.807355               1.000000   \n",
       " 6                                 3.169925               1.000000   \n",
       " 7                                 2.584963               1.000000   \n",
       " 8                                 1.000000               1.000000   \n",
       " 9                                -0.000000               0.700000   \n",
       " 10                                2.321928               1.000000   \n",
       " 11                                3.169925               1.000000   \n",
       " 12                                1.000000               0.400000   \n",
       " 13                                2.807355               0.189189   \n",
       " 14                               -0.000000               0.481944   \n",
       " 15                               -0.000000               0.509259   \n",
       " 16                                3.459432               0.611111   \n",
       " 17                               -0.000000               0.250000   \n",
       " 18                                3.000000               0.666667   \n",
       " 19                                2.321928               1.000000   \n",
       " 20                                1.000000               1.000000   \n",
       " 21                                1.000000               0.400000   \n",
       " 22                                3.459432               0.647059   \n",
       " 23                                2.321928               1.000000   \n",
       " 24                               -0.000000               0.450000   \n",
       " 25                               -0.000000               1.000000   \n",
       " 26                                1.584963               0.500000   \n",
       " 27                                2.000000               1.000000   \n",
       " 28                                1.000000               0.400000   \n",
       " 29                                2.584963               0.222222   \n",
       " ...                                    ...                    ...   \n",
       " 5521                             -0.000000               0.000000   \n",
       " 5522                              2.584963               0.750000   \n",
       " 5523                             -0.000000               0.821970   \n",
       " 5524                              3.000000               0.727273   \n",
       " 5525                              3.459432               0.916667   \n",
       " 5526                              4.700440               0.684211   \n",
       " 5527                              3.807355               0.636364   \n",
       " 5528                             -0.000000               0.125000   \n",
       " 5529                             -0.000000               1.000000   \n",
       " 5530                             -0.000000               0.000000   \n",
       " 5531                              3.321928               1.000000   \n",
       " 5532                             -0.000000               1.000000   \n",
       " 5533                              1.000000               0.333333   \n",
       " 5534                             -0.000000               0.583333   \n",
       " 5535                              2.321928               0.833333   \n",
       " 5536                             -0.000000               1.000000   \n",
       " 5537                              1.000000               1.000000   \n",
       " 5538                             -0.000000               0.000000   \n",
       " 5539                              1.000000               0.400000   \n",
       " 5540                              2.000000               1.000000   \n",
       " 5541                              1.584963               1.000000   \n",
       " 5542                              3.321928               0.625000   \n",
       " 5543                              1.000000               0.666667   \n",
       " 5544                              3.000000               1.000000   \n",
       " 5545                              3.169925               1.000000   \n",
       " 5546                              4.754888               0.710526   \n",
       " 5547                              2.321928               0.714286   \n",
       " 5548                              1.584963               1.000000   \n",
       " 5549                              1.584963               1.000000   \n",
       " 5550                              1.584963               0.600000   \n",
       " \n",
       "       wn_synset_pos_ratio_2  swn_avg_objective_score  \\\n",
       " 0                  1.000000                 1.000000   \n",
       " 1                  1.000000                 0.955000   \n",
       " 2                  0.907990                 0.993056   \n",
       " 3                  0.351351                 0.928571   \n",
       " 4                  0.675676                 0.964286   \n",
       " 5                  1.000000                 1.000000   \n",
       " 6                  1.000000                 0.833333   \n",
       " 7                  1.000000                 1.000000   \n",
       " 8                  1.000000                 1.000000   \n",
       " 9                  0.700000                 0.597222   \n",
       " 10                 1.000000                 1.000000   \n",
       " 11                 1.000000                 0.986111   \n",
       " 12                 0.600000                 1.000000   \n",
       " 13                 0.012397                 0.918919   \n",
       " 14                 0.645105                 0.724826   \n",
       " 15                 0.660140                 0.633102   \n",
       " 16                 0.907990                 0.993056   \n",
       " 17                 0.250000                 0.000000   \n",
       " 18                 0.822430                 0.906250   \n",
       " 19                 1.000000                 1.000000   \n",
       " 20                 1.000000                 1.000000   \n",
       " 21                 0.600000                 1.000000   \n",
       " 22                 0.797834                 0.955882   \n",
       " 23                 1.000000                 0.550000   \n",
       " 24                 0.520930                 1.000000   \n",
       " 25                 0.250000                 1.000000   \n",
       " 26                 0.441860                 1.000000   \n",
       " 27                 1.000000                 1.000000   \n",
       " 28                 0.600000                 1.000000   \n",
       " 29                 0.052083                 0.944444   \n",
       " ...                     ...                      ...   \n",
       " 5521               0.000000                 0.964286   \n",
       " 5522               0.743590                 0.718750   \n",
       " 5523               0.755319                 0.983902   \n",
       " 5524               0.510638                 0.988636   \n",
       " 5525               1.000000                 0.979167   \n",
       " 5526               0.934400                 0.976974   \n",
       " 5527               0.720000                 0.659091   \n",
       " 5528               0.051282                 0.718750   \n",
       " 5529               1.000000                 1.000000   \n",
       " 5530               0.000000                 1.000000   \n",
       " 5531               1.000000                 1.000000   \n",
       " 5532               1.000000                 1.000000   \n",
       " 5533               0.764706                 0.916667   \n",
       " 5534               0.866224                 0.947917   \n",
       " 5535               0.967742                 0.979167   \n",
       " 5536               1.000000                 1.000000   \n",
       " 5537               1.000000                 1.000000   \n",
       " 5538               0.000000                 1.000000   \n",
       " 5539               0.611111                 1.000000   \n",
       " 5540               1.000000                 0.718750   \n",
       " 5541               1.000000                 1.000000   \n",
       " 5542               0.682731                 0.937500   \n",
       " 5543               0.826087                 0.833333   \n",
       " 5544               1.000000                 0.984375   \n",
       " 5545               1.000000                 0.958333   \n",
       " 5546               0.574760                 0.944079   \n",
       " 5547               0.804688                 1.000000   \n",
       " 5548               1.000000                 1.000000   \n",
       " 5549               1.000000                 1.000000   \n",
       " 5550               0.884615                 1.000000   \n",
       " \n",
       "       wn_synsets_freq_ratio_to_max_agg_min  \\\n",
       " 0                                 0.189436   \n",
       " 1                                 0.333867   \n",
       " 2                                 0.347925   \n",
       " 3                                 0.512238   \n",
       " 4                                 0.415089   \n",
       " 5                                 0.317939   \n",
       " 6                                 0.028839   \n",
       " 7                                 1.000000   \n",
       " 8                                 1.000000   \n",
       " 9                                 0.713637   \n",
       " 10                                0.360355   \n",
       " 11                                0.207832   \n",
       " 12                                0.103653   \n",
       " 13                                0.160432   \n",
       " 14                                0.554222   \n",
       " 15                                0.704412   \n",
       " 16                                0.347925   \n",
       " 17                                1.000000   \n",
       " 18                                0.765310   \n",
       " 19                                0.058221   \n",
       " 20                                1.000000   \n",
       " 21                                0.103653   \n",
       " 22                                1.000000   \n",
       " 23                                1.000000   \n",
       " 24                                0.464640   \n",
       " 25                                0.009217   \n",
       " 26                                0.825626   \n",
       " 27                                1.000000   \n",
       " 28                                0.103653   \n",
       " 29                                0.169803   \n",
       " ...                                    ...   \n",
       " 5521                              0.071359   \n",
       " 5522                              1.000000   \n",
       " 5523                              0.515770   \n",
       " 5524                              0.031540   \n",
       " 5525                              1.000000   \n",
       " 5526                              0.065743   \n",
       " 5527                              1.000000   \n",
       " 5528                              1.000000   \n",
       " 5529                              1.000000   \n",
       " 5530                              0.293443   \n",
       " 5531                              0.127308   \n",
       " 5532                              1.000000   \n",
       " 5533                              0.689584   \n",
       " 5534                              0.844792   \n",
       " 5535                              1.000000   \n",
       " 5536                              0.035795   \n",
       " 5537                              0.364411   \n",
       " 5538                              1.000000   \n",
       " 5539                              1.000000   \n",
       " 5540                              1.000000   \n",
       " 5541                              0.976458   \n",
       " 5542                              0.100407   \n",
       " 5543                              1.000000   \n",
       " 5544                              1.000000   \n",
       " 5545                              1.000000   \n",
       " 5546                              0.431929   \n",
       " 5547                              1.000000   \n",
       " 5548                              1.000000   \n",
       " 5549                              0.123264   \n",
       " 5550                              1.000000   \n",
       " \n",
       "       wn_synsets_freq_ratio_to_max_agg_mean  \\\n",
       " 0                                  0.189436   \n",
       " 1                                  0.004366   \n",
       " 2                                  0.347925   \n",
       " 3                                  0.019643   \n",
       " 4                                  0.168791   \n",
       " 5                                  0.317939   \n",
       " 6                                  0.014078   \n",
       " 7                                  0.028216   \n",
       " 8                                  1.000000   \n",
       " 9                                  0.713637   \n",
       " 10                                 0.360355   \n",
       " 11                                 0.207832   \n",
       " 12                                 0.092333   \n",
       " 13                                 0.002098   \n",
       " 14                                 0.534061   \n",
       " 15                                 0.681304   \n",
       " 16                                 0.347925   \n",
       " 17                                 1.000000   \n",
       " 18                                 0.695987   \n",
       " 19                                 0.026997   \n",
       " 20                                 0.018887   \n",
       " 21                                 0.092333   \n",
       " 22                                 1.000000   \n",
       " 23                                 0.013422   \n",
       " 24                                 0.458980   \n",
       " 25                                 0.004396   \n",
       " 26                                 0.825626   \n",
       " 27                                 0.051250   \n",
       " 28                                 0.092333   \n",
       " 29                                 0.004209   \n",
       " ...                                     ...   \n",
       " 5521                               0.023946   \n",
       " 5522                               1.000000   \n",
       " 5523                               0.061322   \n",
       " 5524                               0.020577   \n",
       " 5525                               0.102067   \n",
       " 5526                               0.003625   \n",
       " 5527                               1.000000   \n",
       " 5528                               1.000000   \n",
       " 5529                               1.000000   \n",
       " 5530                               0.293443   \n",
       " 5531                               0.042720   \n",
       " 5532                               1.000000   \n",
       " 5533                               0.181725   \n",
       " 5534                               0.468761   \n",
       " 5535                               0.755797   \n",
       " 5536                               0.035795   \n",
       " 5537                               0.364411   \n",
       " 5538                               1.000000   \n",
       " 5539                               1.000000   \n",
       " 5540                               1.000000   \n",
       " 5541                               0.976458   \n",
       " 5542                               0.002400   \n",
       " 5543                               1.000000   \n",
       " 5544                               1.000000   \n",
       " 5545                               1.000000   \n",
       " 5546                               0.023464   \n",
       " 5547                               1.000000   \n",
       " 5548                               0.763270   \n",
       " 5549                               0.005613   \n",
       " 5550                               0.826068   \n",
       " \n",
       "       wn_synsets_freq_ratio_to_max_agg_median  wn_synsets_avg_lemma_freq  \\\n",
       " 0                                    0.189436              105340.600000   \n",
       " 1                                    0.025479               72545.669725   \n",
       " 2                                    0.347925              291977.555556   \n",
       " 3                                    0.119332              168836.846154   \n",
       " 4                                    0.218636              117411.923077   \n",
       " 5                                    0.317939               65987.000000   \n",
       " 6                                    0.014078               19710.937500   \n",
       " 7                                    0.919014              331001.400000   \n",
       " 8                                    1.000000              232392.000000   \n",
       " 9                                    0.713637              157901.727451   \n",
       " 10                                   0.360355              494925.470588   \n",
       " 11                                   0.207832               62191.166667   \n",
       " 12                                   0.092333               36038.500000   \n",
       " 13                                   0.012243               72222.557823   \n",
       " 14                                   0.534061              133815.741162   \n",
       " 15                                   0.681304              166408.154882   \n",
       " 16                                   0.347925              291977.555556   \n",
       " 17                                   1.000000                   0.000000   \n",
       " 18                                   0.695987              207246.909091   \n",
       " 19                                   0.026997               25006.125000   \n",
       " 20                                   1.000000              245390.000000   \n",
       " 21                                   0.092333               36038.500000   \n",
       " 22                                   1.000000              538062.000000   \n",
       " 23                                   0.013422              244573.222222   \n",
       " 24                                   0.458980               32246.931818   \n",
       " 25                                   0.004396                 327.333333   \n",
       " 26                                   0.825626               28455.363636   \n",
       " 27                                   0.051250              446187.666667   \n",
       " 28                                   0.092333               36038.500000   \n",
       " 29                                   0.004209               66846.657143   \n",
       " ...                                       ...                        ...   \n",
       " 5521                                 0.023946               74031.978723   \n",
       " 5522                                 1.000000               38458.714286   \n",
       " 5523                                 0.061322               38248.283898   \n",
       " 5524                                 0.020577               59565.067797   \n",
       " 5525                                 0.102067               16931.500000   \n",
       " 5526                                 0.010240              150196.562500   \n",
       " 5527                                 1.000000              157248.903226   \n",
       " 5528                                 1.000000               38458.714286   \n",
       " 5529                                 1.000000                4573.000000   \n",
       " 5530                                 0.293443                 610.000000   \n",
       " 5531                                 0.042720               77523.407407   \n",
       " 5532                                 1.000000               36460.000000   \n",
       " 5533                                 0.181725               37724.000000   \n",
       " 5534                                 0.468761               43849.600000   \n",
       " 5535                                 0.755797               49975.200000   \n",
       " 5536                                 0.035795              129602.666667   \n",
       " 5537                                 0.364411              103719.750000   \n",
       " 5538                                 1.000000              120924.000000   \n",
       " 5539                                 1.000000              177067.428571   \n",
       " 5540                                 1.000000               37957.000000   \n",
       " 5541                                 0.976458              125772.500000   \n",
       " 5542                                 0.003717              287559.342105   \n",
       " 5543                                 1.000000               30747.100000   \n",
       " 5544                                 1.000000              361364.181818   \n",
       " 5545                                 1.000000               95548.642857   \n",
       " 5546                                 0.062571              460928.215054   \n",
       " 5547                                 1.000000              433566.681818   \n",
       " 5548                                 0.763270              155925.933333   \n",
       " 5549                                 0.123264              170809.857143   \n",
       " 5550                                 0.826068              173803.538462   \n",
       " \n",
       "       wn_synsets_freq_ratio_to_avg  wn_synset_lesk_wsd_ratio_hi_freq  \\\n",
       " 0                         1.744483                          0.400000   \n",
       " 1                         0.408174                          0.000000   \n",
       " 2                         0.582399                          0.333333   \n",
       " 3                         0.694776                          0.000000   \n",
       " 4                         0.848128                          0.500000   \n",
       " 5                         1.948588                          1.000000   \n",
       " 6                         1.409938                          0.500000   \n",
       " 7                         0.600000                          0.000000   \n",
       " 8                         1.000000                          0.000000   \n",
       " 9                         0.017378                          0.000000   \n",
       " 10                        0.953160                          0.000000   \n",
       " 11                        0.691851                          0.000000   \n",
       " 12                        1.369400                          0.200000   \n",
       " 13                        0.845648                          0.000000   \n",
       " 14                        0.659262                          0.300000   \n",
       " 15                        0.635473                          0.333333   \n",
       " 16                        0.582399                          0.000000   \n",
       " 17                        0.000000                          0.000000   \n",
       " 18                        0.729085                          1.000000   \n",
       " 19                        1.269540                          0.500000   \n",
       " 20                        0.666667                          0.000000   \n",
       " 21                        1.369400                          0.200000   \n",
       " 22                        0.523710                          0.000000   \n",
       " 23                        0.627874                          0.000000   \n",
       " 24                        0.992931                          0.600000   \n",
       " 25                        1.121005                          1.000000   \n",
       " 26                        0.736499                          1.000000   \n",
       " 27                        0.354069                          0.000000   \n",
       " 28                        1.369400                          0.200000   \n",
       " 29                        0.905634                          0.000000   \n",
       " ...                            ...                               ...   \n",
       " 5521                      3.514454                          0.000000   \n",
       " 5522                      0.395373                          0.000000   \n",
       " 5523                      0.996594                          0.000000   \n",
       " 5524                      1.249765                          0.000000   \n",
       " 5525                      0.581898                          0.000000   \n",
       " 5526                      2.123100                          1.000000   \n",
       " 5527                      0.362995                          0.000000   \n",
       " 5528                      0.395373                          0.000000   \n",
       " 5529                      1.000000                          0.000000   \n",
       " 5530                      3.407821                          0.000000   \n",
       " 5531                      2.062835                          0.800000   \n",
       " 5532                      0.339615                          0.000000   \n",
       " 5533                      0.517710                          0.000000   \n",
       " 5534                      0.570698                          0.000000   \n",
       " 5535                      0.618482                          0.000000   \n",
       " 5536                      9.868474                          0.333333   \n",
       " 5537                      0.617758                          0.000000   \n",
       " 5538                      1.000000                          0.000000   \n",
       " 5539                      0.714561                          0.000000   \n",
       " 5540                      0.823077                          0.000000   \n",
       " 5541                      0.620602                          0.000000   \n",
       " 5542                      2.661502                          0.500000   \n",
       " 5543                      0.355211                          0.000000   \n",
       " 5544                      0.769423                          0.000000   \n",
       " 5545                      0.721808                          0.000000   \n",
       " 5546                      0.991706                          1.000000   \n",
       " 5547                      0.347504                          0.000000   \n",
       " 5548                      0.323169                          0.000000   \n",
       " 5549                      1.554583                          0.666667   \n",
       " 5550                      0.399233                          0.000000   \n",
       " \n",
       "       wn_synset_lesk_wsd_ratio_low_freq  \\\n",
       " 0                              0.400000   \n",
       " 1                              1.000000   \n",
       " 2                              0.333333   \n",
       " 3                              0.000000   \n",
       " 4                              0.000000   \n",
       " 5                              0.000000   \n",
       " 6                              0.500000   \n",
       " 7                              0.500000   \n",
       " 8                              0.000000   \n",
       " 9                              0.133333   \n",
       " 10                             0.666667   \n",
       " 11                             0.000000   \n",
       " 12                             0.600000   \n",
       " 13                             0.500000   \n",
       " 14                             0.316667   \n",
       " 15                             0.222222   \n",
       " 16                             0.666667   \n",
       " 17                             0.000000   \n",
       " 18                             0.000000   \n",
       " 19                             0.500000   \n",
       " 20                             0.500000   \n",
       " 21                             0.600000   \n",
       " 22                             0.666667   \n",
       " 23                             0.500000   \n",
       " 24                             0.300000   \n",
       " 25                             0.000000   \n",
       " 26                             0.000000   \n",
       " 27                             1.000000   \n",
       " 28                             0.600000   \n",
       " 29                             0.000000   \n",
       " ...                                 ...   \n",
       " 5521                           0.000000   \n",
       " 5522                           0.000000   \n",
       " 5523                           0.000000   \n",
       " 5524                           0.000000   \n",
       " 5525                           0.000000   \n",
       " 5526                           0.000000   \n",
       " 5527                           0.000000   \n",
       " 5528                           0.000000   \n",
       " 5529                           0.000000   \n",
       " 5530                           0.000000   \n",
       " 5531                           0.200000   \n",
       " 5532                           0.666667   \n",
       " 5533                           0.000000   \n",
       " 5534                           0.000000   \n",
       " 5535                           0.000000   \n",
       " 5536                           0.333333   \n",
       " 5537                           0.666667   \n",
       " 5538                           0.000000   \n",
       " 5539                           0.500000   \n",
       " 5540                           0.000000   \n",
       " 5541                           0.000000   \n",
       " 5542                           0.500000   \n",
       " 5543                           0.000000   \n",
       " 5544                           0.000000   \n",
       " 5545                           0.500000   \n",
       " 5546                           0.000000   \n",
       " 5547                           0.900000   \n",
       " 5548                           0.777778   \n",
       " 5549                           0.000000   \n",
       " 5550                           0.666667   \n",
       " \n",
       "       wn_synset_lesk_wsd_ratio_hi_nopos_freq  \\\n",
       " 0                                   0.400000   \n",
       " 1                                   0.000000   \n",
       " 2                                   0.333333   \n",
       " 3                                   0.000000   \n",
       " 4                                   0.500000   \n",
       " 5                                   1.000000   \n",
       " 6                                   0.500000   \n",
       " 7                                   0.000000   \n",
       " 8                                   0.000000   \n",
       " 9                                   0.000000   \n",
       " 10                                  0.000000   \n",
       " 11                                  0.000000   \n",
       " 12                                  0.200000   \n",
       " 13                                  0.000000   \n",
       " 14                                  0.300000   \n",
       " 15                                  0.333333   \n",
       " 16                                  0.000000   \n",
       " 17                                  0.000000   \n",
       " 18                                  1.000000   \n",
       " 19                                  0.500000   \n",
       " 20                                  0.000000   \n",
       " 21                                  0.200000   \n",
       " 22                                  0.000000   \n",
       " 23                                  0.000000   \n",
       " 24                                  0.600000   \n",
       " 25                                  1.000000   \n",
       " 26                                  1.000000   \n",
       " 27                                  0.000000   \n",
       " 28                                  0.200000   \n",
       " 29                                  0.000000   \n",
       " ...                                      ...   \n",
       " 5521                                1.000000   \n",
       " 5522                                0.000000   \n",
       " 5523                                0.000000   \n",
       " 5524                                0.000000   \n",
       " 5525                                0.000000   \n",
       " 5526                                1.000000   \n",
       " 5527                                0.000000   \n",
       " 5528                                0.000000   \n",
       " 5529                                0.000000   \n",
       " 5530                                1.000000   \n",
       " 5531                                0.800000   \n",
       " 5532                                0.000000   \n",
       " 5533                                0.000000   \n",
       " 5534                                0.000000   \n",
       " 5535                                0.000000   \n",
       " 5536                                0.333333   \n",
       " 5537                                0.000000   \n",
       " 5538                                0.000000   \n",
       " 5539                                0.000000   \n",
       " 5540                                0.000000   \n",
       " 5541                                0.000000   \n",
       " 5542                                0.500000   \n",
       " 5543                                0.000000   \n",
       " 5544                                0.000000   \n",
       " 5545                                0.000000   \n",
       " 5546                                1.000000   \n",
       " 5547                                0.000000   \n",
       " 5548                                0.000000   \n",
       " 5549                                0.666667   \n",
       " 5550                                0.000000   \n",
       " \n",
       "       wn_synset_lesk_wsd_ratio_low_nopos_freq  \\\n",
       " 0                                    0.400000   \n",
       " 1                                    1.000000   \n",
       " 2                                    0.333333   \n",
       " 3                                    0.500000   \n",
       " 4                                    0.250000   \n",
       " 5                                    0.000000   \n",
       " 6                                    0.500000   \n",
       " 7                                    0.500000   \n",
       " 8                                    0.000000   \n",
       " 9                                    0.133333   \n",
       " 10                                   0.666667   \n",
       " 11                                   0.000000   \n",
       " 12                                   0.600000   \n",
       " 13                                   0.500000   \n",
       " 14                                   0.316667   \n",
       " 15                                   0.222222   \n",
       " 16                                   0.666667   \n",
       " 17                                   0.000000   \n",
       " 18                                   0.000000   \n",
       " 19                                   0.500000   \n",
       " 20                                   0.500000   \n",
       " 21                                   0.600000   \n",
       " 22                                   0.666667   \n",
       " 23                                   0.500000   \n",
       " 24                                   0.300000   \n",
       " 25                                   0.000000   \n",
       " 26                                   0.000000   \n",
       " 27                                   1.000000   \n",
       " 28                                   0.600000   \n",
       " 29                                   0.000000   \n",
       " ...                                       ...   \n",
       " 5521                                 0.000000   \n",
       " 5522                                 0.500000   \n",
       " 5523                                 0.000000   \n",
       " 5524                                 0.000000   \n",
       " 5525                                 0.000000   \n",
       " 5526                                 0.000000   \n",
       " 5527                                 0.666667   \n",
       " 5528                                 0.500000   \n",
       " 5529                                 0.000000   \n",
       " 5530                                 0.000000   \n",
       " 5531                                 0.200000   \n",
       " 5532                                 0.666667   \n",
       " 5533                                 0.800000   \n",
       " 5534                                 0.400000   \n",
       " 5535                                 0.000000   \n",
       " 5536                                 0.333333   \n",
       " 5537                                 0.666667   \n",
       " 5538                                 0.000000   \n",
       " 5539                                 0.500000   \n",
       " 5540                                 0.000000   \n",
       " 5541                                 0.000000   \n",
       " 5542                                 0.500000   \n",
       " 5543                                 0.500000   \n",
       " 5544                                 0.000000   \n",
       " 5545                                 0.500000   \n",
       " 5546                                 0.000000   \n",
       " 5547                                 0.900000   \n",
       " 5548                                 0.777778   \n",
       " 5549                                 0.000000   \n",
       " 5550                                 0.666667   \n",
       " \n",
       "       wn_synset_lesk_wsd_ratio_hi_freq_sum  \\\n",
       " 0                                 0.879779   \n",
       " 1                                 0.000000   \n",
       " 2                                 0.456629   \n",
       " 3                                 0.000000   \n",
       " 4                                 0.500000   \n",
       " 5                                 1.000000   \n",
       " 6                                 0.727137   \n",
       " 7                                 0.000000   \n",
       " 8                                 0.000000   \n",
       " 9                                 0.000000   \n",
       " 10                                0.000000   \n",
       " 11                                0.000000   \n",
       " 12                                0.900928   \n",
       " 13                                0.000000   \n",
       " 14                                0.475232   \n",
       " 15                                0.333333   \n",
       " 16                                0.000000   \n",
       " 17                                0.000000   \n",
       " 18                                1.000000   \n",
       " 19                                0.991095   \n",
       " 20                                0.000000   \n",
       " 21                                0.900928   \n",
       " 22                                0.000000   \n",
       " 23                                0.000000   \n",
       " 24                                0.950464   \n",
       " 25                                1.000000   \n",
       " 26                                1.000000   \n",
       " 27                                0.000000   \n",
       " 28                                0.900928   \n",
       " 29                                0.000000   \n",
       " ...                                    ...   \n",
       " 5521                              0.000000   \n",
       " 5522                              0.000000   \n",
       " 5523                              0.000000   \n",
       " 5524                              0.000000   \n",
       " 5525                              0.000000   \n",
       " 5526                              1.000000   \n",
       " 5527                              0.000000   \n",
       " 5528                              0.000000   \n",
       " 5529                              0.000000   \n",
       " 5530                              0.000000   \n",
       " 5531                              0.960363   \n",
       " 5532                              0.000000   \n",
       " 5533                              0.000000   \n",
       " 5534                              0.000000   \n",
       " 5535                              0.000000   \n",
       " 5536                              0.943633   \n",
       " 5537                              0.000000   \n",
       " 5538                              0.000000   \n",
       " 5539                              0.000000   \n",
       " 5540                              0.000000   \n",
       " 5541                              0.000000   \n",
       " 5542                              0.999564   \n",
       " 5543                              0.000000   \n",
       " 5544                              0.000000   \n",
       " 5545                              0.000000   \n",
       " 5546                              1.000000   \n",
       " 5547                              0.000000   \n",
       " 5548                              0.000000   \n",
       " 5549                              0.911565   \n",
       " 5550                              0.000000   \n",
       " \n",
       "       wn_synset_lesk_wsd_ratio_low_freq_sum  \\\n",
       " 0                                  0.005574   \n",
       " 1                                  1.000000   \n",
       " 2                                  0.102494   \n",
       " 3                                  0.000000   \n",
       " 4                                  0.000000   \n",
       " 5                                  0.000000   \n",
       " 6                                  0.272863   \n",
       " 7                                  0.001773   \n",
       " 8                                  0.000000   \n",
       " 9                                  0.108674   \n",
       " 10                                 0.543371   \n",
       " 11                                 0.000000   \n",
       " 12                                 0.005688   \n",
       " 13                                 0.023619   \n",
       " 14                                 0.097449   \n",
       " 15                                 0.128036   \n",
       " 16                                 0.384107   \n",
       " 17                                 0.000000   \n",
       " 18                                 0.000000   \n",
       " 19                                 0.008905   \n",
       " 20                                 0.163895   \n",
       " 21                                 0.005688   \n",
       " 22                                 0.088355   \n",
       " 23                                 0.059359   \n",
       " 24                                 0.002844   \n",
       " 25                                 0.000000   \n",
       " 26                                 0.000000   \n",
       " 27                                 1.000000   \n",
       " 28                                 0.005688   \n",
       " 29                                 0.000000   \n",
       " ...                                     ...   \n",
       " 5521                               0.000000   \n",
       " 5522                               0.000000   \n",
       " 5523                               0.000000   \n",
       " 5524                               0.000000   \n",
       " 5525                               0.000000   \n",
       " 5526                               0.000000   \n",
       " 5527                               0.000000   \n",
       " 5528                               0.000000   \n",
       " 5529                               0.000000   \n",
       " 5530                               0.000000   \n",
       " 5531                               0.039637   \n",
       " 5532                               0.018495   \n",
       " 5533                               0.000000   \n",
       " 5534                               0.000000   \n",
       " 5535                               0.000000   \n",
       " 5536                               0.022590   \n",
       " 5537                               0.162007   \n",
       " 5538                               0.000000   \n",
       " 5539                               0.449899   \n",
       " 5540                               0.000000   \n",
       " 5541                               0.000000   \n",
       " 5542                               0.000436   \n",
       " 5543                               0.000000   \n",
       " 5544                               0.000000   \n",
       " 5545                               0.317142   \n",
       " 5546                               0.000000   \n",
       " 5547                               0.295570   \n",
       " 5548                               0.362164   \n",
       " 5549                               0.000000   \n",
       " 5550                               0.145537   \n",
       " \n",
       "       wn_synset_lesk_wsd_ratio_to_freq_sum  \\\n",
       " 0                                 0.114647   \n",
       " 1                                 0.949241   \n",
       " 2                                 0.440878   \n",
       " 3                                 1.000000   \n",
       " 4                                 0.658969   \n",
       " 5                                 0.317939   \n",
       " 6                                 0.341843   \n",
       " 7                                 0.998227   \n",
       " 8                                 1.000000   \n",
       " 9                                 0.491326   \n",
       " 10                                0.456629   \n",
       " 11                                1.000000   \n",
       " 12                                0.093384   \n",
       " 13                                0.976381   \n",
       " 14                                0.368647   \n",
       " 15                                0.460401   \n",
       " 16                                0.615893   \n",
       " 17                                0.000000   \n",
       " 18                                0.765310   \n",
       " 19                                0.082388   \n",
       " 20                                0.836105   \n",
       " 21                                0.093384   \n",
       " 22                                0.911645   \n",
       " 23                                0.940641   \n",
       " 24                                0.459505   \n",
       " 25                                0.008715   \n",
       " 26                                0.825626   \n",
       " 27                                1.890660   \n",
       " 28                                0.093384   \n",
       " 29                                1.000000   \n",
       " ...                                    ...   \n",
       " 5521                              0.000000   \n",
       " 5522                              0.000000   \n",
       " 5523                              1.000000   \n",
       " 5524                              1.000000   \n",
       " 5525                              1.000000   \n",
       " 5526                              0.401464   \n",
       " 5527                              1.000000   \n",
       " 5528                              1.000000   \n",
       " 5529                              1.000000   \n",
       " 5530                              0.000000   \n",
       " 5531                              0.058880   \n",
       " 5532                              0.981505   \n",
       " 5533                              0.000000   \n",
       " 5534                              0.500000   \n",
       " 5535                              1.000000   \n",
       " 5536                              0.033778   \n",
       " 5537                              0.837993   \n",
       " 5538                              0.000000   \n",
       " 5539                              0.550101   \n",
       " 5540                              1.000000   \n",
       " 5541                              1.000000   \n",
       " 5542                              0.117071   \n",
       " 5543                              1.000000   \n",
       " 5544                              1.000000   \n",
       " 5545                              0.682858   \n",
       " 5546                              0.431929   \n",
       " 5547                              0.704430   \n",
       " 5548                              0.318918   \n",
       " 5549                              0.088435   \n",
       " 5550                              0.427231   \n",
       " \n",
       "       wn_synset_lesk_wsd__norm_sense_rank  \n",
       " 0                                0.000000  \n",
       " 1                                0.080000  \n",
       " 2                                0.166667  \n",
       " 3                                0.857143  \n",
       " 4                                0.500000  \n",
       " 5                                0.142857  \n",
       " 6                                0.444444  \n",
       " 7                                0.833333  \n",
       " 8                                0.000000  \n",
       " 9                                0.208889  \n",
       " 10                               0.600000  \n",
       " 11                               0.444444  \n",
       " 12                               0.400000  \n",
       " 13                               0.810811  \n",
       " 14                               0.169444  \n",
       " 15                               0.092593  \n",
       " 16                               0.277778  \n",
       " 17                               0.000000  \n",
       " 18                               0.000000  \n",
       " 19                               0.400000  \n",
       " 20                               0.000000  \n",
       " 21                               0.400000  \n",
       " 22                               0.294118  \n",
       " 23                               0.400000  \n",
       " 24                               0.533333  \n",
       " 25                               0.000000  \n",
       " 26                               0.666667  \n",
       " 27                               0.500000  \n",
       " 28                               0.400000  \n",
       " 29                               0.777778  \n",
       " ...                                   ...  \n",
       " 5521                             0.000000  \n",
       " 5522                             0.000000  \n",
       " 5523                             0.299242  \n",
       " 5524                             0.181818  \n",
       " 5525                             0.416667  \n",
       " 5526                             0.921053  \n",
       " 5527                             0.000000  \n",
       " 5528                             0.250000  \n",
       " 5529                             0.000000  \n",
       " 5530                             0.000000  \n",
       " 5531                             0.400000  \n",
       " 5532                             0.000000  \n",
       " 5533                             0.000000  \n",
       " 5534                             0.166667  \n",
       " 5535                             0.333333  \n",
       " 5536                             0.000000  \n",
       " 5537                             0.500000  \n",
       " 5538                             0.000000  \n",
       " 5539                             0.400000  \n",
       " 5540                             0.750000  \n",
       " 5541                             0.666667  \n",
       " 5542                             0.687500  \n",
       " 5543                             0.666667  \n",
       " 5544                             0.250000  \n",
       " 5545                             0.777778  \n",
       " 5546                             0.473684  \n",
       " 5547                             0.000000  \n",
       " 5548                             0.333333  \n",
       " 5549                             0.000000  \n",
       " 5550                             0.200000  \n",
       " \n",
       " [5551 rows x 39 columns],\n",
       "        binary  wn_synset_freq  wn_synset_avg_lemma_freq  \\\n",
       " 5551        1            1.00                  5.000000   \n",
       " 5552        1           25.00                  4.360000   \n",
       " 5553        0           18.00                  3.000000   \n",
       " 5554        1            7.00                  1.857143   \n",
       " 5555        1            7.00                  1.785714   \n",
       " 5556        1            7.00                  1.714286   \n",
       " 5557        1            9.00                  3.555556   \n",
       " 5558        0            6.00                  1.666667   \n",
       " 5559        1            2.00                  1.000000   \n",
       " 5560        0            3.20                  1.413333   \n",
       " 5561        1            5.00                  3.400000   \n",
       " 5562        0            9.00                  2.666667   \n",
       " 5563        1            5.00                  3.600000   \n",
       " 5564        0           37.00                  3.972973   \n",
       " 5565        1            8.75                  2.108333   \n",
       " 5566        1           10.00                  1.611111   \n",
       " 5567        0           18.00                  3.000000   \n",
       " 5568        1            0.00                  0.000000   \n",
       " 5569        0           12.00                  1.833333   \n",
       " 5570        1            5.00                  3.200000   \n",
       " 5571        0            2.00                  1.500000   \n",
       " 5572        1            5.00                  3.600000   \n",
       " 5573        0           17.00                  2.176471   \n",
       " 5574        0            5.00                  1.800000   \n",
       " 5575        1            5.50                  2.716667   \n",
       " 5576        0            1.00                  3.000000   \n",
       " 5577        0            6.00                  1.833333   \n",
       " 5578        0            4.00                  1.500000   \n",
       " 5579        0            5.00                  3.600000   \n",
       " 5580        1           27.00                  2.592593   \n",
       " ...       ...             ...                       ...   \n",
       " 11072       0           21.00                  2.238095   \n",
       " 11073       0            8.00                  2.625000   \n",
       " 11074       1           11.50                  3.598485   \n",
       " 11075       0           11.00                  5.363636   \n",
       " 11076       1           12.00                  1.833333   \n",
       " 11077       0           38.00                  2.105263   \n",
       " 11078       0           22.00                  2.818182   \n",
       " 11079       0            8.00                  2.625000   \n",
       " 11080       1            1.00                  1.000000   \n",
       " 11081       1            1.00                  1.000000   \n",
       " 11082       0           10.00                  2.700000   \n",
       " 11083       0            1.00                  3.000000   \n",
       " 11084       1            6.00                  3.333333   \n",
       " 11085       1            6.00                  2.500000   \n",
       " 11086       1            6.00                  1.666667   \n",
       " 11087       1            1.00                  3.000000   \n",
       " 11088       0            2.00                  4.000000   \n",
       " 11089       0            1.00                  1.000000   \n",
       " 11090       0            5.00                  1.400000   \n",
       " 11091       1            4.00                  1.500000   \n",
       " 11092       0            3.00                  2.666667   \n",
       " 11093       0           16.00                  2.375000   \n",
       " 11094       1            3.00                  3.333333   \n",
       " 11095       1            8.00                  1.375000   \n",
       " 11096       1            9.00                  1.555556   \n",
       " 11097       0           38.00                  2.447368   \n",
       " 11098       0            7.00                  3.142857   \n",
       " 11099       0            3.00                  5.000000   \n",
       " 11100       0            3.00                  4.666667   \n",
       " 11101       0            5.00                  2.600000   \n",
       " \n",
       "        wn_synset_avg_lemma_len  wn_synset_diff_len_avg_lemma_len  \\\n",
       " 5551                  9.000000                          1.000000   \n",
       " 5552                  6.284404                          0.284404   \n",
       " 5553                  6.500000                          2.500000   \n",
       " 5554                  7.461538                          1.461538   \n",
       " 5555                  8.855769                          0.355769   \n",
       " 5556                 10.250000                         -0.750000   \n",
       " 5557                  8.312500                         -1.687500   \n",
       " 5558                 12.800000                          3.800000   \n",
       " 5559                 11.000000                          0.000000   \n",
       " 5560                  5.454902                         -1.345098   \n",
       " 5561                  6.941176                         -0.058824   \n",
       " 5562                  9.333333                         -0.666667   \n",
       " 5563                  9.333333                         -0.666667   \n",
       " 5564                  6.632653                         -0.367347   \n",
       " 5565                  5.674242                         -1.825758   \n",
       " 5566                  4.454545                         -2.212121   \n",
       " 5567                  6.500000                          2.500000   \n",
       " 5568                  0.000000                        -10.000000   \n",
       " 5569                  6.863636                          0.863636   \n",
       " 5570                  7.125000                         -0.875000   \n",
       " 5571                 14.333333                          5.333333   \n",
       " 5572                  9.333333                         -0.666667   \n",
       " 5573                  6.675676                          0.675676   \n",
       " 5574                  9.444444                          0.444444   \n",
       " 5575                  8.439394                         -0.560606   \n",
       " 5576                 10.666667                          2.666667   \n",
       " 5577                  7.545455                         -0.454545   \n",
       " 5578                  6.500000                         -2.500000   \n",
       " 5579                  9.333333                         -0.666667   \n",
       " 5580                  6.328571                          0.328571   \n",
       " ...                        ...                               ...   \n",
       " 11072                 6.893617                         -1.106383   \n",
       " 11073                 9.095238                          3.095238   \n",
       " 11074                 5.909476                          1.909476   \n",
       " 11075                 5.864407                          1.864407   \n",
       " 11076                 5.954545                          1.954545   \n",
       " 11077                 5.087500                          0.087500   \n",
       " 11078                 7.661290                          2.661290   \n",
       " 11079                 9.095238                          3.095238   \n",
       " 11080                 5.000000                          0.000000   \n",
       " 11081                 6.000000                         -1.000000   \n",
       " 11082                 5.370370                          0.370370   \n",
       " 11083                 7.333333                          5.333333   \n",
       " 11084                10.400000                         -0.600000   \n",
       " 11085                 9.900000                          0.900000   \n",
       " 11086                 9.400000                          2.400000   \n",
       " 11087                10.333333                         -0.666667   \n",
       " 11088                 6.625000                          1.625000   \n",
       " 11089                 7.000000                          0.000000   \n",
       " 11090                 7.142857                          1.142857   \n",
       " 11091                 8.500000                          0.500000   \n",
       " 11092                 6.625000                          0.625000   \n",
       " 11093                 5.315789                          1.315789   \n",
       " 11094                 6.600000                          1.600000   \n",
       " 11095                 8.909091                         -1.090909   \n",
       " 11096                 9.500000                          1.500000   \n",
       " 11097                 6.440860                          1.440860   \n",
       " 11098                 8.136364                          4.136364   \n",
       " 11099                 9.266667                         -0.733333   \n",
       " 11100                10.285714                          3.285714   \n",
       " 11101                 8.307692                          3.307692   \n",
       " \n",
       "        wn_synset_avg_hypernyms  wn_synset_sum_hypernyms  \\\n",
       " 5551                  0.000000                 0.000000   \n",
       " 5552                  0.840000                21.000000   \n",
       " 5553                  0.888889                16.000000   \n",
       " 5554                  0.428571                 3.000000   \n",
       " 5555                  0.714286                 5.000000   \n",
       " 5556                  1.000000                 7.000000   \n",
       " 5557                  0.888889                 8.000000   \n",
       " 5558                  1.000000                 6.000000   \n",
       " 5559                  0.000000                 0.000000   \n",
       " 5560                  0.400000                 2.800000   \n",
       " 5561                  1.000000                 5.000000   \n",
       " 5562                  1.000000                 9.000000   \n",
       " 5563                  0.600000                 3.000000   \n",
       " 5564                  0.756757                28.000000   \n",
       " 5565                  0.622222                 7.750000   \n",
       " 5566                  0.629630                 9.333333   \n",
       " 5567                  0.888889                16.000000   \n",
       " 5568                  0.000000                 0.000000   \n",
       " 5569                  1.000000                12.000000   \n",
       " 5570                  0.600000                 3.000000   \n",
       " 5571                  0.000000                 0.000000   \n",
       " 5572                  0.600000                 3.000000   \n",
       " 5573                  1.000000                17.000000   \n",
       " 5574                  0.000000                 0.000000   \n",
       " 5575                  0.800000                 4.500000   \n",
       " 5576                  1.000000                 1.000000   \n",
       " 5577                  1.000000                 6.000000   \n",
       " 5578                  0.750000                 3.000000   \n",
       " 5579                  0.600000                 3.000000   \n",
       " 5580                  0.925926                25.000000   \n",
       " ...                        ...                      ...   \n",
       " 11072                 1.000000                21.000000   \n",
       " 11073                 0.250000                 2.000000   \n",
       " 11074                 1.045455                12.000000   \n",
       " 11075                 1.090909                12.000000   \n",
       " 11076                 1.000000                12.000000   \n",
       " 11077                 1.026316                39.000000   \n",
       " 11078                 0.318182                 7.000000   \n",
       " 11079                 0.250000                 2.000000   \n",
       " 11080                 1.000000                 1.000000   \n",
       " 11081                 1.000000                 1.000000   \n",
       " 11082                 1.000000                10.000000   \n",
       " 11083                 1.000000                 1.000000   \n",
       " 11084                 0.333333                 2.000000   \n",
       " 11085                 0.666667                 4.000000   \n",
       " 11086                 1.000000                 6.000000   \n",
       " 11087                 1.000000                 1.000000   \n",
       " 11088                 1.000000                 2.000000   \n",
       " 11089                 1.000000                 1.000000   \n",
       " 11090                 0.400000                 2.000000   \n",
       " 11091                 0.000000                 0.000000   \n",
       " 11092                 1.333333                 4.000000   \n",
       " 11093                 0.687500                11.000000   \n",
       " 11094                 0.333333                 1.000000   \n",
       " 11095                 1.000000                 8.000000   \n",
       " 11096                 1.000000                 9.000000   \n",
       " 11097                 0.921053                35.000000   \n",
       " 11098                 1.428571                10.000000   \n",
       " 11099                 1.000000                 3.000000   \n",
       " 11100                 1.000000                 3.000000   \n",
       " 11101                 0.800000                 4.000000   \n",
       " \n",
       "        wn_synset_avg_hyponyms  wn_synset_avg_definition_len  \\\n",
       " 5551                 0.000000                     23.000000   \n",
       " 5552                 4.400000                     33.560000   \n",
       " 5553                 5.555556                     47.333333   \n",
       " 5554                 1.142857                     52.285714   \n",
       " 5555                 1.000000                     52.928571   \n",
       " 5556                 0.857143                     53.571429   \n",
       " 5557                 1.777778                     36.888889   \n",
       " 5558                 3.000000                     50.666667   \n",
       " 5559                 0.000000                     42.000000   \n",
       " 5560                 3.502222                     33.182222   \n",
       " 5561                13.400000                     64.800000   \n",
       " 5562                 4.111111                     59.111111   \n",
       " 5563                 1.000000                     71.600000   \n",
       " 5564                 3.054054                     37.675676   \n",
       " 5565                 2.201389                     46.816667   \n",
       " 5566                 2.601852                     38.555556   \n",
       " 5567                 5.555556                     47.333333   \n",
       " 5568                 0.000000                      0.000000   \n",
       " 5569                 2.250000                     68.333333   \n",
       " 5570                 0.600000                     28.800000   \n",
       " 5571                 0.000000                    141.000000   \n",
       " 5572                 1.000000                     71.600000   \n",
       " 5573                 4.000000                     44.705882   \n",
       " 5574                 0.000000                     42.800000   \n",
       " 5575                 1.250000                     60.216667   \n",
       " 5576                 3.000000                     36.000000   \n",
       " 5577                 1.500000                     48.833333   \n",
       " 5578                 3.000000                     63.000000   \n",
       " 5579                 1.000000                     71.600000   \n",
       " 5580                 2.481481                     49.851852   \n",
       " ...                       ...                           ...   \n",
       " 11072                2.428571                     50.190476   \n",
       " 11073                1.000000                     46.750000   \n",
       " 11074                0.924242                     62.882576   \n",
       " 11075                1.181818                     53.181818   \n",
       " 11076                0.666667                     72.583333   \n",
       " 11077                4.315789                     43.131579   \n",
       " 11078                0.409091                     54.909091   \n",
       " 11079                1.000000                     46.750000   \n",
       " 11080               17.000000                    163.000000   \n",
       " 11081                0.000000                     19.000000   \n",
       " 11082                5.800000                     51.100000   \n",
       " 11083                0.000000                     58.000000   \n",
       " 11084                0.166667                     49.833333   \n",
       " 11085                2.333333                     43.833333   \n",
       " 11086                4.500000                     37.833333   \n",
       " 11087                2.000000                     64.000000   \n",
       " 11088               12.500000                     30.000000   \n",
       " 11089                3.000000                     14.000000   \n",
       " 11090                2.000000                     67.200000   \n",
       " 11091                0.000000                     59.750000   \n",
       " 11092              135.000000                     79.666667   \n",
       " 11093               10.375000                     53.437500   \n",
       " 11094                1.666667                     47.000000   \n",
       " 11095                4.500000                     64.250000   \n",
       " 11096                0.666667                     51.222222   \n",
       " 11097                5.473684                     43.578947   \n",
       " 11098                5.714286                     66.571429   \n",
       " 11099                2.000000                     82.000000   \n",
       " 11100                2.666667                     59.666667   \n",
       " 11101                1.000000                     49.000000   \n",
       " \n",
       "        wn_synset_avg_hyptree_depth  wn_synset_num_distinct_pos  \\\n",
       " 5551                      0.000000                    1.000000   \n",
       " 5552                      1.520000                    1.000000   \n",
       " 5553                      4.166667                    2.000000   \n",
       " 5554                      2.428571                    3.000000   \n",
       " 5555                      4.285714                    2.000000   \n",
       " 5556                      6.142857                    1.000000   \n",
       " 5557                      3.111111                    1.000000   \n",
       " 5558                      5.333333                    1.000000   \n",
       " 5559                      0.000000                    2.000000   \n",
       " 5560                      2.493333                    0.800000   \n",
       " 5561                      5.800000                    1.000000   \n",
       " 5562                      6.666667                    1.000000   \n",
       " 5563                      3.200000                    3.000000   \n",
       " 5564                      2.567568                    5.000000   \n",
       " 5565                      3.279167                    1.750000   \n",
       " 5566                      3.305556                    1.333333   \n",
       " 5567                      4.166667                    2.000000   \n",
       " 5568                      0.000000                    0.000000   \n",
       " 5569                      5.750000                    2.000000   \n",
       " 5570                      1.000000                    1.000000   \n",
       " 5571                      7.000000                    1.000000   \n",
       " 5572                      3.200000                    3.000000   \n",
       " 5573                      4.764706                    2.000000   \n",
       " 5574                      0.000000                    2.000000   \n",
       " 5575                      4.266667                    2.500000   \n",
       " 5576                      9.000000                    1.000000   \n",
       " 5577                      5.333333                    2.000000   \n",
       " 5578                      3.000000                    1.000000   \n",
       " 5579                      3.200000                    3.000000   \n",
       " 5580                      3.481481                    2.000000   \n",
       " ...                            ...                         ...   \n",
       " 11072                     2.000000                    1.000000   \n",
       " 11073                     1.125000                    3.000000   \n",
       " 11074                     6.632576                    2.000000   \n",
       " 11075                     6.181818                    2.000000   \n",
       " 11076                     7.083333                    2.000000   \n",
       " 11077                     4.000000                    2.000000   \n",
       " 11078                     2.727273                    4.000000   \n",
       " 11079                     1.125000                    3.000000   \n",
       " 11080                     7.000000                    1.000000   \n",
       " 11081                     2.000000                    1.000000   \n",
       " 11082                     2.100000                    1.000000   \n",
       " 11083                     7.000000                    1.000000   \n",
       " 11084                     3.000000                    3.000000   \n",
       " 11085                     5.000000                    2.500000   \n",
       " 11086                     7.000000                    2.000000   \n",
       " 11087                     6.000000                    1.000000   \n",
       " 11088                     8.000000                    1.000000   \n",
       " 11089                    10.000000                    1.000000   \n",
       " 11090                     2.800000                    3.000000   \n",
       " 11091                     0.000000                    2.000000   \n",
       " 11092                     6.333333                    1.000000   \n",
       " 11093                     2.937500                    2.000000   \n",
       " 11094                     3.000000                    3.000000   \n",
       " 11095                     7.000000                    1.000000   \n",
       " 11096                     6.555556                    1.000000   \n",
       " 11097                     3.131579                    2.000000   \n",
       " 11098                     5.857143                    2.000000   \n",
       " 11099                     9.333333                    1.000000   \n",
       " 11100                     6.000000                    1.000000   \n",
       " 11101                     6.000000                    3.000000   \n",
       " \n",
       "        wn_synset_avg_num_relations  wn_synset_avg_freq_pos_noun  \\\n",
       " 5551                      0.000000                     0.000000   \n",
       " 5552                      5.240000                     0.000000   \n",
       " 5553                      9.777778                    11.000000   \n",
       " 5554                      1.571429                     3.000000   \n",
       " 5555                      1.714286                     5.000000   \n",
       " 5556                      1.857143                     7.000000   \n",
       " 5557                      2.666667                     0.000000   \n",
       " 5558                      5.666667                     6.000000   \n",
       " 5559                      0.000000                     0.000000   \n",
       " 5560                      6.182222                     2.800000   \n",
       " 5561                     25.800000                     5.000000   \n",
       " 5562                      5.111111                     9.000000   \n",
       " 5563                      1.600000                     2.000000   \n",
       " 5564                      3.810811                     7.000000   \n",
       " 5565                      3.677778                     5.250000   \n",
       " 5566                      4.370370                     6.333333   \n",
       " 5567                      9.777778                    11.000000   \n",
       " 5568                      0.000000                     0.000000   \n",
       " 5569                      3.333333                     8.000000   \n",
       " 5570                      1.200000                     0.000000   \n",
       " 5571                     25.500000                     2.000000   \n",
       " 5572                      1.600000                     2.000000   \n",
       " 5573                      5.058824                    11.000000   \n",
       " 5574                      0.000000                     0.000000   \n",
       " 5575                      2.050000                     2.500000   \n",
       " 5576                      4.000000                     1.000000   \n",
       " 5577                      2.500000                     3.000000   \n",
       " 5578                      3.750000                     0.000000   \n",
       " 5579                      1.600000                     2.000000   \n",
       " 5580                      3.407407                     6.000000   \n",
       " ...                            ...                          ...   \n",
       " 11072                     3.428571                     0.000000   \n",
       " 11073                     1.250000                     1.000000   \n",
       " 11074                     2.803030                     9.500000   \n",
       " 11075                     3.272727                     8.000000   \n",
       " 11076                     2.333333                    11.000000   \n",
       " 11077                     5.368421                    12.000000   \n",
       " 11078                     0.863636                     7.000000   \n",
       " 11079                     1.250000                     1.000000   \n",
       " 11080                    18.000000                     1.000000   \n",
       " 11081                     1.000000                     0.000000   \n",
       " 11082                     6.800000                     0.000000   \n",
       " 11083                     3.000000                     1.000000   \n",
       " 11084                     0.500000                     2.000000   \n",
       " 11085                     3.166667                     3.500000   \n",
       " 11086                     5.833333                     5.000000   \n",
       " 11087                     3.000000                     1.000000   \n",
       " 11088                    49.500000                     2.000000   \n",
       " 11089                    53.000000                     1.000000   \n",
       " 11090                     2.600000                     2.000000   \n",
       " 11091                     0.000000                     0.000000   \n",
       " 11092                   137.333333                     3.000000   \n",
       " 11093                    11.437500                     6.000000   \n",
       " 11094                     8.000000                     1.000000   \n",
       " 11095                     5.625000                     8.000000   \n",
       " 11096                     1.666667                     9.000000   \n",
       " 11097                     6.421053                    11.000000   \n",
       " 11098                     7.857143                     5.000000   \n",
       " 11099                     6.333333                     3.000000   \n",
       " 11100                     8.666667                     3.000000   \n",
       " 11101                     3.200000                     3.000000   \n",
       " \n",
       "        wn_synset_avg_freq_pos_verb  wn_synset_avg_freq_pos_adj  \\\n",
       " 5551                      0.000000                        0.00   \n",
       " 5552                     25.000000                        0.00   \n",
       " 5553                      7.000000                        0.00   \n",
       " 5554                      0.000000                        4.00   \n",
       " 5555                      0.000000                        2.00   \n",
       " 5556                      0.000000                        0.00   \n",
       " 5557                      9.000000                        0.00   \n",
       " 5558                      0.000000                        0.00   \n",
       " 5559                      0.000000                        2.00   \n",
       " 5560                      0.000000                        0.40   \n",
       " 5561                      0.000000                        0.00   \n",
       " 5562                      0.000000                        0.00   \n",
       " 5563                      0.000000                        3.00   \n",
       " 5564                     25.000000                        4.00   \n",
       " 5565                      2.750000                        0.75   \n",
       " 5566                      3.666667                        0.00   \n",
       " 5567                      7.000000                        0.00   \n",
       " 5568                      0.000000                        0.00   \n",
       " 5569                      4.000000                        0.00   \n",
       " 5570                      5.000000                        0.00   \n",
       " 5571                      0.000000                        0.00   \n",
       " 5572                      0.000000                        3.00   \n",
       " 5573                      6.000000                        0.00   \n",
       " 5574                      0.000000                        5.00   \n",
       " 5575                      1.500000                        1.50   \n",
       " 5576                      0.000000                        0.00   \n",
       " 5577                      3.000000                        0.00   \n",
       " 5578                      4.000000                        0.00   \n",
       " 5579                      0.000000                        3.00   \n",
       " 5580                     21.000000                        0.00   \n",
       " ...                            ...                         ...   \n",
       " 11072                    21.000000                        0.00   \n",
       " 11073                     1.000000                        6.00   \n",
       " 11074                     2.000000                        0.00   \n",
       " 11075                     3.000000                        0.00   \n",
       " 11076                     1.000000                        0.00   \n",
       " 11077                    26.000000                        0.00   \n",
       " 11078                     1.000000                       14.00   \n",
       " 11079                     1.000000                        6.00   \n",
       " 11080                     0.000000                        0.00   \n",
       " 11081                     1.000000                        0.00   \n",
       " 11082                    10.000000                        0.00   \n",
       " 11083                     0.000000                        0.00   \n",
       " 11084                     0.000000                        2.00   \n",
       " 11085                     0.500000                        1.00   \n",
       " 11086                     1.000000                        0.00   \n",
       " 11087                     0.000000                        0.00   \n",
       " 11088                     0.000000                        0.00   \n",
       " 11089                     0.000000                        0.00   \n",
       " 11090                     0.000000                        3.00   \n",
       " 11091                     0.000000                        4.00   \n",
       " 11092                     0.000000                        0.00   \n",
       " 11093                    10.000000                        0.00   \n",
       " 11094                     0.000000                        2.00   \n",
       " 11095                     0.000000                        0.00   \n",
       " 11096                     0.000000                        0.00   \n",
       " 11097                    27.000000                        0.00   \n",
       " 11098                     2.000000                        0.00   \n",
       " 11099                     0.000000                        0.00   \n",
       " 11100                     0.000000                        0.00   \n",
       " 11101                     1.000000                        1.00   \n",
       " \n",
       "        wn_synset_avg_freq_pos_adv  wn_synset_avg_freq_pos_noun_norm  \\\n",
       " 5551                          1.0                          0.000000   \n",
       " 5552                          0.0                          0.000000   \n",
       " 5553                          0.0                          0.611111   \n",
       " 5554                          0.0                          0.428571   \n",
       " 5555                          0.0                          0.714286   \n",
       " 5556                          0.0                          1.000000   \n",
       " 5557                          0.0                          0.000000   \n",
       " 5558                          0.0                          1.000000   \n",
       " 5559                          0.0                          0.000000   \n",
       " 5560                          0.0                          0.875000   \n",
       " 5561                          0.0                          1.000000   \n",
       " 5562                          0.0                          1.000000   \n",
       " 5563                          0.0                          0.400000   \n",
       " 5564                          1.0                          0.189189   \n",
       " 5565                          0.0                          0.600000   \n",
       " 5566                          0.0                          0.633333   \n",
       " 5567                          0.0                          0.611111   \n",
       " 5568                          0.0                          0.000000   \n",
       " 5569                          0.0                          0.666667   \n",
       " 5570                          0.0                          0.000000   \n",
       " 5571                          0.0                          1.000000   \n",
       " 5572                          0.0                          0.400000   \n",
       " 5573                          0.0                          0.647059   \n",
       " 5574                          0.0                          0.000000   \n",
       " 5575                          0.0                          0.454545   \n",
       " 5576                          0.0                          1.000000   \n",
       " 5577                          0.0                          0.500000   \n",
       " 5578                          0.0                          0.000000   \n",
       " 5579                          0.0                          0.400000   \n",
       " 5580                          0.0                          0.222222   \n",
       " ...                           ...                               ...   \n",
       " 11072                         0.0                          0.000000   \n",
       " 11073                         0.0                          0.125000   \n",
       " 11074                         0.0                          0.826087   \n",
       " 11075                         0.0                          0.727273   \n",
       " 11076                         0.0                          0.916667   \n",
       " 11077                         0.0                          0.315789   \n",
       " 11078                         0.0                          0.318182   \n",
       " 11079                         0.0                          0.125000   \n",
       " 11080                         0.0                          1.000000   \n",
       " 11081                         0.0                          0.000000   \n",
       " 11082                         0.0                          0.000000   \n",
       " 11083                         0.0                          1.000000   \n",
       " 11084                         2.0                          0.333333   \n",
       " 11085                         1.0                          0.583333   \n",
       " 11086                         0.0                          0.833333   \n",
       " 11087                         0.0                          1.000000   \n",
       " 11088                         0.0                          1.000000   \n",
       " 11089                         0.0                          1.000000   \n",
       " 11090                         0.0                          0.400000   \n",
       " 11091                         0.0                          0.000000   \n",
       " 11092                         0.0                          1.000000   \n",
       " 11093                         0.0                          0.375000   \n",
       " 11094                         0.0                          0.333333   \n",
       " 11095                         0.0                          1.000000   \n",
       " 11096                         0.0                          1.000000   \n",
       " 11097                         0.0                          0.289474   \n",
       " 11098                         0.0                          0.714286   \n",
       " 11099                         0.0                          1.000000   \n",
       " 11100                         0.0                          1.000000   \n",
       " 11101                         0.0                          0.600000   \n",
       " \n",
       "        wn_synset_avg_freq_pos_verb_norm  wn_synset_avg_freq_pos_adj_norm  \\\n",
       " 5551                           0.000000                         0.000000   \n",
       " 5552                           1.000000                         0.000000   \n",
       " 5553                           0.388889                         0.000000   \n",
       " 5554                           0.000000                         0.571429   \n",
       " 5555                           0.000000                         0.285714   \n",
       " 5556                           0.000000                         0.000000   \n",
       " 5557                           1.000000                         0.000000   \n",
       " 5558                           0.000000                         0.000000   \n",
       " 5559                           0.000000                         1.000000   \n",
       " 5560                           0.000000                         0.125000   \n",
       " 5561                           0.000000                         0.000000   \n",
       " 5562                           0.000000                         0.000000   \n",
       " 5563                           0.000000                         0.600000   \n",
       " 5564                           0.675676                         0.108108   \n",
       " 5565                           0.314286                         0.085714   \n",
       " 5566                           0.366667                         0.000000   \n",
       " 5567                           0.388889                         0.000000   \n",
       " 5568                           0.000000                         0.000000   \n",
       " 5569                           0.333333                         0.000000   \n",
       " 5570                           1.000000                         0.000000   \n",
       " 5571                           0.000000                         0.000000   \n",
       " 5572                           0.000000                         0.600000   \n",
       " 5573                           0.352941                         0.000000   \n",
       " 5574                           0.000000                         1.000000   \n",
       " 5575                           0.272727                         0.272727   \n",
       " 5576                           0.000000                         0.000000   \n",
       " 5577                           0.500000                         0.000000   \n",
       " 5578                           1.000000                         0.000000   \n",
       " 5579                           0.000000                         0.600000   \n",
       " 5580                           0.777778                         0.000000   \n",
       " ...                                 ...                              ...   \n",
       " 11072                          1.000000                         0.000000   \n",
       " 11073                          0.125000                         0.750000   \n",
       " 11074                          0.173913                         0.000000   \n",
       " 11075                          0.272727                         0.000000   \n",
       " 11076                          0.083333                         0.000000   \n",
       " 11077                          0.684211                         0.000000   \n",
       " 11078                          0.045455                         0.636364   \n",
       " 11079                          0.125000                         0.750000   \n",
       " 11080                          0.000000                         0.000000   \n",
       " 11081                          1.000000                         0.000000   \n",
       " 11082                          1.000000                         0.000000   \n",
       " 11083                          0.000000                         0.000000   \n",
       " 11084                          0.000000                         0.333333   \n",
       " 11085                          0.083333                         0.166667   \n",
       " 11086                          0.166667                         0.000000   \n",
       " 11087                          0.000000                         0.000000   \n",
       " 11088                          0.000000                         0.000000   \n",
       " 11089                          0.000000                         0.000000   \n",
       " 11090                          0.000000                         0.600000   \n",
       " 11091                          0.000000                         1.000000   \n",
       " 11092                          0.000000                         0.000000   \n",
       " 11093                          0.625000                         0.000000   \n",
       " 11094                          0.000000                         0.666667   \n",
       " 11095                          0.000000                         0.000000   \n",
       " 11096                          0.000000                         0.000000   \n",
       " 11097                          0.710526                         0.000000   \n",
       " 11098                          0.285714                         0.000000   \n",
       " 11099                          0.000000                         0.000000   \n",
       " 11100                          0.000000                         0.000000   \n",
       " 11101                          0.200000                         0.200000   \n",
       " \n",
       "        wn_synset_avg_freq_pos_adv_norm  wn_synset_sense_entropy_uniform  \\\n",
       " 5551                          1.000000                         0.000000   \n",
       " 5552                          0.000000                         4.643856   \n",
       " 5553                          0.000000                         4.169925   \n",
       " 5554                          0.000000                         2.807355   \n",
       " 5555                          0.000000                         2.807355   \n",
       " 5556                          0.000000                         2.807355   \n",
       " 5557                          0.000000                         3.169925   \n",
       " 5558                          0.000000                         2.584963   \n",
       " 5559                          0.000000                         1.000000   \n",
       " 5560                          0.000000                         1.298371   \n",
       " 5561                          0.000000                         2.321928   \n",
       " 5562                          0.000000                         3.169925   \n",
       " 5563                          0.000000                         2.321928   \n",
       " 5564                          0.027027                         5.209453   \n",
       " 5565                          0.000000                         2.519204   \n",
       " 5566                          0.000000                         2.584963   \n",
       " 5567                          0.000000                         4.169925   \n",
       " 5568                          0.000000                         0.000000   \n",
       " 5569                          0.000000                         3.584963   \n",
       " 5570                          0.000000                         2.321928   \n",
       " 5571                          0.000000                         1.000000   \n",
       " 5572                          0.000000                         2.321928   \n",
       " 5573                          0.000000                         4.087463   \n",
       " 5574                          0.000000                         2.321928   \n",
       " 5575                          0.000000                         2.453445   \n",
       " 5576                          0.000000                         0.000000   \n",
       " 5577                          0.000000                         2.584963   \n",
       " 5578                          0.000000                         2.000000   \n",
       " 5579                          0.000000                         2.321928   \n",
       " 5580                          0.000000                         4.754888   \n",
       " ...                                ...                              ...   \n",
       " 11072                         0.000000                         4.392317   \n",
       " 11073                         0.000000                         3.000000   \n",
       " 11074                         0.000000                         3.522197   \n",
       " 11075                         0.000000                         3.459432   \n",
       " 11076                         0.000000                         3.584963   \n",
       " 11077                         0.000000                         5.247928   \n",
       " 11078                         0.000000                         4.459432   \n",
       " 11079                         0.000000                         3.000000   \n",
       " 11080                         0.000000                         0.000000   \n",
       " 11081                         0.000000                         0.000000   \n",
       " 11082                         0.000000                         3.321928   \n",
       " 11083                         0.000000                         0.000000   \n",
       " 11084                         0.333333                         2.584963   \n",
       " 11085                         0.166667                         2.584963   \n",
       " 11086                         0.000000                         2.584963   \n",
       " 11087                         0.000000                         0.000000   \n",
       " 11088                         0.000000                         1.000000   \n",
       " 11089                         0.000000                         0.000000   \n",
       " 11090                         0.000000                         2.321928   \n",
       " 11091                         0.000000                         2.000000   \n",
       " 11092                         0.000000                         1.584963   \n",
       " 11093                         0.000000                         4.000000   \n",
       " 11094                         0.000000                         1.584963   \n",
       " 11095                         0.000000                         3.000000   \n",
       " 11096                         0.000000                         3.169925   \n",
       " 11097                         0.000000                         5.247928   \n",
       " 11098                         0.000000                         2.807355   \n",
       " 11099                         0.000000                         1.584963   \n",
       " 11100                         0.000000                         1.584963   \n",
       " 11101                         0.000000                         2.321928   \n",
       " \n",
       "        wn_synset_sense_entropy_pos_uniform  \\\n",
       " 5551                              0.000000   \n",
       " 5552                              0.000000   \n",
       " 5553                              0.964079   \n",
       " 5554                              0.985228   \n",
       " 5555                              0.492614   \n",
       " 5556                              0.000000   \n",
       " 5557                              0.000000   \n",
       " 5558                              0.000000   \n",
       " 5559                              0.000000   \n",
       " 5560                              0.000000   \n",
       " 5561                              0.000000   \n",
       " 5562                              0.000000   \n",
       " 5563                              0.970951   \n",
       " 5564                              1.324375   \n",
       " 5565                              0.713331   \n",
       " 5566                              0.627458   \n",
       " 5567                              0.964079   \n",
       " 5568                              0.000000   \n",
       " 5569                              0.918296   \n",
       " 5570                              0.000000   \n",
       " 5571                              0.000000   \n",
       " 5572                              0.970951   \n",
       " 5573                              0.936667   \n",
       " 5574                              0.000000   \n",
       " 5575                              0.985475   \n",
       " 5576                              0.000000   \n",
       " 5577                              1.000000   \n",
       " 5578                              0.000000   \n",
       " 5579                              0.970951   \n",
       " 5580                              0.764205   \n",
       " ...                                    ...   \n",
       " 11072                             0.000000   \n",
       " 11073                             1.061278   \n",
       " 11074                             0.629584   \n",
       " 11075                             0.845351   \n",
       " 11076                             0.413817   \n",
       " 11077                             0.899744   \n",
       " 11078                             1.143320   \n",
       " 11079                             1.061278   \n",
       " 11080                             0.000000   \n",
       " 11081                             0.000000   \n",
       " 11082                             0.000000   \n",
       " 11083                             0.000000   \n",
       " 11084                             1.584963   \n",
       " 11085                             1.117492   \n",
       " 11086                             0.650022   \n",
       " 11087                             0.000000   \n",
       " 11088                             0.000000   \n",
       " 11089                             0.000000   \n",
       " 11090                             0.970951   \n",
       " 11091                             0.000000   \n",
       " 11092                             0.000000   \n",
       " 11093                             0.954434   \n",
       " 11094                             0.918296   \n",
       " 11095                             0.000000   \n",
       " 11096                             0.000000   \n",
       " 11097                             0.868040   \n",
       " 11098                             0.863121   \n",
       " 11099                             0.000000   \n",
       " 11100                             0.000000   \n",
       " 11101                             1.370951   \n",
       " \n",
       "        wn_synsets_sense_entropy_pos_central  wn_synset_pos_ratio_1  \\\n",
       " 5551                              -0.000000               1.000000   \n",
       " 5552                               4.643856               1.000000   \n",
       " 5553                               3.459432               0.611111   \n",
       " 5554                               2.000000               0.571429   \n",
       " 5555                              -0.000000               0.785714   \n",
       " 5556                               2.807355               1.000000   \n",
       " 5557                               3.169925               1.000000   \n",
       " 5558                               2.584963               1.000000   \n",
       " 5559                               1.000000               1.000000   \n",
       " 5560                              -0.000000               0.700000   \n",
       " 5561                               2.321928               1.000000   \n",
       " 5562                               3.169925               1.000000   \n",
       " 5563                               1.000000               0.400000   \n",
       " 5564                               2.807355               0.189189   \n",
       " 5565                              -0.000000               0.481944   \n",
       " 5566                              -0.000000               0.509259   \n",
       " 5567                               3.459432               0.611111   \n",
       " 5568                              -0.000000               0.250000   \n",
       " 5569                               3.000000               0.666667   \n",
       " 5570                               2.321928               1.000000   \n",
       " 5571                               1.000000               1.000000   \n",
       " 5572                               1.000000               0.400000   \n",
       " 5573                               3.459432               0.647059   \n",
       " 5574                               2.321928               1.000000   \n",
       " 5575                              -0.000000               0.450000   \n",
       " 5576                              -0.000000               1.000000   \n",
       " 5577                               1.584963               0.500000   \n",
       " 5578                               2.000000               1.000000   \n",
       " 5579                               1.000000               0.400000   \n",
       " 5580                               2.584963               0.222222   \n",
       " ...                                     ...                    ...   \n",
       " 11072                             -0.000000               0.000000   \n",
       " 11073                              2.584963               0.750000   \n",
       " 11074                             -0.000000               0.821970   \n",
       " 11075                              3.000000               0.727273   \n",
       " 11076                              3.459432               0.916667   \n",
       " 11077                              4.700440               0.684211   \n",
       " 11078                              3.807355               0.636364   \n",
       " 11079                             -0.000000               0.125000   \n",
       " 11080                             -0.000000               1.000000   \n",
       " 11081                             -0.000000               0.000000   \n",
       " 11082                              3.321928               1.000000   \n",
       " 11083                             -0.000000               1.000000   \n",
       " 11084                              1.000000               0.333333   \n",
       " 11085                             -0.000000               0.583333   \n",
       " 11086                              2.321928               0.833333   \n",
       " 11087                             -0.000000               1.000000   \n",
       " 11088                              1.000000               1.000000   \n",
       " 11089                             -0.000000               0.000000   \n",
       " 11090                              1.000000               0.400000   \n",
       " 11091                              2.000000               1.000000   \n",
       " 11092                              1.584963               1.000000   \n",
       " 11093                              3.321928               0.625000   \n",
       " 11094                              1.000000               0.666667   \n",
       " 11095                              3.000000               1.000000   \n",
       " 11096                              3.169925               1.000000   \n",
       " 11097                              4.754888               0.710526   \n",
       " 11098                              2.321928               0.714286   \n",
       " 11099                              1.584963               1.000000   \n",
       " 11100                              1.584963               1.000000   \n",
       " 11101                              1.584963               0.600000   \n",
       " \n",
       "        wn_synset_pos_ratio_2  swn_avg_objective_score  \\\n",
       " 5551                1.000000                 1.000000   \n",
       " 5552                1.000000                 0.955000   \n",
       " 5553                0.907990                 0.993056   \n",
       " 5554                0.351351                 0.928571   \n",
       " 5555                0.675676                 0.964286   \n",
       " 5556                1.000000                 1.000000   \n",
       " 5557                1.000000                 0.833333   \n",
       " 5558                1.000000                 1.000000   \n",
       " 5559                1.000000                 1.000000   \n",
       " 5560                0.700000                 0.597222   \n",
       " 5561                1.000000                 1.000000   \n",
       " 5562                1.000000                 0.986111   \n",
       " 5563                0.600000                 1.000000   \n",
       " 5564                0.012397                 0.918919   \n",
       " 5565                0.645105                 0.724826   \n",
       " 5566                0.660140                 0.633102   \n",
       " 5567                0.907990                 0.993056   \n",
       " 5568                0.250000                 0.000000   \n",
       " 5569                0.822430                 0.906250   \n",
       " 5570                1.000000                 1.000000   \n",
       " 5571                1.000000                 1.000000   \n",
       " 5572                0.600000                 1.000000   \n",
       " 5573                0.797834                 0.955882   \n",
       " 5574                1.000000                 0.550000   \n",
       " 5575                0.520930                 1.000000   \n",
       " 5576                0.250000                 1.000000   \n",
       " 5577                0.441860                 1.000000   \n",
       " 5578                1.000000                 1.000000   \n",
       " 5579                0.600000                 1.000000   \n",
       " 5580                0.052083                 0.944444   \n",
       " ...                      ...                      ...   \n",
       " 11072               0.000000                 0.964286   \n",
       " 11073               0.743590                 0.718750   \n",
       " 11074               0.755319                 0.983902   \n",
       " 11075               0.510638                 0.988636   \n",
       " 11076               1.000000                 0.979167   \n",
       " 11077               0.934400                 0.976974   \n",
       " 11078               0.720000                 0.659091   \n",
       " 11079               0.051282                 0.718750   \n",
       " 11080               1.000000                 1.000000   \n",
       " 11081               0.000000                 1.000000   \n",
       " 11082               1.000000                 1.000000   \n",
       " 11083               1.000000                 1.000000   \n",
       " 11084               0.764706                 0.916667   \n",
       " 11085               0.866224                 0.947917   \n",
       " 11086               0.967742                 0.979167   \n",
       " 11087               1.000000                 1.000000   \n",
       " 11088               1.000000                 1.000000   \n",
       " 11089               0.000000                 1.000000   \n",
       " 11090               0.611111                 1.000000   \n",
       " 11091               1.000000                 0.718750   \n",
       " 11092               1.000000                 1.000000   \n",
       " 11093               0.682731                 0.937500   \n",
       " 11094               0.826087                 0.833333   \n",
       " 11095               1.000000                 0.984375   \n",
       " 11096               1.000000                 0.958333   \n",
       " 11097               0.574760                 0.944079   \n",
       " 11098               0.804688                 1.000000   \n",
       " 11099               1.000000                 1.000000   \n",
       " 11100               1.000000                 1.000000   \n",
       " 11101               0.884615                 1.000000   \n",
       " \n",
       "        wn_synsets_freq_ratio_to_max_agg_min  \\\n",
       " 5551                               0.189436   \n",
       " 5552                               0.333867   \n",
       " 5553                               0.347925   \n",
       " 5554                               0.512238   \n",
       " 5555                               0.415089   \n",
       " 5556                               0.317939   \n",
       " 5557                               0.028839   \n",
       " 5558                               1.000000   \n",
       " 5559                               1.000000   \n",
       " 5560                               0.713637   \n",
       " 5561                               0.360355   \n",
       " 5562                               0.207832   \n",
       " 5563                               0.103653   \n",
       " 5564                               0.160432   \n",
       " 5565                               0.554222   \n",
       " 5566                               0.704412   \n",
       " 5567                               0.347925   \n",
       " 5568                               1.000000   \n",
       " 5569                               0.765310   \n",
       " 5570                               0.058221   \n",
       " 5571                               1.000000   \n",
       " 5572                               0.103653   \n",
       " 5573                               1.000000   \n",
       " 5574                               1.000000   \n",
       " 5575                               0.464640   \n",
       " 5576                               0.009217   \n",
       " 5577                               0.825626   \n",
       " 5578                               1.000000   \n",
       " 5579                               0.103653   \n",
       " 5580                               0.169803   \n",
       " ...                                     ...   \n",
       " 11072                              0.071359   \n",
       " 11073                              1.000000   \n",
       " 11074                              0.515770   \n",
       " 11075                              0.031540   \n",
       " 11076                              1.000000   \n",
       " 11077                              0.065743   \n",
       " 11078                              1.000000   \n",
       " 11079                              1.000000   \n",
       " 11080                              1.000000   \n",
       " 11081                              0.293443   \n",
       " 11082                              0.127308   \n",
       " 11083                              1.000000   \n",
       " 11084                              0.689584   \n",
       " 11085                              0.844792   \n",
       " 11086                              1.000000   \n",
       " 11087                              0.035795   \n",
       " 11088                              0.364411   \n",
       " 11089                              1.000000   \n",
       " 11090                              1.000000   \n",
       " 11091                              1.000000   \n",
       " 11092                              0.976458   \n",
       " 11093                              0.100407   \n",
       " 11094                              1.000000   \n",
       " 11095                              1.000000   \n",
       " 11096                              1.000000   \n",
       " 11097                              0.431929   \n",
       " 11098                              1.000000   \n",
       " 11099                              1.000000   \n",
       " 11100                              0.123264   \n",
       " 11101                              1.000000   \n",
       " \n",
       "        wn_synsets_freq_ratio_to_max_agg_mean  \\\n",
       " 5551                                0.189436   \n",
       " 5552                                0.004366   \n",
       " 5553                                0.347925   \n",
       " 5554                                0.019643   \n",
       " 5555                                0.168791   \n",
       " 5556                                0.317939   \n",
       " 5557                                0.014078   \n",
       " 5558                                0.028216   \n",
       " 5559                                1.000000   \n",
       " 5560                                0.713637   \n",
       " 5561                                0.360355   \n",
       " 5562                                0.207832   \n",
       " 5563                                0.092333   \n",
       " 5564                                0.002098   \n",
       " 5565                                0.534061   \n",
       " 5566                                0.681304   \n",
       " 5567                                0.347925   \n",
       " 5568                                1.000000   \n",
       " 5569                                0.695987   \n",
       " 5570                                0.026997   \n",
       " 5571                                0.018887   \n",
       " 5572                                0.092333   \n",
       " 5573                                1.000000   \n",
       " 5574                                0.013422   \n",
       " 5575                                0.458980   \n",
       " 5576                                0.004396   \n",
       " 5577                                0.825626   \n",
       " 5578                                0.051250   \n",
       " 5579                                0.092333   \n",
       " 5580                                0.004209   \n",
       " ...                                      ...   \n",
       " 11072                               0.023946   \n",
       " 11073                               1.000000   \n",
       " 11074                               0.061322   \n",
       " 11075                               0.020577   \n",
       " 11076                               0.102067   \n",
       " 11077                               0.003625   \n",
       " 11078                               1.000000   \n",
       " 11079                               1.000000   \n",
       " 11080                               1.000000   \n",
       " 11081                               0.293443   \n",
       " 11082                               0.042720   \n",
       " 11083                               1.000000   \n",
       " 11084                               0.181725   \n",
       " 11085                               0.468761   \n",
       " 11086                               0.755797   \n",
       " 11087                               0.035795   \n",
       " 11088                               0.364411   \n",
       " 11089                               1.000000   \n",
       " 11090                               1.000000   \n",
       " 11091                               1.000000   \n",
       " 11092                               0.976458   \n",
       " 11093                               0.002400   \n",
       " 11094                               1.000000   \n",
       " 11095                               1.000000   \n",
       " 11096                               1.000000   \n",
       " 11097                               0.023464   \n",
       " 11098                               1.000000   \n",
       " 11099                               0.763270   \n",
       " 11100                               0.005613   \n",
       " 11101                               0.826068   \n",
       " \n",
       "        wn_synsets_freq_ratio_to_max_agg_median  wn_synsets_avg_lemma_freq  \\\n",
       " 5551                                  0.189436              105340.600000   \n",
       " 5552                                  0.025479               72545.669725   \n",
       " 5553                                  0.347925              291977.555556   \n",
       " 5554                                  0.119332              168836.846154   \n",
       " 5555                                  0.218636              117411.923077   \n",
       " 5556                                  0.317939               65987.000000   \n",
       " 5557                                  0.014078               19710.937500   \n",
       " 5558                                  0.919014              331001.400000   \n",
       " 5559                                  1.000000              232392.000000   \n",
       " 5560                                  0.713637              157901.727451   \n",
       " 5561                                  0.360355              494925.470588   \n",
       " 5562                                  0.207832               62191.166667   \n",
       " 5563                                  0.092333               36038.500000   \n",
       " 5564                                  0.012243               72222.557823   \n",
       " 5565                                  0.534061              133815.741162   \n",
       " 5566                                  0.681304              166408.154882   \n",
       " 5567                                  0.347925              291977.555556   \n",
       " 5568                                  1.000000                   0.000000   \n",
       " 5569                                  0.695987              207246.909091   \n",
       " 5570                                  0.026997               25006.125000   \n",
       " 5571                                  1.000000              245390.000000   \n",
       " 5572                                  0.092333               36038.500000   \n",
       " 5573                                  1.000000              538062.000000   \n",
       " 5574                                  0.013422              244573.222222   \n",
       " 5575                                  0.458980               32246.931818   \n",
       " 5576                                  0.004396                 327.333333   \n",
       " 5577                                  0.825626               28455.363636   \n",
       " 5578                                  0.051250              446187.666667   \n",
       " 5579                                  0.092333               36038.500000   \n",
       " 5580                                  0.004209               66846.657143   \n",
       " ...                                        ...                        ...   \n",
       " 11072                                 0.023946               74031.978723   \n",
       " 11073                                 1.000000               38458.714286   \n",
       " 11074                                 0.061322               38248.283898   \n",
       " 11075                                 0.020577               59565.067797   \n",
       " 11076                                 0.102067               16931.500000   \n",
       " 11077                                 0.010240              150196.562500   \n",
       " 11078                                 1.000000              157248.903226   \n",
       " 11079                                 1.000000               38458.714286   \n",
       " 11080                                 1.000000                4573.000000   \n",
       " 11081                                 0.293443                 610.000000   \n",
       " 11082                                 0.042720               77523.407407   \n",
       " 11083                                 1.000000               36460.000000   \n",
       " 11084                                 0.181725               37724.000000   \n",
       " 11085                                 0.468761               43849.600000   \n",
       " 11086                                 0.755797               49975.200000   \n",
       " 11087                                 0.035795              129602.666667   \n",
       " 11088                                 0.364411              103719.750000   \n",
       " 11089                                 1.000000              120924.000000   \n",
       " 11090                                 1.000000              177067.428571   \n",
       " 11091                                 1.000000               37957.000000   \n",
       " 11092                                 0.976458              125772.500000   \n",
       " 11093                                 0.003717              287559.342105   \n",
       " 11094                                 1.000000               30747.100000   \n",
       " 11095                                 1.000000              361364.181818   \n",
       " 11096                                 1.000000               95548.642857   \n",
       " 11097                                 0.062571              460928.215054   \n",
       " 11098                                 1.000000              433566.681818   \n",
       " 11099                                 0.763270              155925.933333   \n",
       " 11100                                 0.123264              170809.857143   \n",
       " 11101                                 0.826068              173803.538462   \n",
       " \n",
       "        wn_synsets_freq_ratio_to_avg  wn_synset_lesk_wsd_ratio_hi_freq  \\\n",
       " 5551                       1.744483                          0.400000   \n",
       " 5552                       0.408174                          0.000000   \n",
       " 5553                       0.582399                          0.333333   \n",
       " 5554                       0.694776                          0.000000   \n",
       " 5555                       0.848128                          0.500000   \n",
       " 5556                       1.948588                          1.000000   \n",
       " 5557                       1.409938                          0.500000   \n",
       " 5558                       0.600000                          0.000000   \n",
       " 5559                       1.000000                          0.000000   \n",
       " 5560                       0.017378                          0.000000   \n",
       " 5561                       0.953160                          0.000000   \n",
       " 5562                       0.691851                          0.000000   \n",
       " 5563                       1.369400                          0.200000   \n",
       " 5564                       0.845648                          0.000000   \n",
       " 5565                       0.659262                          0.300000   \n",
       " 5566                       0.635473                          0.333333   \n",
       " 5567                       0.582399                          0.000000   \n",
       " 5568                       0.000000                          0.000000   \n",
       " 5569                       0.729085                          1.000000   \n",
       " 5570                       1.269540                          0.500000   \n",
       " 5571                       0.666667                          0.000000   \n",
       " 5572                       1.369400                          0.200000   \n",
       " 5573                       0.523710                          0.000000   \n",
       " 5574                       0.627874                          0.000000   \n",
       " 5575                       0.992931                          0.600000   \n",
       " 5576                       1.121005                          1.000000   \n",
       " 5577                       0.736499                          1.000000   \n",
       " 5578                       0.354069                          0.000000   \n",
       " 5579                       1.369400                          0.200000   \n",
       " 5580                       0.905634                          0.000000   \n",
       " ...                             ...                               ...   \n",
       " 11072                      3.514454                          0.000000   \n",
       " 11073                      0.395373                          0.000000   \n",
       " 11074                      0.996594                          0.000000   \n",
       " 11075                      1.249765                          0.000000   \n",
       " 11076                      0.581898                          0.000000   \n",
       " 11077                      2.123100                          1.000000   \n",
       " 11078                      0.362995                          0.000000   \n",
       " 11079                      0.395373                          0.000000   \n",
       " 11080                      1.000000                          0.000000   \n",
       " 11081                      3.407821                          0.000000   \n",
       " 11082                      2.062835                          0.800000   \n",
       " 11083                      0.339615                          0.000000   \n",
       " 11084                      0.517710                          0.000000   \n",
       " 11085                      0.570698                          0.000000   \n",
       " 11086                      0.618482                          0.000000   \n",
       " 11087                      9.868474                          0.333333   \n",
       " 11088                      0.617758                          0.000000   \n",
       " 11089                      1.000000                          0.000000   \n",
       " 11090                      0.714561                          0.000000   \n",
       " 11091                      0.823077                          0.000000   \n",
       " 11092                      0.620602                          0.000000   \n",
       " 11093                      2.661502                          0.500000   \n",
       " 11094                      0.355211                          0.000000   \n",
       " 11095                      0.769423                          0.000000   \n",
       " 11096                      0.721808                          0.000000   \n",
       " 11097                      0.991706                          1.000000   \n",
       " 11098                      0.347504                          0.000000   \n",
       " 11099                      0.323169                          0.000000   \n",
       " 11100                      1.554583                          0.666667   \n",
       " 11101                      0.399233                          0.000000   \n",
       " \n",
       "        wn_synset_lesk_wsd_ratio_low_freq  \\\n",
       " 5551                            0.400000   \n",
       " 5552                            1.000000   \n",
       " 5553                            0.333333   \n",
       " 5554                            0.000000   \n",
       " 5555                            0.000000   \n",
       " 5556                            0.000000   \n",
       " 5557                            0.500000   \n",
       " 5558                            0.500000   \n",
       " 5559                            0.000000   \n",
       " 5560                            0.133333   \n",
       " 5561                            0.666667   \n",
       " 5562                            0.000000   \n",
       " 5563                            0.600000   \n",
       " 5564                            0.500000   \n",
       " 5565                            0.316667   \n",
       " 5566                            0.222222   \n",
       " 5567                            0.666667   \n",
       " 5568                            0.000000   \n",
       " 5569                            0.000000   \n",
       " 5570                            0.500000   \n",
       " 5571                            0.500000   \n",
       " 5572                            0.600000   \n",
       " 5573                            0.666667   \n",
       " 5574                            0.500000   \n",
       " 5575                            0.300000   \n",
       " 5576                            0.000000   \n",
       " 5577                            0.000000   \n",
       " 5578                            1.000000   \n",
       " 5579                            0.600000   \n",
       " 5580                            0.000000   \n",
       " ...                                  ...   \n",
       " 11072                           0.000000   \n",
       " 11073                           0.000000   \n",
       " 11074                           0.000000   \n",
       " 11075                           0.000000   \n",
       " 11076                           0.000000   \n",
       " 11077                           0.000000   \n",
       " 11078                           0.000000   \n",
       " 11079                           0.000000   \n",
       " 11080                           0.000000   \n",
       " 11081                           0.000000   \n",
       " 11082                           0.200000   \n",
       " 11083                           0.666667   \n",
       " 11084                           0.000000   \n",
       " 11085                           0.000000   \n",
       " 11086                           0.000000   \n",
       " 11087                           0.333333   \n",
       " 11088                           0.666667   \n",
       " 11089                           0.000000   \n",
       " 11090                           0.500000   \n",
       " 11091                           0.000000   \n",
       " 11092                           0.000000   \n",
       " 11093                           0.500000   \n",
       " 11094                           0.000000   \n",
       " 11095                           0.000000   \n",
       " 11096                           0.500000   \n",
       " 11097                           0.000000   \n",
       " 11098                           0.900000   \n",
       " 11099                           0.777778   \n",
       " 11100                           0.000000   \n",
       " 11101                           0.666667   \n",
       " \n",
       "        wn_synset_lesk_wsd_ratio_hi_nopos_freq  \\\n",
       " 5551                                 0.400000   \n",
       " 5552                                 0.000000   \n",
       " 5553                                 0.333333   \n",
       " 5554                                 0.000000   \n",
       " 5555                                 0.500000   \n",
       " 5556                                 1.000000   \n",
       " 5557                                 0.500000   \n",
       " 5558                                 0.000000   \n",
       " 5559                                 0.000000   \n",
       " 5560                                 0.000000   \n",
       " 5561                                 0.000000   \n",
       " 5562                                 0.000000   \n",
       " 5563                                 0.200000   \n",
       " 5564                                 0.000000   \n",
       " 5565                                 0.300000   \n",
       " 5566                                 0.333333   \n",
       " 5567                                 0.000000   \n",
       " 5568                                 0.000000   \n",
       " 5569                                 1.000000   \n",
       " 5570                                 0.500000   \n",
       " 5571                                 0.000000   \n",
       " 5572                                 0.200000   \n",
       " 5573                                 0.000000   \n",
       " 5574                                 0.000000   \n",
       " 5575                                 0.600000   \n",
       " 5576                                 1.000000   \n",
       " 5577                                 1.000000   \n",
       " 5578                                 0.000000   \n",
       " 5579                                 0.200000   \n",
       " 5580                                 0.000000   \n",
       " ...                                       ...   \n",
       " 11072                                1.000000   \n",
       " 11073                                0.000000   \n",
       " 11074                                0.000000   \n",
       " 11075                                0.000000   \n",
       " 11076                                0.000000   \n",
       " 11077                                1.000000   \n",
       " 11078                                0.000000   \n",
       " 11079                                0.000000   \n",
       " 11080                                0.000000   \n",
       " 11081                                1.000000   \n",
       " 11082                                0.800000   \n",
       " 11083                                0.000000   \n",
       " 11084                                0.000000   \n",
       " 11085                                0.000000   \n",
       " 11086                                0.000000   \n",
       " 11087                                0.333333   \n",
       " 11088                                0.000000   \n",
       " 11089                                0.000000   \n",
       " 11090                                0.000000   \n",
       " 11091                                0.000000   \n",
       " 11092                                0.000000   \n",
       " 11093                                0.500000   \n",
       " 11094                                0.000000   \n",
       " 11095                                0.000000   \n",
       " 11096                                0.000000   \n",
       " 11097                                1.000000   \n",
       " 11098                                0.000000   \n",
       " 11099                                0.000000   \n",
       " 11100                                0.666667   \n",
       " 11101                                0.000000   \n",
       " \n",
       "        wn_synset_lesk_wsd_ratio_low_nopos_freq  \\\n",
       " 5551                                  0.400000   \n",
       " 5552                                  1.000000   \n",
       " 5553                                  0.333333   \n",
       " 5554                                  0.500000   \n",
       " 5555                                  0.250000   \n",
       " 5556                                  0.000000   \n",
       " 5557                                  0.500000   \n",
       " 5558                                  0.500000   \n",
       " 5559                                  0.000000   \n",
       " 5560                                  0.133333   \n",
       " 5561                                  0.666667   \n",
       " 5562                                  0.000000   \n",
       " 5563                                  0.600000   \n",
       " 5564                                  0.500000   \n",
       " 5565                                  0.316667   \n",
       " 5566                                  0.222222   \n",
       " 5567                                  0.666667   \n",
       " 5568                                  0.000000   \n",
       " 5569                                  0.000000   \n",
       " 5570                                  0.500000   \n",
       " 5571                                  0.500000   \n",
       " 5572                                  0.600000   \n",
       " 5573                                  0.666667   \n",
       " 5574                                  0.500000   \n",
       " 5575                                  0.300000   \n",
       " 5576                                  0.000000   \n",
       " 5577                                  0.000000   \n",
       " 5578                                  1.000000   \n",
       " 5579                                  0.600000   \n",
       " 5580                                  0.000000   \n",
       " ...                                        ...   \n",
       " 11072                                 0.000000   \n",
       " 11073                                 0.500000   \n",
       " 11074                                 0.000000   \n",
       " 11075                                 0.000000   \n",
       " 11076                                 0.000000   \n",
       " 11077                                 0.000000   \n",
       " 11078                                 0.666667   \n",
       " 11079                                 0.500000   \n",
       " 11080                                 0.000000   \n",
       " 11081                                 0.000000   \n",
       " 11082                                 0.200000   \n",
       " 11083                                 0.666667   \n",
       " 11084                                 0.800000   \n",
       " 11085                                 0.400000   \n",
       " 11086                                 0.000000   \n",
       " 11087                                 0.333333   \n",
       " 11088                                 0.666667   \n",
       " 11089                                 0.000000   \n",
       " 11090                                 0.500000   \n",
       " 11091                                 0.000000   \n",
       " 11092                                 0.000000   \n",
       " 11093                                 0.500000   \n",
       " 11094                                 0.500000   \n",
       " 11095                                 0.000000   \n",
       " 11096                                 0.500000   \n",
       " 11097                                 0.000000   \n",
       " 11098                                 0.900000   \n",
       " 11099                                 0.777778   \n",
       " 11100                                 0.000000   \n",
       " 11101                                 0.666667   \n",
       " \n",
       "        wn_synset_lesk_wsd_ratio_hi_freq_sum  \\\n",
       " 5551                               0.879779   \n",
       " 5552                               0.000000   \n",
       " 5553                               0.456629   \n",
       " 5554                               0.000000   \n",
       " 5555                               0.500000   \n",
       " 5556                               1.000000   \n",
       " 5557                               0.727137   \n",
       " 5558                               0.000000   \n",
       " 5559                               0.000000   \n",
       " 5560                               0.000000   \n",
       " 5561                               0.000000   \n",
       " 5562                               0.000000   \n",
       " 5563                               0.900928   \n",
       " 5564                               0.000000   \n",
       " 5565                               0.475232   \n",
       " 5566                               0.333333   \n",
       " 5567                               0.000000   \n",
       " 5568                               0.000000   \n",
       " 5569                               1.000000   \n",
       " 5570                               0.991095   \n",
       " 5571                               0.000000   \n",
       " 5572                               0.900928   \n",
       " 5573                               0.000000   \n",
       " 5574                               0.000000   \n",
       " 5575                               0.950464   \n",
       " 5576                               1.000000   \n",
       " 5577                               1.000000   \n",
       " 5578                               0.000000   \n",
       " 5579                               0.900928   \n",
       " 5580                               0.000000   \n",
       " ...                                     ...   \n",
       " 11072                              0.000000   \n",
       " 11073                              0.000000   \n",
       " 11074                              0.000000   \n",
       " 11075                              0.000000   \n",
       " 11076                              0.000000   \n",
       " 11077                              1.000000   \n",
       " 11078                              0.000000   \n",
       " 11079                              0.000000   \n",
       " 11080                              0.000000   \n",
       " 11081                              0.000000   \n",
       " 11082                              0.960363   \n",
       " 11083                              0.000000   \n",
       " 11084                              0.000000   \n",
       " 11085                              0.000000   \n",
       " 11086                              0.000000   \n",
       " 11087                              0.943633   \n",
       " 11088                              0.000000   \n",
       " 11089                              0.000000   \n",
       " 11090                              0.000000   \n",
       " 11091                              0.000000   \n",
       " 11092                              0.000000   \n",
       " 11093                              0.999564   \n",
       " 11094                              0.000000   \n",
       " 11095                              0.000000   \n",
       " 11096                              0.000000   \n",
       " 11097                              1.000000   \n",
       " 11098                              0.000000   \n",
       " 11099                              0.000000   \n",
       " 11100                              0.911565   \n",
       " 11101                              0.000000   \n",
       " \n",
       "        wn_synset_lesk_wsd_ratio_low_freq_sum  \\\n",
       " 5551                                0.005574   \n",
       " 5552                                1.000000   \n",
       " 5553                                0.102494   \n",
       " 5554                                0.000000   \n",
       " 5555                                0.000000   \n",
       " 5556                                0.000000   \n",
       " 5557                                0.272863   \n",
       " 5558                                0.001773   \n",
       " 5559                                0.000000   \n",
       " 5560                                0.108674   \n",
       " 5561                                0.543371   \n",
       " 5562                                0.000000   \n",
       " 5563                                0.005688   \n",
       " 5564                                0.023619   \n",
       " 5565                                0.097449   \n",
       " 5566                                0.128036   \n",
       " 5567                                0.384107   \n",
       " 5568                                0.000000   \n",
       " 5569                                0.000000   \n",
       " 5570                                0.008905   \n",
       " 5571                                0.163895   \n",
       " 5572                                0.005688   \n",
       " 5573                                0.088355   \n",
       " 5574                                0.059359   \n",
       " 5575                                0.002844   \n",
       " 5576                                0.000000   \n",
       " 5577                                0.000000   \n",
       " 5578                                1.000000   \n",
       " 5579                                0.005688   \n",
       " 5580                                0.000000   \n",
       " ...                                      ...   \n",
       " 11072                               0.000000   \n",
       " 11073                               0.000000   \n",
       " 11074                               0.000000   \n",
       " 11075                               0.000000   \n",
       " 11076                               0.000000   \n",
       " 11077                               0.000000   \n",
       " 11078                               0.000000   \n",
       " 11079                               0.000000   \n",
       " 11080                               0.000000   \n",
       " 11081                               0.000000   \n",
       " 11082                               0.039637   \n",
       " 11083                               0.018495   \n",
       " 11084                               0.000000   \n",
       " 11085                               0.000000   \n",
       " 11086                               0.000000   \n",
       " 11087                               0.022590   \n",
       " 11088                               0.162007   \n",
       " 11089                               0.000000   \n",
       " 11090                               0.449899   \n",
       " 11091                               0.000000   \n",
       " 11092                               0.000000   \n",
       " 11093                               0.000436   \n",
       " 11094                               0.000000   \n",
       " 11095                               0.000000   \n",
       " 11096                               0.317142   \n",
       " 11097                               0.000000   \n",
       " 11098                               0.295570   \n",
       " 11099                               0.362164   \n",
       " 11100                               0.000000   \n",
       " 11101                               0.145537   \n",
       " \n",
       "        wn_synset_lesk_wsd_ratio_to_freq_sum  \\\n",
       " 5551                               0.114647   \n",
       " 5552                               0.949241   \n",
       " 5553                               0.440878   \n",
       " 5554                               1.000000   \n",
       " 5555                               0.658969   \n",
       " 5556                               0.317939   \n",
       " 5557                               0.341843   \n",
       " 5558                               0.998227   \n",
       " 5559                               1.000000   \n",
       " 5560                               0.491326   \n",
       " 5561                               0.456629   \n",
       " 5562                               1.000000   \n",
       " 5563                               0.093384   \n",
       " 5564                               0.976381   \n",
       " 5565                               0.368647   \n",
       " 5566                               0.460401   \n",
       " 5567                               0.615893   \n",
       " 5568                               0.000000   \n",
       " 5569                               0.765310   \n",
       " 5570                               0.082388   \n",
       " 5571                               0.836105   \n",
       " 5572                               0.093384   \n",
       " 5573                               0.911645   \n",
       " 5574                               0.940641   \n",
       " 5575                               0.459505   \n",
       " 5576                               0.008715   \n",
       " 5577                               0.825626   \n",
       " 5578                               1.890660   \n",
       " 5579                               0.093384   \n",
       " 5580                               1.000000   \n",
       " ...                                     ...   \n",
       " 11072                              0.000000   \n",
       " 11073                              0.000000   \n",
       " 11074                              1.000000   \n",
       " 11075                              1.000000   \n",
       " 11076                              1.000000   \n",
       " 11077                              0.401464   \n",
       " 11078                              1.000000   \n",
       " 11079                              1.000000   \n",
       " 11080                              1.000000   \n",
       " 11081                              0.000000   \n",
       " 11082                              0.058880   \n",
       " 11083                              0.981505   \n",
       " 11084                              0.000000   \n",
       " 11085                              0.500000   \n",
       " 11086                              1.000000   \n",
       " 11087                              0.033778   \n",
       " 11088                              0.837993   \n",
       " 11089                              0.000000   \n",
       " 11090                              0.550101   \n",
       " 11091                              1.000000   \n",
       " 11092                              1.000000   \n",
       " 11093                              0.117071   \n",
       " 11094                              1.000000   \n",
       " 11095                              1.000000   \n",
       " 11096                              0.682858   \n",
       " 11097                              0.431929   \n",
       " 11098                              0.704430   \n",
       " 11099                              0.318918   \n",
       " 11100                              0.088435   \n",
       " 11101                              0.427231   \n",
       " \n",
       "        wn_synset_lesk_wsd__norm_sense_rank  \n",
       " 5551                              0.000000  \n",
       " 5552                              0.080000  \n",
       " 5553                              0.166667  \n",
       " 5554                              0.857143  \n",
       " 5555                              0.500000  \n",
       " 5556                              0.142857  \n",
       " 5557                              0.444444  \n",
       " 5558                              0.833333  \n",
       " 5559                              0.000000  \n",
       " 5560                              0.208889  \n",
       " 5561                              0.600000  \n",
       " 5562                              0.444444  \n",
       " 5563                              0.400000  \n",
       " 5564                              0.810811  \n",
       " 5565                              0.169444  \n",
       " 5566                              0.092593  \n",
       " 5567                              0.277778  \n",
       " 5568                              0.000000  \n",
       " 5569                              0.000000  \n",
       " 5570                              0.400000  \n",
       " 5571                              0.000000  \n",
       " 5572                              0.400000  \n",
       " 5573                              0.294118  \n",
       " 5574                              0.400000  \n",
       " 5575                              0.533333  \n",
       " 5576                              0.000000  \n",
       " 5577                              0.666667  \n",
       " 5578                              0.500000  \n",
       " 5579                              0.400000  \n",
       " 5580                              0.777778  \n",
       " ...                                    ...  \n",
       " 11072                             0.000000  \n",
       " 11073                             0.000000  \n",
       " 11074                             0.299242  \n",
       " 11075                             0.181818  \n",
       " 11076                             0.416667  \n",
       " 11077                             0.921053  \n",
       " 11078                             0.000000  \n",
       " 11079                             0.250000  \n",
       " 11080                             0.000000  \n",
       " 11081                             0.000000  \n",
       " 11082                             0.400000  \n",
       " 11083                             0.000000  \n",
       " 11084                             0.000000  \n",
       " 11085                             0.166667  \n",
       " 11086                             0.333333  \n",
       " 11087                             0.000000  \n",
       " 11088                             0.500000  \n",
       " 11089                             0.000000  \n",
       " 11090                             0.400000  \n",
       " 11091                             0.750000  \n",
       " 11092                             0.666667  \n",
       " 11093                             0.687500  \n",
       " 11094                             0.666667  \n",
       " 11095                             0.250000  \n",
       " 11096                             0.777778  \n",
       " 11097                             0.473684  \n",
       " 11098                             0.000000  \n",
       " 11099                             0.333333  \n",
       " 11100                             0.000000  \n",
       " 11101                             0.200000  \n",
       " \n",
       " [5551 rows x 39 columns])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = ctx_datasets_fc_context_complexity[0].train\n",
    "test = ctx_datasets_fc_context_complexity[0].train\n",
    "train = remove_label_for_binary_df_and_ctx_features(train)\n",
    "test = remove_label_for_binary_df_and_ctx_features(test)\n",
    "transform_feat_to_num(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (5.2.1) XGBoost Target Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 13.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=100, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=2)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(random_grid)\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "fs = ctx_datasets_fc_context_complexity[0]\n",
    "train, test = transform_feat_to_num(remove_label_for_binary_df_and_ctx_features(fs.train), \\\n",
    "        remove_label_for_binary_df_and_ctx_features(fs.test))\n",
    "x_train = train.loc[:, train.columns != 'binary']\n",
    "y_train = train.binary.values\n",
    "rf_random.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1800,\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 4,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 10,\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1800 out of 1800 | elapsed:   26.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 1800 out of 1800 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Done 1800 out of 1800 | elapsed:  1.0min finished\n",
      "[Parallel(n_jobs=1)]: Done 1800 out of 1800 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Done 1800 out of 1800 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=1)]: Done 1800 out of 1800 | elapsed:    0.6s finished\n"
     ]
    }
   ],
   "source": [
    "results = [Result(fs, fs.fc, fs.agg, fs.context,\n",
    "    random_forest(*transform_feat_to_num(remove_label_for_binary_df_and_ctx_features(fs.train), \n",
    "        remove_label_for_binary_df_and_ctx_features(fs.test)))) for fs in ctx_datasets_fc_context_complexity[0:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = [{'dataset' : result.dataset.name, 'agg' : result.agg[0],\n",
    "                    'zc' : result.fc, 'prec' : result.measure[0][1],\n",
    "               'rec' : result.measure[1][1], 'f1' : result.measure[2][1]} \n",
    "                   for result in results]\n",
    "feature_eval_data = pd.DataFrame.from_records(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agg</th>\n",
       "      <th>dataset</th>\n",
       "      <th>f1</th>\n",
       "      <th>prec</th>\n",
       "      <th>rec</th>\n",
       "      <th>zc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(dist, &lt;function agg_ctx_feat_num_distance at 0x000000FC01E1DEA0&gt;)</td>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>0.765292</td>\n",
       "      <td>0.739011</td>\n",
       "      <td>0.793510</td>\n",
       "      <td>(context_complexity, [(context_complexity_from_target, &lt;function ctx_features_context_complexity_from_target at 0x000000FC25B7FD90&gt;), (context_complexity_from_context, &lt;function ctx_features_conte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(dist, &lt;function agg_ctx_feat_num_distance at 0x000000FC01E1DEA0&gt;)</td>\n",
       "      <td>WikiNews</td>\n",
       "      <td>0.789546</td>\n",
       "      <td>0.767380</td>\n",
       "      <td>0.813031</td>\n",
       "      <td>(context_complexity, [(context_complexity_from_target, &lt;function ctx_features_context_complexity_from_target at 0x000000FC25B7FD90&gt;), (context_complexity_from_context, &lt;function ctx_features_conte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(dist, &lt;function agg_ctx_feat_num_distance at 0x000000FC01E1DEA0&gt;)</td>\n",
       "      <td>News</td>\n",
       "      <td>0.839523</td>\n",
       "      <td>0.819425</td>\n",
       "      <td>0.860632</td>\n",
       "      <td>(context_complexity, [(context_complexity_from_target, &lt;function ctx_features_context_complexity_from_target at 0x000000FC25B7FD90&gt;), (context_complexity_from_context, &lt;function ctx_features_conte...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  agg  \\\n",
       "0  (dist, <function agg_ctx_feat_num_distance at 0x000000FC01E1DEA0>)   \n",
       "1  (dist, <function agg_ctx_feat_num_distance at 0x000000FC01E1DEA0>)   \n",
       "2  (dist, <function agg_ctx_feat_num_distance at 0x000000FC01E1DEA0>)   \n",
       "\n",
       "     dataset        f1      prec       rec  \\\n",
       "0  Wikipedia  0.765292  0.739011  0.793510   \n",
       "1   WikiNews  0.789546  0.767380  0.813031   \n",
       "2       News  0.839523  0.819425  0.860632   \n",
       "\n",
       "                                                                                                                                                                                                        zc  \n",
       "0  (context_complexity, [(context_complexity_from_target, <function ctx_features_context_complexity_from_target at 0x000000FC25B7FD90>), (context_complexity_from_context, <function ctx_features_conte...  \n",
       "1  (context_complexity, [(context_complexity_from_target, <function ctx_features_context_complexity_from_target at 0x000000FC25B7FD90>), (context_complexity_from_context, <function ctx_features_conte...  \n",
       "2  (context_complexity, [(context_complexity_from_target, <function ctx_features_context_complexity_from_target at 0x000000FC25B7FD90>), (context_complexity_from_context, <function ctx_features_conte...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_eval_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (5.2.2) Adding Context Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1800 out of 1800 | elapsed:   36.8s finished\n",
      "[Parallel(n_jobs=1)]: Done 1800 out of 1800 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Done 1800 out of 1800 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=1)]: Done 1800 out of 1800 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Done 1800 out of 1800 | elapsed:  1.7min finished\n",
      "[Parallel(n_jobs=1)]: Done 1800 out of 1800 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Done 1800 out of 1800 | elapsed:   37.7s finished\n",
      "[Parallel(n_jobs=1)]: Done 1800 out of 1800 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Done 1800 out of 1800 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=1)]: Done 1800 out of 1800 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Done 1800 out of 1800 | elapsed:  1.7min finished\n",
      "[Parallel(n_jobs=1)]: Done 1800 out of 1800 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Done 1800 out of 1800 | elapsed:   38.5s finished\n",
      "[Parallel(n_jobs=1)]: Done 1800 out of 1800 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Done 1800 out of 1800 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=1)]: Done 1800 out of 1800 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Done 1800 out of 1800 | elapsed:  1.8min finished\n",
      "[Parallel(n_jobs=1)]: Done 1800 out of 1800 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Done 1800 out of 1800 | elapsed:   39.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 1800 out of 1800 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Done 1800 out of 1800 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=1)]: Done 1800 out of 1800 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Done 1800 out of 1800 | elapsed:  1.8min finished\n",
      "[Parallel(n_jobs=1)]: Done 1800 out of 1800 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Done 1800 out of 1800 | elapsed:   32.8s finished\n",
      "[Parallel(n_jobs=1)]: Done 1800 out of 1800 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Done 1800 out of 1800 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=1)]: Done 1800 out of 1800 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Done 1800 out of 1800 | elapsed:  1.6min finished\n",
      "[Parallel(n_jobs=1)]: Done 1800 out of 1800 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Done 1800 out of 1800 | elapsed:   33.4s finished\n",
      "[Parallel(n_jobs=1)]: Done 1800 out of 1800 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Done 1800 out of 1800 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=1)]: Done 1800 out of 1800 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Done 1800 out of 1800 | elapsed:  1.6min finished\n",
      "[Parallel(n_jobs=1)]: Done 1800 out of 1800 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Done 1800 out of 1800 | elapsed:   37.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 1800 out of 1800 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Done 1800 out of 1800 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=1)]: Done 1800 out of 1800 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Done 1800 out of 1800 | elapsed:  1.7min finished\n",
      "[Parallel(n_jobs=1)]: Done 1800 out of 1800 | elapsed:    0.6s finished\n"
     ]
    }
   ],
   "source": [
    "results = [Result(fs, fs.fc, fs.agg, fs.context,\n",
    "    random_forest(*transform_feat_to_num(remove_labels_for_binary_df(fs.train), \n",
    "        remove_labels_for_binary_df(fs.test)))) for fs in ctx_datasets_fc_context_complexity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agg</th>\n",
       "      <th>context</th>\n",
       "      <th>dataset</th>\n",
       "      <th>f1</th>\n",
       "      <th>prec</th>\n",
       "      <th>rec</th>\n",
       "      <th>zc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(dist, &lt;function agg_ctx_feat_num_distance at 0x000000FC01E1DEA0&gt;)</td>\n",
       "      <td>[(ctx_window_pre_suc_n, {'n': 2, 'filtering': True}, &lt;function &lt;lambda&gt; at 0x000000FC7A0AD620&gt;), (ctx_window_pre_suc_n, {'n': 2, 'filtering': True}, &lt;function &lt;lambda&gt; at 0x000000FC7A0AD620&gt;)]</td>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>0.764622</td>\n",
       "      <td>0.740331</td>\n",
       "      <td>0.790560</td>\n",
       "      <td>(context_complexity, [(context_complexity_from_target, &lt;function ctx_features_context_complexity_from_target at 0x000000FC25B7FD90&gt;), (context_complexity_from_context, &lt;function ctx_features_conte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(dist, &lt;function agg_ctx_feat_num_distance at 0x000000FC01E1DEA0&gt;)</td>\n",
       "      <td>[(ctx_window_pre_suc_n, {'n': 2, 'filtering': True}, &lt;function &lt;lambda&gt; at 0x000000FC7A0AD620&gt;), (ctx_window_pre_suc_n, {'n': 2, 'filtering': True}, &lt;function &lt;lambda&gt; at 0x000000FC7A0AD620&gt;)]</td>\n",
       "      <td>WikiNews</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.772358</td>\n",
       "      <td>0.807365</td>\n",
       "      <td>(context_complexity, [(context_complexity_from_target, &lt;function ctx_features_context_complexity_from_target at 0x000000FC25B7FD90&gt;), (context_complexity_from_context, &lt;function ctx_features_conte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(dist, &lt;function agg_ctx_feat_num_distance at 0x000000FC01E1DEA0&gt;)</td>\n",
       "      <td>[(ctx_window_pre_suc_n, {'n': 2, 'filtering': True}, &lt;function &lt;lambda&gt; at 0x000000FC7A0AD620&gt;), (ctx_window_pre_suc_n, {'n': 2, 'filtering': True}, &lt;function &lt;lambda&gt; at 0x000000FC7A0AD620&gt;)]</td>\n",
       "      <td>News</td>\n",
       "      <td>0.838122</td>\n",
       "      <td>0.818057</td>\n",
       "      <td>0.859195</td>\n",
       "      <td>(context_complexity, [(context_complexity_from_target, &lt;function ctx_features_context_complexity_from_target at 0x000000FC25B7FD90&gt;), (context_complexity_from_context, &lt;function ctx_features_conte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(dist, &lt;function agg_ctx_feat_num_distance at 0x000000FC01E1DEA0&gt;)</td>\n",
       "      <td>[(ctx_window_pre_suc_n, {'n': 3, 'filtering': True}, &lt;function &lt;lambda&gt; at 0x000000FC7A0AD6A8&gt;), (ctx_window_pre_suc_n, {'n': 3, 'filtering': True}, &lt;function &lt;lambda&gt; at 0x000000FC7A0AD6A8&gt;)]</td>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>0.758226</td>\n",
       "      <td>0.736111</td>\n",
       "      <td>0.781711</td>\n",
       "      <td>(context_complexity, [(context_complexity_from_target, &lt;function ctx_features_context_complexity_from_target at 0x000000FC25B7FD90&gt;), (context_complexity_from_context, &lt;function ctx_features_conte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(dist, &lt;function agg_ctx_feat_num_distance at 0x000000FC01E1DEA0&gt;)</td>\n",
       "      <td>[(ctx_window_pre_suc_n, {'n': 3, 'filtering': True}, &lt;function &lt;lambda&gt; at 0x000000FC7A0AD6A8&gt;), (ctx_window_pre_suc_n, {'n': 3, 'filtering': True}, &lt;function &lt;lambda&gt; at 0x000000FC7A0AD6A8&gt;)]</td>\n",
       "      <td>WikiNews</td>\n",
       "      <td>0.787795</td>\n",
       "      <td>0.771739</td>\n",
       "      <td>0.804533</td>\n",
       "      <td>(context_complexity, [(context_complexity_from_target, &lt;function ctx_features_context_complexity_from_target at 0x000000FC25B7FD90&gt;), (context_complexity_from_context, &lt;function ctx_features_conte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(dist, &lt;function agg_ctx_feat_num_distance at 0x000000FC01E1DEA0&gt;)</td>\n",
       "      <td>[(ctx_window_pre_suc_n, {'n': 3, 'filtering': True}, &lt;function &lt;lambda&gt; at 0x000000FC7A0AD6A8&gt;), (ctx_window_pre_suc_n, {'n': 3, 'filtering': True}, &lt;function &lt;lambda&gt; at 0x000000FC7A0AD6A8&gt;)]</td>\n",
       "      <td>News</td>\n",
       "      <td>0.837307</td>\n",
       "      <td>0.817808</td>\n",
       "      <td>0.857759</td>\n",
       "      <td>(context_complexity, [(context_complexity_from_target, &lt;function ctx_features_context_complexity_from_target at 0x000000FC25B7FD90&gt;), (context_complexity_from_context, &lt;function ctx_features_conte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(dist, &lt;function agg_ctx_feat_num_distance at 0x000000FC01E1DEA0&gt;)</td>\n",
       "      <td>[(ctx_window_pre_suc_n, {'n': 4, 'filtering': True}, &lt;function &lt;lambda&gt; at 0x000000FC7A0AD730&gt;), (ctx_window_pre_suc_n, {'n': 4, 'filtering': True}, &lt;function &lt;lambda&gt; at 0x000000FC7A0AD730&gt;)]</td>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>0.758523</td>\n",
       "      <td>0.731507</td>\n",
       "      <td>0.787611</td>\n",
       "      <td>(context_complexity, [(context_complexity_from_target, &lt;function ctx_features_context_complexity_from_target at 0x000000FC25B7FD90&gt;), (context_complexity_from_context, &lt;function ctx_features_conte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(dist, &lt;function agg_ctx_feat_num_distance at 0x000000FC01E1DEA0&gt;)</td>\n",
       "      <td>[(ctx_window_pre_suc_n, {'n': 4, 'filtering': True}, &lt;function &lt;lambda&gt; at 0x000000FC7A0AD730&gt;), (ctx_window_pre_suc_n, {'n': 4, 'filtering': True}, &lt;function &lt;lambda&gt; at 0x000000FC7A0AD730&gt;)]</td>\n",
       "      <td>WikiNews</td>\n",
       "      <td>0.787204</td>\n",
       "      <td>0.773224</td>\n",
       "      <td>0.801700</td>\n",
       "      <td>(context_complexity, [(context_complexity_from_target, &lt;function ctx_features_context_complexity_from_target at 0x000000FC25B7FD90&gt;), (context_complexity_from_context, &lt;function ctx_features_conte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(dist, &lt;function agg_ctx_feat_num_distance at 0x000000FC01E1DEA0&gt;)</td>\n",
       "      <td>[(ctx_window_pre_suc_n, {'n': 4, 'filtering': True}, &lt;function &lt;lambda&gt; at 0x000000FC7A0AD730&gt;), (ctx_window_pre_suc_n, {'n': 4, 'filtering': True}, &lt;function &lt;lambda&gt; at 0x000000FC7A0AD730&gt;)]</td>\n",
       "      <td>News</td>\n",
       "      <td>0.837079</td>\n",
       "      <td>0.818681</td>\n",
       "      <td>0.856322</td>\n",
       "      <td>(context_complexity, [(context_complexity_from_target, &lt;function ctx_features_context_complexity_from_target at 0x000000FC25B7FD90&gt;), (context_complexity_from_context, &lt;function ctx_features_conte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(dist, &lt;function agg_ctx_feat_num_distance at 0x000000FC01E1DEA0&gt;)</td>\n",
       "      <td>[(ctx_window_pre_suc_n, {'n': 5, 'filtering': True}, &lt;function &lt;lambda&gt; at 0x000000FC7A0AD7B8&gt;), (ctx_window_pre_suc_n, {'n': 5, 'filtering': True}, &lt;function &lt;lambda&gt; at 0x000000FC7A0AD7B8&gt;)]</td>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>0.759602</td>\n",
       "      <td>0.733516</td>\n",
       "      <td>0.787611</td>\n",
       "      <td>(context_complexity, [(context_complexity_from_target, &lt;function ctx_features_context_complexity_from_target at 0x000000FC25B7FD90&gt;), (context_complexity_from_context, &lt;function ctx_features_conte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(dist, &lt;function agg_ctx_feat_num_distance at 0x000000FC01E1DEA0&gt;)</td>\n",
       "      <td>[(ctx_window_pre_suc_n, {'n': 5, 'filtering': True}, &lt;function &lt;lambda&gt; at 0x000000FC7A0AD7B8&gt;), (ctx_window_pre_suc_n, {'n': 5, 'filtering': True}, &lt;function &lt;lambda&gt; at 0x000000FC7A0AD7B8&gt;)]</td>\n",
       "      <td>WikiNews</td>\n",
       "      <td>0.782730</td>\n",
       "      <td>0.769863</td>\n",
       "      <td>0.796034</td>\n",
       "      <td>(context_complexity, [(context_complexity_from_target, &lt;function ctx_features_context_complexity_from_target at 0x000000FC25B7FD90&gt;), (context_complexity_from_context, &lt;function ctx_features_conte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(dist, &lt;function agg_ctx_feat_num_distance at 0x000000FC01E1DEA0&gt;)</td>\n",
       "      <td>[(ctx_window_pre_suc_n, {'n': 5, 'filtering': True}, &lt;function &lt;lambda&gt; at 0x000000FC7A0AD7B8&gt;), (ctx_window_pre_suc_n, {'n': 5, 'filtering': True}, &lt;function &lt;lambda&gt; at 0x000000FC7A0AD7B8&gt;)]</td>\n",
       "      <td>News</td>\n",
       "      <td>0.836491</td>\n",
       "      <td>0.817558</td>\n",
       "      <td>0.856322</td>\n",
       "      <td>(context_complexity, [(context_complexity_from_target, &lt;function ctx_features_context_complexity_from_target at 0x000000FC25B7FD90&gt;), (context_complexity_from_context, &lt;function ctx_features_conte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(dist, &lt;function agg_ctx_feat_num_distance at 0x000000FC01E1DEA0&gt;)</td>\n",
       "      <td>[(ctx_dep_in, {'filtering': True}, &lt;function &lt;lambda&gt; at 0x000000FC7A0ADA60&gt;), (ctx_dep_in, {'filtering': True}, &lt;function &lt;lambda&gt; at 0x000000FC7A0ADA60&gt;)]</td>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>0.763271</td>\n",
       "      <td>0.743017</td>\n",
       "      <td>0.784661</td>\n",
       "      <td>(context_complexity, [(context_complexity_from_target, &lt;function ctx_features_context_complexity_from_target at 0x000000FC25B7FD90&gt;), (context_complexity_from_context, &lt;function ctx_features_conte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(dist, &lt;function agg_ctx_feat_num_distance at 0x000000FC01E1DEA0&gt;)</td>\n",
       "      <td>[(ctx_dep_in, {'filtering': True}, &lt;function &lt;lambda&gt; at 0x000000FC7A0ADA60&gt;), (ctx_dep_in, {'filtering': True}, &lt;function &lt;lambda&gt; at 0x000000FC7A0ADA60&gt;)]</td>\n",
       "      <td>WikiNews</td>\n",
       "      <td>0.794444</td>\n",
       "      <td>0.779292</td>\n",
       "      <td>0.810198</td>\n",
       "      <td>(context_complexity, [(context_complexity_from_target, &lt;function ctx_features_context_complexity_from_target at 0x000000FC25B7FD90&gt;), (context_complexity_from_context, &lt;function ctx_features_conte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(dist, &lt;function agg_ctx_feat_num_distance at 0x000000FC01E1DEA0&gt;)</td>\n",
       "      <td>[(ctx_dep_in, {'filtering': True}, &lt;function &lt;lambda&gt; at 0x000000FC7A0ADA60&gt;), (ctx_dep_in, {'filtering': True}, &lt;function &lt;lambda&gt; at 0x000000FC7A0ADA60&gt;)]</td>\n",
       "      <td>News</td>\n",
       "      <td>0.839072</td>\n",
       "      <td>0.821183</td>\n",
       "      <td>0.857759</td>\n",
       "      <td>(context_complexity, [(context_complexity_from_target, &lt;function ctx_features_context_complexity_from_target at 0x000000FC25B7FD90&gt;), (context_complexity_from_context, &lt;function ctx_features_conte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(dist, &lt;function agg_ctx_feat_num_distance at 0x000000FC01E1DEA0&gt;)</td>\n",
       "      <td>[(ctx_dep_out, {'filtering': True}, &lt;function &lt;lambda&gt; at 0x000000FC7A0ADAE8&gt;), (ctx_dep_out, {'filtering': True}, &lt;function &lt;lambda&gt; at 0x000000FC7A0ADAE8&gt;)]</td>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>0.749642</td>\n",
       "      <td>0.727778</td>\n",
       "      <td>0.772861</td>\n",
       "      <td>(context_complexity, [(context_complexity_from_target, &lt;function ctx_features_context_complexity_from_target at 0x000000FC25B7FD90&gt;), (context_complexity_from_context, &lt;function ctx_features_conte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(dist, &lt;function agg_ctx_feat_num_distance at 0x000000FC01E1DEA0&gt;)</td>\n",
       "      <td>[(ctx_dep_out, {'filtering': True}, &lt;function &lt;lambda&gt; at 0x000000FC7A0ADAE8&gt;), (ctx_dep_out, {'filtering': True}, &lt;function &lt;lambda&gt; at 0x000000FC7A0ADAE8&gt;)]</td>\n",
       "      <td>WikiNews</td>\n",
       "      <td>0.792190</td>\n",
       "      <td>0.780220</td>\n",
       "      <td>0.804533</td>\n",
       "      <td>(context_complexity, [(context_complexity_from_target, &lt;function ctx_features_context_complexity_from_target at 0x000000FC25B7FD90&gt;), (context_complexity_from_context, &lt;function ctx_features_conte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(dist, &lt;function agg_ctx_feat_num_distance at 0x000000FC01E1DEA0&gt;)</td>\n",
       "      <td>[(ctx_dep_out, {'filtering': True}, &lt;function &lt;lambda&gt; at 0x000000FC7A0ADAE8&gt;), (ctx_dep_out, {'filtering': True}, &lt;function &lt;lambda&gt; at 0x000000FC7A0ADAE8&gt;)]</td>\n",
       "      <td>News</td>\n",
       "      <td>0.833566</td>\n",
       "      <td>0.811989</td>\n",
       "      <td>0.856322</td>\n",
       "      <td>(context_complexity, [(context_complexity_from_target, &lt;function ctx_features_context_complexity_from_target at 0x000000FC25B7FD90&gt;), (context_complexity_from_context, &lt;function ctx_features_conte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(dist, &lt;function agg_ctx_feat_num_distance at 0x000000FC01E1DEA0&gt;)</td>\n",
       "      <td>[(ctx_dep_in_out, {'filtering': True}, &lt;function &lt;lambda&gt; at 0x000000FC7A0ADB70&gt;), (ctx_dep_in_out, {'filtering': True}, &lt;function &lt;lambda&gt; at 0x000000FC7A0ADB70&gt;)]</td>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>0.746398</td>\n",
       "      <td>0.729577</td>\n",
       "      <td>0.764012</td>\n",
       "      <td>(context_complexity, [(context_complexity_from_target, &lt;function ctx_features_context_complexity_from_target at 0x000000FC25B7FD90&gt;), (context_complexity_from_context, &lt;function ctx_features_conte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(dist, &lt;function agg_ctx_feat_num_distance at 0x000000FC01E1DEA0&gt;)</td>\n",
       "      <td>[(ctx_dep_in_out, {'filtering': True}, &lt;function &lt;lambda&gt; at 0x000000FC7A0ADB70&gt;), (ctx_dep_in_out, {'filtering': True}, &lt;function &lt;lambda&gt; at 0x000000FC7A0ADB70&gt;)]</td>\n",
       "      <td>WikiNews</td>\n",
       "      <td>0.794444</td>\n",
       "      <td>0.779292</td>\n",
       "      <td>0.810198</td>\n",
       "      <td>(context_complexity, [(context_complexity_from_target, &lt;function ctx_features_context_complexity_from_target at 0x000000FC25B7FD90&gt;), (context_complexity_from_context, &lt;function ctx_features_conte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(dist, &lt;function agg_ctx_feat_num_distance at 0x000000FC01E1DEA0&gt;)</td>\n",
       "      <td>[(ctx_dep_in_out, {'filtering': True}, &lt;function &lt;lambda&gt; at 0x000000FC7A0ADB70&gt;), (ctx_dep_in_out, {'filtering': True}, &lt;function &lt;lambda&gt; at 0x000000FC7A0ADB70&gt;)]</td>\n",
       "      <td>News</td>\n",
       "      <td>0.837438</td>\n",
       "      <td>0.820690</td>\n",
       "      <td>0.854885</td>\n",
       "      <td>(context_complexity, [(context_complexity_from_target, &lt;function ctx_features_context_complexity_from_target at 0x000000FC25B7FD90&gt;), (context_complexity_from_context, &lt;function ctx_features_conte...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   agg  \\\n",
       "0   (dist, <function agg_ctx_feat_num_distance at 0x000000FC01E1DEA0>)   \n",
       "1   (dist, <function agg_ctx_feat_num_distance at 0x000000FC01E1DEA0>)   \n",
       "2   (dist, <function agg_ctx_feat_num_distance at 0x000000FC01E1DEA0>)   \n",
       "3   (dist, <function agg_ctx_feat_num_distance at 0x000000FC01E1DEA0>)   \n",
       "4   (dist, <function agg_ctx_feat_num_distance at 0x000000FC01E1DEA0>)   \n",
       "5   (dist, <function agg_ctx_feat_num_distance at 0x000000FC01E1DEA0>)   \n",
       "6   (dist, <function agg_ctx_feat_num_distance at 0x000000FC01E1DEA0>)   \n",
       "7   (dist, <function agg_ctx_feat_num_distance at 0x000000FC01E1DEA0>)   \n",
       "8   (dist, <function agg_ctx_feat_num_distance at 0x000000FC01E1DEA0>)   \n",
       "9   (dist, <function agg_ctx_feat_num_distance at 0x000000FC01E1DEA0>)   \n",
       "10  (dist, <function agg_ctx_feat_num_distance at 0x000000FC01E1DEA0>)   \n",
       "11  (dist, <function agg_ctx_feat_num_distance at 0x000000FC01E1DEA0>)   \n",
       "12  (dist, <function agg_ctx_feat_num_distance at 0x000000FC01E1DEA0>)   \n",
       "13  (dist, <function agg_ctx_feat_num_distance at 0x000000FC01E1DEA0>)   \n",
       "14  (dist, <function agg_ctx_feat_num_distance at 0x000000FC01E1DEA0>)   \n",
       "15  (dist, <function agg_ctx_feat_num_distance at 0x000000FC01E1DEA0>)   \n",
       "16  (dist, <function agg_ctx_feat_num_distance at 0x000000FC01E1DEA0>)   \n",
       "17  (dist, <function agg_ctx_feat_num_distance at 0x000000FC01E1DEA0>)   \n",
       "18  (dist, <function agg_ctx_feat_num_distance at 0x000000FC01E1DEA0>)   \n",
       "19  (dist, <function agg_ctx_feat_num_distance at 0x000000FC01E1DEA0>)   \n",
       "20  (dist, <function agg_ctx_feat_num_distance at 0x000000FC01E1DEA0>)   \n",
       "\n",
       "                                                                                                                                                                                             context  \\\n",
       "0   [(ctx_window_pre_suc_n, {'n': 2, 'filtering': True}, <function <lambda> at 0x000000FC7A0AD620>), (ctx_window_pre_suc_n, {'n': 2, 'filtering': True}, <function <lambda> at 0x000000FC7A0AD620>)]   \n",
       "1   [(ctx_window_pre_suc_n, {'n': 2, 'filtering': True}, <function <lambda> at 0x000000FC7A0AD620>), (ctx_window_pre_suc_n, {'n': 2, 'filtering': True}, <function <lambda> at 0x000000FC7A0AD620>)]   \n",
       "2   [(ctx_window_pre_suc_n, {'n': 2, 'filtering': True}, <function <lambda> at 0x000000FC7A0AD620>), (ctx_window_pre_suc_n, {'n': 2, 'filtering': True}, <function <lambda> at 0x000000FC7A0AD620>)]   \n",
       "3   [(ctx_window_pre_suc_n, {'n': 3, 'filtering': True}, <function <lambda> at 0x000000FC7A0AD6A8>), (ctx_window_pre_suc_n, {'n': 3, 'filtering': True}, <function <lambda> at 0x000000FC7A0AD6A8>)]   \n",
       "4   [(ctx_window_pre_suc_n, {'n': 3, 'filtering': True}, <function <lambda> at 0x000000FC7A0AD6A8>), (ctx_window_pre_suc_n, {'n': 3, 'filtering': True}, <function <lambda> at 0x000000FC7A0AD6A8>)]   \n",
       "5   [(ctx_window_pre_suc_n, {'n': 3, 'filtering': True}, <function <lambda> at 0x000000FC7A0AD6A8>), (ctx_window_pre_suc_n, {'n': 3, 'filtering': True}, <function <lambda> at 0x000000FC7A0AD6A8>)]   \n",
       "6   [(ctx_window_pre_suc_n, {'n': 4, 'filtering': True}, <function <lambda> at 0x000000FC7A0AD730>), (ctx_window_pre_suc_n, {'n': 4, 'filtering': True}, <function <lambda> at 0x000000FC7A0AD730>)]   \n",
       "7   [(ctx_window_pre_suc_n, {'n': 4, 'filtering': True}, <function <lambda> at 0x000000FC7A0AD730>), (ctx_window_pre_suc_n, {'n': 4, 'filtering': True}, <function <lambda> at 0x000000FC7A0AD730>)]   \n",
       "8   [(ctx_window_pre_suc_n, {'n': 4, 'filtering': True}, <function <lambda> at 0x000000FC7A0AD730>), (ctx_window_pre_suc_n, {'n': 4, 'filtering': True}, <function <lambda> at 0x000000FC7A0AD730>)]   \n",
       "9   [(ctx_window_pre_suc_n, {'n': 5, 'filtering': True}, <function <lambda> at 0x000000FC7A0AD7B8>), (ctx_window_pre_suc_n, {'n': 5, 'filtering': True}, <function <lambda> at 0x000000FC7A0AD7B8>)]   \n",
       "10  [(ctx_window_pre_suc_n, {'n': 5, 'filtering': True}, <function <lambda> at 0x000000FC7A0AD7B8>), (ctx_window_pre_suc_n, {'n': 5, 'filtering': True}, <function <lambda> at 0x000000FC7A0AD7B8>)]   \n",
       "11  [(ctx_window_pre_suc_n, {'n': 5, 'filtering': True}, <function <lambda> at 0x000000FC7A0AD7B8>), (ctx_window_pre_suc_n, {'n': 5, 'filtering': True}, <function <lambda> at 0x000000FC7A0AD7B8>)]   \n",
       "12                                      [(ctx_dep_in, {'filtering': True}, <function <lambda> at 0x000000FC7A0ADA60>), (ctx_dep_in, {'filtering': True}, <function <lambda> at 0x000000FC7A0ADA60>)]   \n",
       "13                                      [(ctx_dep_in, {'filtering': True}, <function <lambda> at 0x000000FC7A0ADA60>), (ctx_dep_in, {'filtering': True}, <function <lambda> at 0x000000FC7A0ADA60>)]   \n",
       "14                                      [(ctx_dep_in, {'filtering': True}, <function <lambda> at 0x000000FC7A0ADA60>), (ctx_dep_in, {'filtering': True}, <function <lambda> at 0x000000FC7A0ADA60>)]   \n",
       "15                                    [(ctx_dep_out, {'filtering': True}, <function <lambda> at 0x000000FC7A0ADAE8>), (ctx_dep_out, {'filtering': True}, <function <lambda> at 0x000000FC7A0ADAE8>)]   \n",
       "16                                    [(ctx_dep_out, {'filtering': True}, <function <lambda> at 0x000000FC7A0ADAE8>), (ctx_dep_out, {'filtering': True}, <function <lambda> at 0x000000FC7A0ADAE8>)]   \n",
       "17                                    [(ctx_dep_out, {'filtering': True}, <function <lambda> at 0x000000FC7A0ADAE8>), (ctx_dep_out, {'filtering': True}, <function <lambda> at 0x000000FC7A0ADAE8>)]   \n",
       "18                              [(ctx_dep_in_out, {'filtering': True}, <function <lambda> at 0x000000FC7A0ADB70>), (ctx_dep_in_out, {'filtering': True}, <function <lambda> at 0x000000FC7A0ADB70>)]   \n",
       "19                              [(ctx_dep_in_out, {'filtering': True}, <function <lambda> at 0x000000FC7A0ADB70>), (ctx_dep_in_out, {'filtering': True}, <function <lambda> at 0x000000FC7A0ADB70>)]   \n",
       "20                              [(ctx_dep_in_out, {'filtering': True}, <function <lambda> at 0x000000FC7A0ADB70>), (ctx_dep_in_out, {'filtering': True}, <function <lambda> at 0x000000FC7A0ADB70>)]   \n",
       "\n",
       "      dataset        f1      prec       rec  \\\n",
       "0   Wikipedia  0.764622  0.740331  0.790560   \n",
       "1    WikiNews  0.789474  0.772358  0.807365   \n",
       "2        News  0.838122  0.818057  0.859195   \n",
       "3   Wikipedia  0.758226  0.736111  0.781711   \n",
       "4    WikiNews  0.787795  0.771739  0.804533   \n",
       "5        News  0.837307  0.817808  0.857759   \n",
       "6   Wikipedia  0.758523  0.731507  0.787611   \n",
       "7    WikiNews  0.787204  0.773224  0.801700   \n",
       "8        News  0.837079  0.818681  0.856322   \n",
       "9   Wikipedia  0.759602  0.733516  0.787611   \n",
       "10   WikiNews  0.782730  0.769863  0.796034   \n",
       "11       News  0.836491  0.817558  0.856322   \n",
       "12  Wikipedia  0.763271  0.743017  0.784661   \n",
       "13   WikiNews  0.794444  0.779292  0.810198   \n",
       "14       News  0.839072  0.821183  0.857759   \n",
       "15  Wikipedia  0.749642  0.727778  0.772861   \n",
       "16   WikiNews  0.792190  0.780220  0.804533   \n",
       "17       News  0.833566  0.811989  0.856322   \n",
       "18  Wikipedia  0.746398  0.729577  0.764012   \n",
       "19   WikiNews  0.794444  0.779292  0.810198   \n",
       "20       News  0.837438  0.820690  0.854885   \n",
       "\n",
       "                                                                                                                                                                                                         zc  \n",
       "0   (context_complexity, [(context_complexity_from_target, <function ctx_features_context_complexity_from_target at 0x000000FC25B7FD90>), (context_complexity_from_context, <function ctx_features_conte...  \n",
       "1   (context_complexity, [(context_complexity_from_target, <function ctx_features_context_complexity_from_target at 0x000000FC25B7FD90>), (context_complexity_from_context, <function ctx_features_conte...  \n",
       "2   (context_complexity, [(context_complexity_from_target, <function ctx_features_context_complexity_from_target at 0x000000FC25B7FD90>), (context_complexity_from_context, <function ctx_features_conte...  \n",
       "3   (context_complexity, [(context_complexity_from_target, <function ctx_features_context_complexity_from_target at 0x000000FC25B7FD90>), (context_complexity_from_context, <function ctx_features_conte...  \n",
       "4   (context_complexity, [(context_complexity_from_target, <function ctx_features_context_complexity_from_target at 0x000000FC25B7FD90>), (context_complexity_from_context, <function ctx_features_conte...  \n",
       "5   (context_complexity, [(context_complexity_from_target, <function ctx_features_context_complexity_from_target at 0x000000FC25B7FD90>), (context_complexity_from_context, <function ctx_features_conte...  \n",
       "6   (context_complexity, [(context_complexity_from_target, <function ctx_features_context_complexity_from_target at 0x000000FC25B7FD90>), (context_complexity_from_context, <function ctx_features_conte...  \n",
       "7   (context_complexity, [(context_complexity_from_target, <function ctx_features_context_complexity_from_target at 0x000000FC25B7FD90>), (context_complexity_from_context, <function ctx_features_conte...  \n",
       "8   (context_complexity, [(context_complexity_from_target, <function ctx_features_context_complexity_from_target at 0x000000FC25B7FD90>), (context_complexity_from_context, <function ctx_features_conte...  \n",
       "9   (context_complexity, [(context_complexity_from_target, <function ctx_features_context_complexity_from_target at 0x000000FC25B7FD90>), (context_complexity_from_context, <function ctx_features_conte...  \n",
       "10  (context_complexity, [(context_complexity_from_target, <function ctx_features_context_complexity_from_target at 0x000000FC25B7FD90>), (context_complexity_from_context, <function ctx_features_conte...  \n",
       "11  (context_complexity, [(context_complexity_from_target, <function ctx_features_context_complexity_from_target at 0x000000FC25B7FD90>), (context_complexity_from_context, <function ctx_features_conte...  \n",
       "12  (context_complexity, [(context_complexity_from_target, <function ctx_features_context_complexity_from_target at 0x000000FC25B7FD90>), (context_complexity_from_context, <function ctx_features_conte...  \n",
       "13  (context_complexity, [(context_complexity_from_target, <function ctx_features_context_complexity_from_target at 0x000000FC25B7FD90>), (context_complexity_from_context, <function ctx_features_conte...  \n",
       "14  (context_complexity, [(context_complexity_from_target, <function ctx_features_context_complexity_from_target at 0x000000FC25B7FD90>), (context_complexity_from_context, <function ctx_features_conte...  \n",
       "15  (context_complexity, [(context_complexity_from_target, <function ctx_features_context_complexity_from_target at 0x000000FC25B7FD90>), (context_complexity_from_context, <function ctx_features_conte...  \n",
       "16  (context_complexity, [(context_complexity_from_target, <function ctx_features_context_complexity_from_target at 0x000000FC25B7FD90>), (context_complexity_from_context, <function ctx_features_conte...  \n",
       "17  (context_complexity, [(context_complexity_from_target, <function ctx_features_context_complexity_from_target at 0x000000FC25B7FD90>), (context_complexity_from_context, <function ctx_features_conte...  \n",
       "18  (context_complexity, [(context_complexity_from_target, <function ctx_features_context_complexity_from_target at 0x000000FC25B7FD90>), (context_complexity_from_context, <function ctx_features_conte...  \n",
       "19  (context_complexity, [(context_complexity_from_target, <function ctx_features_context_complexity_from_target at 0x000000FC25B7FD90>), (context_complexity_from_context, <function ctx_features_conte...  \n",
       "20  (context_complexity, [(context_complexity_from_target, <function ctx_features_context_complexity_from_target at 0x000000FC25B7FD90>), (context_complexity_from_context, <function ctx_features_conte...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation = [{'dataset' : result.dataset.name, 'agg' : result.agg[0],\n",
    "                    'zc' : result.fc, 'context':result.context , 'prec' : result.measure[0][1],\n",
    "               'rec' : result.measure[1][1], 'f1' : result.measure[2][1]} \n",
    "                   for result in results]\n",
    "feature_eval_data = pd.DataFrame.from_records(evaluation)\n",
    "feature_eval_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
