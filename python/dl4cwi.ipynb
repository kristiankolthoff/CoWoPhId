{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1.1) Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from collections import defaultdict\n",
    "\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "Dataset = namedtuple('Dataset', 'name, train, test')\n",
    "Model = namedtuple('Model', 'type, name, dimension, corpus, model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "MAIN_PATH_DATASET = \"../cwishareddataset/traindevset/english/\"\n",
    "genres = ['Wikipedia', 'WikiNews', 'News']\n",
    "datasets = ['Train', 'Dev']\n",
    "columns = ['id', 'sentence', \"start\", \"end\", \"target\", \n",
    "           \"nat\", \"non_nat\", \"nat_marked\", \"non_nat_marked\", \"binary\", \"prob\"]\n",
    "\n",
    "\n",
    "datasets = [Dataset('Wikipedia', 'Train', 'Dev'),\n",
    "            Dataset('WikiNews', 'Train', 'Dev'),\n",
    "            Dataset('News', 'Train', 'Dev')]\n",
    "\n",
    "feature_categories = []\n",
    "\n",
    "def load_df(path):\n",
    "    df = pd.read_csv(path, header=None, sep = \"\\t\")\n",
    "    df.columns = columns\n",
    "    return df\n",
    "\n",
    "datasets = [Dataset(d.name, load_df(MAIN_PATH_DATASET + d.name + '_' + d.train + '.tsv'),\n",
    "                            load_df(MAIN_PATH_DATASET + d.name + '_' + d.test + '.tsv'))\n",
    "                            for d in datasets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1.2) Load Embedding Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Studio\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1209: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model : glove.6B.50d.txt\n",
      "load model : glove.twitter.27B.50d.txt\n",
      "[Model(type='glove', name='glove.6B.50d.txt', dimension=50, corpus='wikipedia+gigaword5', model=<gensim.models.keyedvectors.Word2VecKeyedVectors object at 0x000000FF9AD07358>), Model(type='glove', name='glove.twitter.27B.50d.txt', dimension=50, corpus='twitter', model=<gensim.models.keyedvectors.Word2VecKeyedVectors object at 0x000000FFA833D828>)]\n"
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "MAIN_PATH = 'D:/workspace_python/CoWoReId/python/resources/word-embeddings/'\n",
    "\n",
    "glove_defs = [#Model('glove', 'glove.42B.300d.txt', 300, 'cc42B', None),  \n",
    "              #Model('glove', 'glove.840B.300d.txt', 300, 'cc840B', None), \n",
    "              Model('glove', 'glove.6B.50d.txt', 50, 'wikipedia+gigaword5', None), \n",
    "              #Model('glove', 'glove.6B.100d.txt',100, 'wikipedia+gigaword5', None),\n",
    "              #Model('glove', 'glove.6B.200d.txt', 200, 'wikipedia+gigaword5', None), \n",
    "              #Model('glove', 'glove.6B.300d.txt', 300, 'wikipedia+gigaword5', None),\n",
    "              #Model('glove', 'glove.twitter.27B.25d.txt', 25, 'twitter', None)]\n",
    "              Model('glove', 'glove.twitter.27B.50d.txt', 50, 'twitter', None)] \n",
    "              #Model('glove', 'glove.twitter.27B.100d.txt', 100, 'twitter', None), \n",
    "              #Model('glove', 'glove.twitter.27B.200d.txt', 200, 'twitter', None)]\n",
    "\n",
    "glove_models = []\n",
    "for model in glove_defs:\n",
    "    glove_file = datapath(MAIN_PATH + model.name)\n",
    "    tmp_file = get_tmpfile(model.name + '-temp')\n",
    "    glove2word2vec(glove_file, tmp_file)\n",
    "    vecs = KeyedVectors.load_word2vec_format(tmp_file)\n",
    "    glove_models.append(Model(model.type, model.name, model.dimension, model.corpus, vecs))\n",
    "    print('load model : {}'.format(model.name))\n",
    "    \n",
    "print(glove_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = []\n",
    "models.extend(glove_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2.1) Preprocessing\n",
    "Here we present all the code to preprocess the data stored in a dataframe into a proper representation that can be used in sequence tagging models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from functools import lru_cache\n",
    "from utils import penn_to_wn\n",
    "import re\n",
    "import unicodedata\n",
    "import sys\n",
    "from collections import Counter\n",
    "from ngram_representation import missing_strat_random\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "tbl = dict.fromkeys(i for i in range(sys.maxunicode)\n",
    "                      if unicodedata.category(chr(i)).startswith('P'))\n",
    "\n",
    "def overlaps(start1, end1, start2, end2):\n",
    "    return bool(range(max(start1, start2), min(end1, end2)+1))\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(tbl)\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def all_tokens_with_index(context):\n",
    "    '''\n",
    "    Receives a sentence denoted by context and applies tokenization\n",
    "    on the input. Each token is annotated with its word index starting\n",
    "    from 1 and the corresponding start and end character positions of \n",
    "    the word. Also applies some strategies to handle unproper formated\n",
    "    input sentence string such as removing additional whitespaces and \n",
    "    quotation marks that otherwise change the actual character start\n",
    "    and end positions. All results are cached in case it has to be computed\n",
    "    multiple times for the same sentence.\n",
    "    '''\n",
    "    curr_pos = 0\n",
    "    targets = []\n",
    "    j = 0\n",
    "    w = 0\n",
    "    curr_split = ''\n",
    "    ctx_split = context.split()\n",
    "    whitespaces = re.findall('\\s+', context)\n",
    "    num_whitespaces = [len(token) for token in whitespaces]\n",
    "    num_whitespaces.append(1)\n",
    "    tokens = word_tokenize(context)\n",
    "    tokens = ['\"' if token not in context else token for token in tokens]\n",
    "    for index, token in enumerate(tokens, 1):\n",
    "        targets.append((token, index, curr_pos, (curr_pos + len(token))))\n",
    "        curr_pos += len(token)\n",
    "        curr_split += token\n",
    "        if ctx_split[j] == curr_split:\n",
    "            curr_pos += num_whitespaces[w]\n",
    "            j += 1\n",
    "            w += 1\n",
    "            curr_split = ''\n",
    "    return [val for val in targets if val[0] != '\"']\n",
    "\n",
    "def build_vocabulary(sentences, embedding, dimension, \n",
    "                     missing='unique', provided = ['s_target', 'e_target']):\n",
    "    '''\n",
    "    Based on a list of sentences which are themselve represented\n",
    "    as a list of words, constructs a vocabulary of the words contained\n",
    "    and assigns unique indicies to the words. In particular, it returns \n",
    "    a map of indices to their words, a map of words to their indices\n",
    "    and based on the provided embedding model an embedding matrix\n",
    "    for the constructed vocabulary. For missing vocabulary, it \n",
    "    constructs a random embedding and a proper index is missing parameter\n",
    "    is set to 'unique', otherwise if it is set to 'equal' it creates\n",
    "    a random embedding for one special UNK embedding and neglects missing\n",
    "    vocabulary in the built index. All tokens in the 'provided' list,\n",
    "    receive under 'equal' mode still individual random embeddings.\n",
    "    '''\n",
    "    if missing not in ['unique', 'equal']:\n",
    "        raise ValueError(\"Parameter missing must be either 'equal' or 'unique'\")\n",
    "    all_words = [word for sentence in sentences for word in sentence]\n",
    "    print('# Words : {}'.format(len(all_words)))\n",
    "    counter = Counter(all_words)\n",
    "    index = 1\n",
    "    word2index = {}\n",
    "    for (word, count) in counter.most_common():\n",
    "        if (missing=='unique' or word in embedding.vocab):\n",
    "            word2index[word] = index\n",
    "            index += 1\n",
    "    word2index['_pad_'] = 0\n",
    "    if missing == 'equal':\n",
    "        word2index['_unk_'] = len(word2index)\n",
    "        for token in provided:\n",
    "            word2index[token] = len(word2index)\n",
    "    index2word = {index : word for word, index in word2index.items()}\n",
    "    vocab_size = len(word2index)\n",
    "    print('# Vocab : {}'.format(vocab_size))\n",
    "    embedding_matrix = np.zeros(((vocab_size), dimension))\n",
    "    embedding_matrix[0] = missing_strat_random('_pad_', dimension)\n",
    "    missing_embed_words = []\n",
    "    for word, index in word2index.items():\n",
    "        if word in embedding.vocab:\n",
    "            embedding_matrix[index] = embedding[word]\n",
    "        else:\n",
    "            embedding_matrix[index] = missing_strat_random(word, dimension)\n",
    "            missing_embed_words.append(word)\n",
    "    missing_embed_count = len(missing_embed_words)\n",
    "    print('# Words missing embedding : {}'.format(missing_embed_count))\n",
    "    print('Embedding shape : {}'.format(embedding_matrix.shape))\n",
    "    return word2index, index2word, embedding_matrix\n",
    "\n",
    "\n",
    "def build_char_vocabulary(sentences, embedding, dimension, \n",
    "                          missing='unique', provided = ['_']):\n",
    "    '''\n",
    "    Based on a list of sentences which are themselve represented\n",
    "    as a list of words, constructs a character vocabulary and provides\n",
    "    a mapping of unique indices to the found characters, a mapping of\n",
    "    the characters to their indicies and a character embedding matrix\n",
    "    where the i-th row represents the character embedding of the character\n",
    "    with index i. This is based on a provided character embedding, represented\n",
    "    as a dictionary. Provided tokens will be added as a single char to\n",
    "    the vocabulary.\n",
    "    '''\n",
    "    if missing not in ['unique', 'equal']:\n",
    "        raise ValueError(\"Parameter missing must be either 'equal' or 'unique'\")\n",
    "    all_chars = [char for sentence in sentences \n",
    "                 for word in sentence for char in word]\n",
    "    all_chars.extend(provided)\n",
    "    print('# Chars : {}'.format(len(all_chars)))\n",
    "    counter = Counter(all_chars)\n",
    "    index = 1\n",
    "    char2index = {}\n",
    "    for (char, count) in counter.most_common():\n",
    "        if (missing=='unique' or char in embedding.keys()):\n",
    "            char2index[char] = index\n",
    "            index += 1\n",
    "    char2index['_pad_'] = 0\n",
    "    if missing == 'equal':\n",
    "        char2index['_unk_'] = len(char2index)\n",
    "    index2char = {index : char for char, index in char2index.items()}\n",
    "    vocab_size = len(char2index)\n",
    "    print('# Vocab (chars) : {}'.format(vocab_size))\n",
    "    embedding_matrix = np.zeros(((vocab_size), dimension))\n",
    "    embedding_matrix[0] = missing_strat_random('_pad_', dimension)\n",
    "    missing_embed_chars = []\n",
    "    for char, index in char2index.items():\n",
    "        if char in embedding.keys():\n",
    "            embedding_matrix[index] = embedding[char]\n",
    "        else:\n",
    "            embedding_matrix[index] = missing_strat_random(char, dimension)\n",
    "            missing_embed_chars.append(char)\n",
    "    missing_embed_count = len(missing_embed_chars)\n",
    "    print('# Chars missing embedding : {}'.format(missing_embed_count))\n",
    "    print('Embedding shape : {}'.format(embedding_matrix.shape))\n",
    "    return char2index, index2char, embedding_matrix\n",
    "\n",
    "\n",
    "def compute_character_embeddings(embedding):\n",
    "    '''\n",
    "    Computes a character embedding as a dictionary of word to its\n",
    "    embedding based on a gensim word embedding. For each character,\n",
    "    averages the word embeddings containing the character as an\n",
    "    approximation to character-level embeddings.\n",
    "    '''\n",
    "    chars = {}\n",
    "    for word, vocab in embedding.vocab.items():\n",
    "        vector = embedding[word]\n",
    "        for char in word:\n",
    "            if ord(char)<128:\n",
    "                if char in chars:\n",
    "                    chars[char] = (chars[char][0]+vector, \n",
    "                                   chars[char][1]+1)\n",
    "                else:\n",
    "                    chars[char] = (vector, 1)\n",
    "    for char, (vector, num) in chars.items():\n",
    "        chars[char] = np.round(vector/num, 6).tolist()\n",
    "    return chars\n",
    "\n",
    "def forward_transformation_v1(dataframe, lowercase = True, filter_punc = True, filtering = \"a132\"):\n",
    "    '''\n",
    "    Transforms the provided dataframe rows into a representation\n",
    "    to be used in a sequence classifier. For each sentence in the\n",
    "    dataset, returns the sentence id, the sentence as a list of \n",
    "    words based on tokenization, the binary label for each word, \n",
    "    the probability label for each word and a list of (start, end)\n",
    "    tuples representing the start and end positions of the words \n",
    "    in the sentence word list. This can be used to map back the\n",
    "    predictions later. This function should be used if classification\n",
    "    is done on word level.\n",
    "    '''\n",
    "    grouped = dataframe.groupby('sentence').apply(lambda row : \n",
    "                        {'sent_id' : list(set(row['sent_id']))[0],\n",
    "                         'sentence' : list(set(row['sentence']))[0], \n",
    "                         'tags': [tag for tag in zip(row['target'], \n",
    "                            row['start'], row['end'], row['binary'], row['prob'])]})\n",
    "    sentence_ids = []\n",
    "    sentences = []\n",
    "    binaries = []\n",
    "    probabilities = []\n",
    "    start_ends = []\n",
    "    for vals in grouped:\n",
    "        sent_id = vals['sent_id']\n",
    "        sentence = vals['sentence']\n",
    "        tags = vals['tags']\n",
    "        tags_without_labels = [(word, start, end) for word, start, end, binary, prob in tags]\n",
    "        all_tokens = all_tokens_with_index(sentence)\n",
    "        sent_repr = [(word, start, end, tags[tags_without_labels.index((word, start, end))][3],\n",
    "                     tags[tags_without_labels.index((word, start, end))][4])\n",
    "           if (word, start, end) in tags_without_labels \n",
    "          else (word, start, end, 0, 0.0) for word, index, start, end in all_tokens]\n",
    "        if lowercase:\n",
    "            sent_repr = [(word.lower(), start, end, binary, prob) \n",
    "                         for word, start, end, binary, prob in sent_repr]\n",
    "        if filter_punc:\n",
    "            sent_repr = list(filter(lambda vals : remove_punctuation(vals[0]), sent_repr))\n",
    "        if filtering:\n",
    "            sent_repr = list(filter(lambda vals : vals[0] != \"'s\", sent_repr))\n",
    "            sent_repr = list(filter(lambda vals : vals[0] != \"``\", sent_repr))\n",
    "        sentence_ids.append(sent_id)\n",
    "        sentences.append([vals[0] for vals in sent_repr])\n",
    "        binaries.append([vals[3] for vals in sent_repr])\n",
    "        probabilities.append([vals[4] for vals in sent_repr])\n",
    "        start_ends.append([(vals[1], vals[2]) for vals in sent_repr])\n",
    "    return sentence_ids, sentences, start_ends, binaries, probabilities\n",
    "\n",
    "\n",
    "def forward_transformation_v2(dataframe, start_tag = 's_target', end_tag = 'e_target',\n",
    "                                   lowercase = True, filter_punc = True, filtering = \"a132\"):\n",
    "    '''\n",
    "    Transforms the provided dataframe rows into a representation\n",
    "    to be used in a sequence classifier. Here, each row in the dataframe\n",
    "    is transformed into one instance to classify and each target in a \n",
    "    sentence is tagged by surrounding it with the provided start and\n",
    "    end tag. Hence, the whole sequence is classified at once. Returns\n",
    "    the transformed sentences (one for each row in the dataframe), the\n",
    "    corresponding binary and probabilitiy label.\n",
    "    '''\n",
    "    sentences = []\n",
    "    binaries = []\n",
    "    probabilities = []\n",
    "    for index, row in dataframe.iterrows():\n",
    "        sentence = row['sentence']\n",
    "        start = row['start']\n",
    "        end = row['end']\n",
    "        sentence = sentence[:start] + start_tag + ' ' + sentence[start:end] + \\\n",
    "                             ' ' + end_tag + sentence[end:]\n",
    "        if lowercase:\n",
    "            sentence = sentence.lower()\n",
    "        sent_repr = all_tokens_with_index(sentence)\n",
    "        if filter_punc:\n",
    "            sent_repr = list(filter(lambda vals : remove_punctuation(vals[0]), sent_repr))\n",
    "        if filtering:\n",
    "            sent_repr = list(filter(lambda vals : vals[0] != \"'s\", sent_repr))\n",
    "            sent_repr = list(filter(lambda vals : vals[0] != \"``\", sent_repr))\n",
    "        sentences.append([word for word, index, start, end in sent_repr])\n",
    "        binaries.append(row['binary'])\n",
    "        probabilities.append(row['prob'])\n",
    "    return sentences, binaries, probabilities\n",
    "\n",
    "\n",
    "def merge_train_test_dataset(dataset):\n",
    "    '''\n",
    "    Computes the training and test set size as (1) the\n",
    "    number of rows and (2) the number of unique sentences\n",
    "    contained. Merges the training and test set and\n",
    "    computes the same values for the merged dataframe.\n",
    "    This can be used before creating the vocabulary,\n",
    "    to also not miss vocabulary contained solely in the\n",
    "    test set. Before training, the dataset has to be split\n",
    "    up again based on the provided numbers.\n",
    "    '''\n",
    "    # Compute num rows and sents for train and test\n",
    "    train_num_rows = dataset.train.shape[0]\n",
    "    train_num_sents = len(list(set(dataset.train.sentence.values.tolist())))\n",
    "    test_num_rows = dataset.test.shape[0]\n",
    "    test_num_sents = len(list(set(dataset.test.sentence.values.tolist())))\n",
    "    # Merge dataframes and compute same values\n",
    "    dataset_merged = dataset.train.append(dataset.test)\n",
    "    dataset_merged['sent_id'] = dataset_merged.groupby('sentence').ngroup()\n",
    "    dataset_num_rows = dataset_merged.shape[0]\n",
    "    dataset_num_sents = len(list(set(dataset_merged.sentence.values.tolist())))\n",
    "    print('----------------------')\n",
    "    print('# Rows train : {}'.format(train_num_rows))\n",
    "    print('# Rows test : {}'.format(test_num_rows))\n",
    "    print('# Rows dataset : {}'.format(dataset_num_rows))\n",
    "    print('----------------------')\n",
    "    print('# Sents train : {}'.format(train_num_sents))\n",
    "    print('# Sents test : {}'.format(test_num_sents))\n",
    "    print('# Sents dataset : {}'.format(dataset_num_sents))\n",
    "    print('----------------------')\n",
    "    return dataset_merged, train_num_rows, test_num_rows, \\\n",
    "                dataset_num_rows, train_num_sents, test_num_sents, \\\n",
    "                dataset_num_sents\n",
    "        \n",
    "def split_train_test_dataset(dataset, index):\n",
    "    '''\n",
    "    Splits the given dataset (here the list of sentences represented\n",
    "    as list of words, binary label lists etc.) into train and test\n",
    "    based on the given index. Depending on the used sequence representation\n",
    "    (v1 or v2), the index should be either the number of training sentences \n",
    "    (unique) or the number of training rows.\n",
    "    '''\n",
    "    train = dataset[:index]\n",
    "    test = dataset[index:]\n",
    "    print('Training set length : {}'.format(len(train)))\n",
    "    print('Test set length : {}'.format(len(test)))\n",
    "    return train, test\n",
    "        \n",
    "def sentence_max_length(sentences):\n",
    "    sent_lens = [len(sentence) for sentence in sentences]\n",
    "    sent_max_length = np.max(sent_lens)\n",
    "    print('Max length sentence : {}'.format(sent_max_length))\n",
    "    return sent_max_length\n",
    "\n",
    "def pad_encode_sequences(sentences, word2index, missing, max_length):\n",
    "    '''\n",
    "    Encodes a list of sentences (a sentence represented as a list of words)\n",
    "    into their corresponding integer index based on the provided dictionary.\n",
    "    For missing tokens in the dictionary, applies the provided 'missing' value.\n",
    "    Afterwards, applies padding to the sentences and uses 'max_length' as the\n",
    "    maximum overall sentence length.\n",
    "    '''\n",
    "    words_with_indices = [[word2index.get(word, missing)\n",
    "                        for word in sent] for sent in sentences]\n",
    "    pad_val = word2index['_pad_']\n",
    "    return pad_sequences(maxlen=max_length, \\\n",
    "            sequences=words_with_indices, padding=\"post\", value=pad_val)\n",
    "\n",
    "def pad_binaries_probs(binaries, probabilities, max_length):\n",
    "    '''\n",
    "    Applies padding to binary labels and the probabilities.\n",
    "    Parameter 'max_length' is used as the maximum length\n",
    "    to pad the two provided lists to.\n",
    "    '''\n",
    "    binary_padded = pad_sequences(maxlen=max_length, sequences=binaries, padding=\"post\", value=0)\n",
    "    prob_padded = pad_sequences(maxlen=max_length, sequences=probabilities, padding=\"post\", value=0, dtype=\"float\")\n",
    "    return binary_padded, prob_padded\n",
    "\n",
    "def ngram_prediction_agg_majority_vote(predictions):\n",
    "    positive_sum = np.sum(predictions)\n",
    "    ratio = positive_sum / len(predictions)\n",
    "    return int(ratio + 0.5)\n",
    "\n",
    "def ngram_prediction_agg_max(predictions):\n",
    "    return np.max(predictions)\n",
    "\n",
    "def ngram_prediction_agg_begin(predictions):\n",
    "    return predictions[0]\n",
    "\n",
    "def ngram_prediction_agg_end(predictions):\n",
    "    return predictions[-1]\n",
    "\n",
    "def backward_transformation_v1(dataset, sent_ids, test_words_padded, \n",
    "                    index2word, test_start_end, final_predictions):\n",
    "    '''\n",
    "    Based on the dataset, the list of sentence_ids, the padded words\n",
    "    from the test set, the start and end tuple list of the test set and\n",
    "    the produced v1 predictions, maps the predictions back to original\n",
    "    representation (from number of sentences to number of rows) and\n",
    "    computes the F1-score between predictions and labels of the orignal\n",
    "    representation. For n-gram targets, applies an aggregation strategy.\n",
    "    '''\n",
    "    ngram_prediction_agg = ngram_prediction_agg_max\n",
    "    results = []\n",
    "    num_missing_match = []\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    count=0\n",
    "    sent_count = 0\n",
    "    for ind, sent in enumerate(test_words_padded):\n",
    "        sent_id = sent_ids[ind]\n",
    "        words = [index2word[index]  for index in sent]\n",
    "        #print(sent_id)\n",
    "        #print(words)\n",
    "        ses = test_start_end[ind]\n",
    "        preds = final_predictions[ind]\n",
    "        #print(ses)\n",
    "        #print(preds)\n",
    "        selected = dataset.loc[dataset.sent_id==sent_id,]\n",
    "        targets = selected.target.values.tolist()\n",
    "        start_ends = list(zip(selected.start.values.tolist(), selected.end.values.tolist()))\n",
    "        binary_y = selected.binary.values.tolist()\n",
    "        #print(binary_y)\n",
    "        #print(targets)\n",
    "        #print(start_ends)\n",
    "        for label_index, (start, end) in enumerate(start_ends):\n",
    "            #print('-----',start, end)\n",
    "            matching_indices = [i for i, (s, e) in enumerate(ses) if overlaps(start, end, s, e)]\n",
    "            if not matching_indices:\n",
    "                num_missing_match.append((sent_id, (start,end), ses, words))\n",
    "                prediction = 1\n",
    "            matching_predictions = [preds[i] for i in matching_indices]\n",
    "            if len(matching_predictions)>1:\n",
    "                prediction = ngram_prediction_agg(matching_predictions)\n",
    "            else:\n",
    "                if matching_indices:\n",
    "                    prediction = matching_predictions[0]\n",
    "            matching_labels = binary_y[label_index]\n",
    "            #print(matching_indices)\n",
    "            #print(matching_labels)\n",
    "            #print(matching_predictions)\n",
    "            #print(prediction)\n",
    "            all_labels.append(matching_labels)\n",
    "            all_predictions.append(prediction)\n",
    "    f1 = f1_score(all_labels, all_predictions)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2.2) DL Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2.2.1) Utility Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import keras.callbacks\n",
    "\n",
    "class MetricsV2(keras.callbacks.Callback):\n",
    "    def __init__(self, training_data, show_test_data=True):\n",
    "        self.train_f1_scores = []\n",
    "        self.test_f1_scores = []\n",
    "        self.training_data = training_data\n",
    "        self.show_test_data = show_test_data\n",
    "        \n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        # Compute the F1-score for the test data\n",
    "        test_label = self.validation_data[1]\n",
    "        test_label = np.array(test_label)\n",
    "        test_label = np.argmax(test_label, axis = 1)\n",
    "        test_predict = np.asarray(self.model.predict(self.validation_data[0]))\n",
    "        test_predict = np.argmax(test_predict, axis = 1)\n",
    "        test_f1 = f1_score(test_label, test_predict)\n",
    "        self.test_f1_scores.append(test_f1)\n",
    "        # Compute the F1-score for the training data\n",
    "        train_label = self.training_data[1]\n",
    "        train_label = np.array(train_label)\n",
    "        train_label = np.argmax(train_label, axis = 1)\n",
    "        train_predict = np.asarray(self.model.predict(self.training_data[0]))\n",
    "        train_predict = np.argmax(train_predict, axis = 1)\n",
    "        train_f1 = f1_score(train_label, train_predict)\n",
    "        self.train_f1_scores.append(train_f1)\n",
    "        print('Training F1-score : {}'.format(train_f1))\n",
    "        print('Testing F1-score : {}'.format(test_f1))\n",
    "        if self.show_test_data:\n",
    "            print('--------------------Targets-------------------------')\n",
    "            print(test_label)\n",
    "            print('--------------------Predictions-------------------------')\n",
    "            print(test_predict)\n",
    "    \n",
    "class MetricsV1(keras.callbacks.Callback):\n",
    "    \n",
    "    def __init__(self, training_data, show_test_data=True):\n",
    "        self.train_f1_scores = []\n",
    "        self.test_f1_scores = []\n",
    "        self.training_data = training_data\n",
    "        self.show_test_data = show_test_data\n",
    "        \n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        # Compute the F1-score for the test data\n",
    "        test_label = self.validation_data[1]\n",
    "        test_label = np.array(test_label)\n",
    "        test_shape = test_label.shape\n",
    "        test_label = test_label.reshape((test_shape[0]*test_shape[1], test_shape[2]))\n",
    "        test_label = np.argmax(test_label, axis = 1)\n",
    "        test_predict = np.asarray(self.model.predict(self.validation_data[0]))\n",
    "        test_predict = test_predict.reshape((test_shape[0]*test_shape[1]), test_shape[2])\n",
    "        test_predict = np.argmax(test_predict, axis = 1)\n",
    "        test_f1 = f1_score(test_label, test_predict)\n",
    "        self.test_f1_scores.append(test_f1)\n",
    "        # Compute the F1-score for the training data\n",
    "        train_label = self.training_data[1]\n",
    "        train_label = np.array(train_label)\n",
    "        train_shape = train_label.shape\n",
    "        train_label = train_label.reshape((train_shape[0]*train_shape[1], train_shape[2]))\n",
    "        train_label = np.argmax(train_label, axis = 1)\n",
    "        train_predict = np.asarray(self.model.predict(self.training_data[0]))\n",
    "        train_predict = train_predict.reshape((train_shape[0]*train_shape[1]), train_shape[2])\n",
    "        train_predict = np.argmax(train_predict, axis = 1)\n",
    "        train_f1 = f1_score(train_label, train_predict)\n",
    "        self.train_f1_scores.append(train_f1)\n",
    "        print('Training F1-score : {}'.format(train_f1))\n",
    "        print('Testing F1-score : {}'.format(test_f1))\n",
    "        if self.show_test_data:\n",
    "            print('--------------------Targets-------------------------')\n",
    "            print(test_label)\n",
    "            print('--------------------Predictions-------------------------')\n",
    "            print(test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def weighted_categorical_crossentropy(weights):\n",
    "    \"\"\"\n",
    "    A weighted version of keras.objectives.categorical_crossentropy\n",
    "    \n",
    "    Variables:\n",
    "        weights: numpy array of shape (C,) where C is the number of classes\n",
    "    \n",
    "    Usage:\n",
    "        weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 10x.\n",
    "        loss = weighted_categorical_crossentropy(weights)\n",
    "        model.compile(loss=loss,optimizer='adam')\n",
    "    \"\"\"\n",
    "    \n",
    "    weights = K.variable(weights)\n",
    "        \n",
    "    def loss(y_true, y_pred):\n",
    "        # scale predictions so that the class probas of each sample sum to 1\n",
    "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "        # clip to prevent NaN's and Inf's\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        # calc\n",
    "        loss = y_true * K.log(y_pred) * weights\n",
    "        loss = -K.sum(loss, -1)\n",
    "        return loss\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2.2.2) Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Input\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "\n",
    "def model_v1_LSTM(sent_max_length, vocab_size, dimension, embedding):\n",
    "    in_seq = Input(shape=(sent_max_length,))\n",
    "    embed = Embedding(input_dim=vocab_size, output_dim=dimension, \\\n",
    "                  weights=[embedding], input_length=sent_max_length)(in_seq)\n",
    "    drop = Dropout(0.1)(embed)\n",
    "    lstm = LSTM(units=150, return_sequences=True, recurrent_dropout=0.1)(drop)\n",
    "    out = TimeDistributed(Dense(2, activation=\"softmax\"))(lstm)\n",
    "    return Model(in_seq, out)\n",
    "\n",
    "def model_v1_BiLSTM(sent_max_length, vocab_size, dimension, embedding):\n",
    "    in_seq = Input(shape=(sent_max_length,))\n",
    "    embed = Embedding(input_dim=vocab_size, output_dim=dimension, \\\n",
    "                  weights=[embedding], input_length=sent_max_length)(in_seq)\n",
    "    drop = Dropout(0.1)(embed)\n",
    "    lstm = Bidirectional(LSTM(units=20, return_sequences=True, recurrent_dropout=0.1))(drop)\n",
    "    out = TimeDistributed(Dense(2, activation=\"softmax\"))(lstm)\n",
    "    return Model(in_seq, out)\n",
    "\n",
    "def model_v2_LSTM(sent_max_length, vocab_size, dimension, embedding):\n",
    "    in_seq = Input(shape=(sent_max_length,))\n",
    "    embed = Embedding(input_dim=vocab_size, output_dim=dimension, \\\n",
    "                  weights=[embedding], input_length=sent_max_length)(in_seq)\n",
    "    drop = Dropout(0.1)(embed)\n",
    "    lstm = LSTM(units=150, return_sequences=False, recurrent_dropout=0.1)(drop)\n",
    "    out = Dense(2, activation=\"softmax\")(lstm)\n",
    "    return Model(in_seq, out)\n",
    "\n",
    "def model_v2_BiLSTM(sent_max_length, vocab_size, dimension, embedding):\n",
    "    in_seq = Input(shape=(sent_max_length,))\n",
    "    embed = Embedding(input_dim=vocab_size, output_dim=dimension, \\\n",
    "                  weights=[embedding], input_length=sent_max_length)(in_seq)\n",
    "    drop = Dropout(0.1)(embed)\n",
    "    lstm = Bidirectional(LSTM(units=150, return_sequences=False, recurrent_dropout=0.1))(drop)\n",
    "    out = Dense(2, activation=\"softmax\")(lstm)\n",
    "    return Model(in_seq, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2.2.3) Models preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preparation_v1(dataset, embedding):\n",
    "    dataframe_merged, train_num_rows, test_num_rows, \\\n",
    "                dataset_num_rows, train_num_sents, test_num_sents, \\\n",
    "                dataset_num_sents = merge_train_test_dataset(dataset)\n",
    "    sentence_ids, sentences, start_ends, \\\n",
    "        binaries, probabilties = forward_transformation_v1(dataframe_merged)\n",
    "    word2index, index2word, word_embedding = build_vocabulary(sentences, \\\n",
    "                                embedding, embedding.vector_size, missing='unique')\n",
    "    sent_max_length = sentence_max_length(sentences)\n",
    "    words_padded = pad_encode_sequences(sentences, word2index, '', sent_max_length)\n",
    "    binaries_padded, probabilities_padded = pad_binaries_probs(binaries, probabilties, sent_max_length)\n",
    "    binaries_padded_categorical = [to_categorical(clazz, num_classes=2) for clazz in binaries_padded]\n",
    "    model = model_v1_BiLSTM(sent_max_length, len(word2index), embedding.vector_size, word_embedding)\n",
    "    model.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "    model.summary()\n",
    "    train_words_padded, test_words_padded = split_train_test_dataset(words_padded, train_num_sents)\n",
    "    train_binaries_padded_cat, test_binaries_padded_cat = split_train_test_dataset(\\\n",
    "                    binaries_padded_categorical, train_num_sents)\n",
    "    print(len(train_words_padded))\n",
    "    print(len(test_words_padded))\n",
    "    metrics_v1 = MetricsV1((train_words_padded, np.array(train_binaries_padded_cat)))\n",
    "    history = model.fit(train_words_padded, np.array(train_binaries_padded_cat),\n",
    "                    batch_size=1, epochs=10, validation_data = (test_words_padded, \n",
    "                    np.array(test_binaries_padded_cat)), verbose=1, callbacks=[metrics_v1])\n",
    "    predictions = model.predict(test_words_padded)\n",
    "    final_predictions = np.argmax(predictions, axis = 2)\n",
    "    train_ses, test_ses = split_train_test_dataset(start_ends, train_num_sents)\n",
    "    train_sent_ids, test_sent_ids = split_train_test_dataset(sentence_ids, train_num_sents)\n",
    "    f1 = backward_transformation_v1(dataframe_merged, test_sent_ids, \\\n",
    "                    test_words_padded, index2word, test_ses, final_predictions)\n",
    "    return f1, metrics_v1.train_f1_scores, metrics_v1.test_f1_scores\n",
    "    \n",
    "def preparation_v2(dataset, embedding):\n",
    "    dataframe_merged, train_num_rows, test_num_rows, \\\n",
    "                dataset_num_rows, train_num_sents, test_num_sents, \\\n",
    "                dataset_num_sents = merge_train_test_dataset(dataset)\n",
    "    sentences, binaries, probabilties = forward_transformation_v2(dataframe_merged)\n",
    "    word2index, index2word, word_embedding = build_vocabulary(sentences, \\\n",
    "                            embedding, embedding.vector_size, missing='unique')\n",
    "    sent_max_length = sentence_max_length(sentences)\n",
    "    words_padded = pad_encode_sequences(sentences, word2index, '', sent_max_length)\n",
    "    binaries_categorical = [to_categorical(clazz, num_classes=2) for clazz in binaries]\n",
    "    model = model_v2_BiLSTM(sent_max_length, len(word2index), embedding.vector_size, word_embedding)\n",
    "    model.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "    model.summary()\n",
    "    train_words_padded, test_words_padded = split_train_test_dataset(words_padded, train_num_rows)\n",
    "    train_binaries_categorical, test_binaries_categorical = split_train_test_dataset(binaries_categorical, train_num_rows)\n",
    "    metrics_v2 = MetricsV2((train_words_padded, np.array(train_binaries_categorical)))\n",
    "    history = model.fit(train_words_padded, np.array(train_binaries_categorical),\n",
    "                    batch_size=1, epochs=10, validation_data = (test_words_padded, \n",
    "                    np.array(test_binaries_categorical)), verbose=1, callbacks=[metrics_v2])\n",
    "    print(len(train_words_padded))\n",
    "    print(len(test_words_padded))\n",
    "    predictions = model.predict(test_words_padded)\n",
    "    final_predictions = np.argmax(predictions, axis = 1)\n",
    "    targets = np.argmax(test_binaries_categorical, axis = 1)\n",
    "    f1 = f1_score(targets, final_predictions)\n",
    "    return f1, metrics_v2.train_f1_scores, metrics_v2.test_f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------\n",
      "# Rows train : 5551\n",
      "# Rows test : 694\n",
      "# Rows dataset : 6245\n",
      "----------------------\n",
      "# Sents train : 387\n",
      "# Sents test : 53\n",
      "# Sents dataset : 440\n",
      "----------------------\n",
      "# Words : 186472\n",
      "# Vocab : 3641\n",
      "# Words missing embedding : 162\n",
      "Embedding shape : (3641, 50)\n",
      "Max length sentence : 103\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_32 (InputLayer)        (None, 103)               0         \n",
      "_________________________________________________________________\n",
      "embedding_32 (Embedding)     (None, 103, 50)           182050    \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 103, 50)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_31 (Bidirectio (None, 300)               241200    \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 423,852\n",
      "Trainable params: 423,852\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training set length : 5551\n",
      "Test set length : 694\n",
      "Training set length : 5551\n",
      "Test set length : 694\n",
      "Train on 5551 samples, validate on 694 samples\n",
      "Epoch 1/1\n",
      "5551/5551 [==============================] - 130s 23ms/step - loss: 0.6836 - acc: 0.5601 - val_loss: 0.6958 - val_acc: 0.5187\n",
      "Training F1-score : 0.5522005131241366\n",
      "Testing F1-score : 0.5916870415647921\n",
      "--------------------Targets-------------------------\n",
      "[1 1 1 1 1 0 1 0 1 0 1 1 1 1 0 0 1 0 1 0 0 0 0 0 1 1 1 1 1 1 0 0 1 1 1 0 1\n",
      " 0 0 1 1 1 0 0 1 1 0 1 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 1 0 1 1 1 0 1 1 0 0 0\n",
      " 1 1 1 0 1 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 1 0 0 1 0 1 0 0 1 0\n",
      " 0 1 0 0 0 1 1 0 1 1 0 0 1 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1\n",
      " 1 1 0 1 0 0 0 1 1 0 0 0 0 1 1 1 1 0 1 0 1 1 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0\n",
      " 0 1 1 0 1 1 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 0 0 1 0 1 0 1 0 1\n",
      " 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 0 1 1 0 0 0 0 1 0 1 0 1 1 1 0 0 1 0 0 0 0 1\n",
      " 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 0 1 1 1 0 0 0 0 0 0 1\n",
      " 1 1 1 1 0 1 0 1 0 0 1 1 0 0 1 0 1 0 0 0 0 0 1 0 1 1 0 1 0 1 0 1 0 1 0 0 1\n",
      " 1 1 1 1 1 1 0 1 1 0 1 0 0 0 0 0 0 0 1 0 1 1 1 1 0 0 1 1 1 1 0 0 0 1 0 1 1\n",
      " 1 0 0 1 1 0 0 0 0 1 0 1 1 1 1 0 0 1 0 1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1\n",
      " 0 1 0 0 0 1 1 1 0 0 0 1 0 1 0 1 1 0 0 1 1 1 1 1 0 0 1 0 0 0 1 0 1 1 1 0 1\n",
      " 0 0 0 0 1 1 0 0 1 1 0 1 1 0 1 0 1 1 0 0 1 1 0 0 0 0 0 0 1 1 1 0 1 1 0 0 0\n",
      " 0 1 0 0 0 0 1 0 1 0 0 0 0 1 1 0 1 1 1 1 1 0 1 0 1 0 0 0 1 0 0 1 1 1 1 1 0\n",
      " 1 1 1 1 1 0 0 0 0 0 1 1 1 0 1 0 0 1 0 1 1 1 1 0 1 0 0 0 0 0 1 1 0 0 1 1 0\n",
      " 0 1 0 0 1 1 1 0 0 0 1 0 0 1 0 0 1 1 1 1 0 1 0 1 0 1 1 1 0 1 1 1 0 1 1 0 0\n",
      " 1 0 0 1 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1 1 1 0 0 1 1 1 1 0 1 1 1\n",
      " 1 1 0 0 0 0 1 1 1 0 0 1 1 1 1 0 1 0 0 1 1 0 1 0 1 1 1 1 1 0 0 0 1 1 1 1 0\n",
      " 1 1 1 1 0 1 1 1 0 0 1 1 1 0 1 1 1 0 0 0 0 1 1 1 0 0 1 1]\n",
      "--------------------Predictions-------------------------\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 0 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1]\n",
      "5551\n",
      "694\n"
     ]
    }
   ],
   "source": [
    "f1, train_f1s, test_f1s = preparation_v2(datasets[0], models[0].model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5916870415647921"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5522005131241366]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_f1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5916870415647921]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_f1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = []\n",
    "datatype = []\n",
    "f1_scores = []\n",
    "epochs = [epoch for epoch, f1 in enumerate(train_f1s)]\n",
    "epochs.extend(epochs)\n",
    "datatype = ['train' for elem in train_f1s]\n",
    "datatype.extend(['test' for elem in test_f1s])\n",
    "f1_scores.extend(train_f1s.copy())\n",
    "f1_scores.extend(test_f1s.copy())\n",
    "evaluation = [{'F1-score' : result[0], 'epoch' : result[1],\n",
    "                    'data' : result[2]} for result in zip(f1_scores, epochs, datatype)]\n",
    "epochs_f1_scores = pd.DataFrame.from_records(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZYAAAEPCAYAAABhkeIdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLCIiYioFi4iImErBIiIiplKwiIiIqf4/0FGPldOZg2wAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.set()\n",
    "ax = sns.lineplot(x=\"epoch\", y=\"F1-score\",\n",
    "                   hue=\"data\", style=\"data\",\n",
    "                   markers=True, dashes=False, data=epochs_f1_scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence_lens = [len(sent) for sent in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence lengths\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEBCAYAAAB13qL/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()\n",
    "ax = sns.distplot(sentence_lens)\n",
    "print('Sentence lengths')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "figure = ax.get_figure()\n",
    "figure.savefig('../plots/dl/sentence_length_dist.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(metrics.f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEBCAYAAAB13qL/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "epoch_f1s = plt.plot(metrics.f1_scores)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
